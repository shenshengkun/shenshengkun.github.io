<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>舒宇的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://shenshengkun.github.io/"/>
  <updated>2019-06-10T03:22:59.745Z</updated>
  <id>https://shenshengkun.github.io/</id>
  
  <author>
    <name>Shu Yu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s1.14集群部署-metrics-server</title>
    <link href="https://shenshengkun.github.io/posts/d3554aa2.html"/>
    <id>https://shenshengkun.github.io/posts/d3554aa2.html</id>
    <published>2019-06-10T03:16:01.000Z</published>
    <updated>2019-06-10T03:22:59.745Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>metrics-server 通过 kube-apiserver 发现所有节点，然后调用 kubelet APIs（通过 https 接口）获得各节点（Node）和 Pod 的 CPU、Memory 等资源使用情况。</p><p>从 Kubernetes 1.12 开始，kubernetes 的安装脚本移除了 Heapster，从 1.13 开始完全移除了对 Heapster 的支持，Heapster 不再被维护。</p><p>替代方案如下：</p><ol><li>用于支持自动扩缩容的 CPU/memory HPA metrics：metrics-server；</li><li>通用的监控方案：使用第三方可以获取 Prometheus 格式监控指标的监控系统，如 Prometheus Operator；</li><li>事件传输：使用第三方工具来传输、归档 kubernetes events；</li></ol><p>Kubernetes Dashboard 还不支持 metrics-server（PR：<a href="https://github.com/kubernetes/dashboard/pull/3504" target="_blank" rel="noopener">#3504</a>），如果使用 metrics-server 替代 Heapster，将无法在 dashboard 中以图形展示 Pod 的内存和 CPU 情况，需要通过 Prometheus、Grafana 等监控方案来弥补。</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work/</span><br><span class="line">git clone https://github.com/kubernetes-incubator/metrics-server.git</span><br><span class="line">cd metrics-server/deploy/1.8+/</span><br><span class="line">ls</span><br><span class="line">aggregated-metrics-reader.yaml  auth-delegator.yaml  auth-reader.yaml  metrics-apiservice.yaml  metrics-server-deployment.yaml  metrics-server-service.yaml  resource-reader.yaml</span><br></pre></td></tr></table></figure><h2 id="修改-metrics-server-deployment-yaml-文件，为-metrics-server-添加三个命令行参数："><a href="#修改-metrics-server-deployment-yaml-文件，为-metrics-server-添加三个命令行参数：" class="headerlink" title="修改 metrics-server-deployment.yaml 文件，为 metrics-server 添加三个命令行参数："></a>修改 <code>metrics-server-deployment.yaml</code> 文件，为 metrics-server 添加三个命令行参数：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class="line">      - name: tmp-dir</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      containers:</span><br><span class="line">      - name: metrics-server</span><br><span class="line">        image: mirrorgooglecontainers/metrics-server-amd64:v0.3.3</span><br><span class="line">        command:</span><br><span class="line">        - /metrics-server</span><br><span class="line">        - --metric-resolution=30s</span><br><span class="line">        - --requestheader-allowed-names=aggregator</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: tmp-dir</span><br><span class="line">          mountPath: /tmp</span><br></pre></td></tr></table></figure><ul><li>–metric-resolution=30s：从 kubelet 采集数据的周期；</li><li>–requestheader-allowed-names=aggregator：允许请求 metrics-server API 的用户名，该名称与 kube-apiserver 的 <code>--proxy-client-cert-file</code> 指定的证书 CN 一致；</li><li>–kubelet-preferred-address-types：优先使用 InternalIP 来访问 kubelet，这样可以避免节点名称<strong>没有 DNS 解析</strong>记录时，通过节点名称调用节点 kubelet API 失败的情况（未配置时默认的情况）；</li></ul><h2 id="修改apiserver参数："><a href="#修改apiserver参数：" class="headerlink" title="修改apiserver参数："></a>修改apiserver参数：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/systemd/system</span><br><span class="line"></span><br><span class="line">vim kube-apiserver.service</span><br><span class="line"></span><br><span class="line">--requestheader-allowed-names=&quot;aggregator&quot;</span><br></pre></td></tr></table></figure><p>重启apiserver</p><h2 id="部署-metrics-server："><a href="#部署-metrics-server：" class="headerlink" title="部署 metrics-server："></a>部署 metrics-server：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work/metrics-server/deploy/1.8+/</span><br><span class="line">kubectl create -f .</span><br></pre></td></tr></table></figure><h2 id="使用-kubectl-top-命令查看集群节点资源使用情况"><a href="#使用-kubectl-top-命令查看集群节点资源使用情况" class="headerlink" title="使用 kubectl top 命令查看集群节点资源使用情况"></a>使用 kubectl top 命令查看集群节点资源使用情况</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 1.8+]# kubectl top node</span><br><span class="line">NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">node1   117m         5%     2217Mi          57%       </span><br><span class="line">node2   147m         7%     2680Mi          69%</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;metrics-server 通过 kube-apiserver 发现所有节点，然后调用 kubelet APIs（通过 https 接口）
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-coredns</title>
    <link href="https://shenshengkun.github.io/posts/77sa4nc2.html"/>
    <id>https://shenshengkun.github.io/posts/77sa4nc2.html</id>
    <published>2019-06-06T04:32:01.000Z</published>
    <updated>2019-06-06T09:59:20.740Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>1.11后CoreDNS 已取代 Kube DNS 作为集群服务发现元件,由于 Kubernetes 需要让 Pod 与 Pod 之间能夠互相通信,然而要能够通信需要知道彼此的 IP 才行,而这种做法通常是通过 Kubernetes API 来获取,但是 Pod IP 会因为生命周期变化而改变,因此这种做法无法弹性使用,且还会增加 API Server 负担,基于此问题 Kubernetes 提供了 DNS 服务来作为查询,让 Pod 能夠以 Service 名称作为域名来查询 IP 位址,因此使用者就再不需要关心实际 Pod IP,而 DNS 也会根据 Pod 变化更新资源记录(Record resources)</p><p>CoreDNS 是由 CNCF 维护的开源 DNS 方案,该方案前身是 SkyDNS,其采用了 Caddy 的一部分来开发伺服器框架,使其能够建立一套快速灵活的 DNS,而 CoreDNS 每个功能都可以被当作成一個插件的中介软体,如 Log、Cache、Kubernetes 等功能,甚至能够将源记录存储在 Redis、Etcd 中</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>coredns 目录是 <code>cluster/addons/dns</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work/kubernetes/cluster/addons/dns/coredns</span><br><span class="line">cp coredns.yaml.base coredns.yaml</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">sed -i -e &quot;s/__PILLAR__DNS__DOMAIN__/$&#123;CLUSTER_DNS_DOMAIN&#125;/&quot; -e &quot;s/__PILLAR__DNS__SERVER__/$&#123;CLUSTER_DNS_SVC_IP&#125;/&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">还需要将镜像修改下，coredns/coredns:1.3.1</span><br></pre></td></tr></table></figure><h2 id="创建-coredns"><a href="#创建-coredns" class="headerlink" title="创建 coredns"></a>创建 coredns</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f coredns.yaml</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28.3</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建成功后，我们进行检查</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          4s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node1 coredns]# kubectl exec -ti busybox -- nslookup kubernetes</span><br><span class="line">Server:    10.254.0.2</span><br><span class="line">Address 1: 10.254.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;1.11后CoreDNS 已取代 Kube DNS 作为集群服务发现元件,由于 Kubernetes 需要让 Pod 与 Pod 之间能夠互
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s角色</title>
    <link href="https://shenshengkun.github.io/posts/65aa44f.html"/>
    <id>https://shenshengkun.github.io/posts/65aa44f.html</id>
    <published>2019-06-06T02:01:01.000Z</published>
    <updated>2019-06-06T02:13:54.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="查看node节点"><a href="#查看node节点" class="headerlink" title="查看node节点"></a>查看node节点</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 work]# kubectl get nodes</span><br><span class="line">NAME    STATUS   ROLES    AGE   VERSION</span><br><span class="line">node1   Ready    &lt;none&gt;   41h   v1.14.2</span><br><span class="line">node2   Ready    &lt;none&gt;   41h   v1.14.2</span><br></pre></td></tr></table></figure><h1 id="设置集群角色"><a href="#设置集群角色" class="headerlink" title="设置集群角色"></a>设置集群角色</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 设置 node1 为 master 角色</span><br><span class="line"></span><br><span class="line">kubectl label nodes node1 node-role.kubernetes.io/master=</span><br><span class="line"></span><br><span class="line"># 设置 node2 为 node 角色</span><br><span class="line"></span><br><span class="line">kubectl label nodes node2 node-role.kubernetes.io/node=</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node1 ~]# kubectl get nodes</span><br><span class="line">NAME    STATUS   ROLES    AGE   VERSION</span><br><span class="line">node1   Ready    master   42h   v1.14.2</span><br><span class="line">node2   Ready    node     42h   v1.14.2</span><br></pre></td></tr></table></figure><h1 id="设置taint"><a href="#设置taint" class="headerlink" title="设置taint"></a>设置taint</h1><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node [node] key=value[effect]   </span><br><span class="line">     其中[effect] 可取值: [ NoSchedule | PreferNoSchedule | NoExecute ]</span><br><span class="line">      NoSchedule: 一定不能被调度</span><br><span class="line">      PreferNoSchedule: 尽量不要调度</span><br><span class="line">      NoExecute: 不仅不会调度, 还会驱逐Node上已有的Pod</span><br></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl taint nodes node1 node-role.kubernetes.io/master=:NoExecute</span><br><span class="line">node/node1 tainted</span><br><span class="line">[root@node1 ~]# kubectl get pods</span><br><span class="line">NAME             READY   STATUS        RESTARTS   AGE</span><br><span class="line">nginx-ds-kztdz   1/1     Running       0          18h</span><br><span class="line">nginx-ds-vbjh9   0/1     Terminating   0          18h</span><br><span class="line">[root@node1 ~]# kubectl get pods</span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-ds-kztdz   1/1     Running   0          18h</span><br></pre></td></tr></table></figure><h2 id="查看taint"><a href="#查看taint" class="headerlink" title="查看taint"></a>查看taint</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl describe node node1</span><br><span class="line">Name:               node1</span><br><span class="line">Roles:              master</span><br><span class="line">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    kubernetes.io/arch=amd64</span><br><span class="line">                    kubernetes.io/hostname=node1</span><br><span class="line">                    kubernetes.io/os=linux</span><br><span class="line">                    node-role.kubernetes.io/master=</span><br><span class="line">Annotations:        node.alpha.kubernetes.io/ttl: 0</span><br><span class="line">                    volumes.kubernetes.io/controller-managed-attach-detach: true</span><br><span class="line">CreationTimestamp:  Tue, 04 Jun 2019 15:28:56 +0800</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoExecute</span><br><span class="line">                    node-role.kubernetes.io/master:NoSchedule</span><br><span class="line">Unschedulable:      false</span><br><span class="line">Conditions:</span><br><span class="line">  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----             ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  MemoryPressure   False   Thu, 06 Jun 2019 10:08:16 +0800   Tue, 04 Jun 2019 15:28:57 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure     False   Thu, 06 Jun 2019 10:08:16 +0800   Tue, 04 Jun 2019 15:28:57 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure      False   Thu, 06 Jun 2019 10:08:16 +0800   Tue, 04 Jun 2019 15:28:57 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready            True    Thu, 06 Jun 2019 10:08:16 +0800   Tue, 04 Jun 2019 15:28:57 +0800   KubeletReady                 kubelet is posting ready status</span><br><span class="line">Addresses:</span><br><span class="line">  InternalIP:  192.168.6.101</span><br></pre></td></tr></table></figure><h2 id="删除taint"><a href="#删除taint" class="headerlink" title="删除taint"></a>删除taint</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl taint nodes node1 node-role.kubernetes.io/master-</span><br><span class="line">node/node1 untainted</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;查看node节点&quot;&gt;&lt;a href=&quot;#查看node节点&quot; class=&quot;headerlink&quot; title=&quot;查看node节点&quot;&gt;&lt;/a&gt;查看node节点&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-node节点</title>
    <link href="https://shenshengkun.github.io/posts/44qq5gb2.html"/>
    <id>https://shenshengkun.github.io/posts/44qq5gb2.html</id>
    <published>2019-06-05T07:33:01.000Z</published>
    <updated>2019-06-06T06:27:52.295Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;yum install -y epel-release&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;yum install -y conntrack ipvsadm ntp ntpdate ipset jq iptables curl sysstat libseccomp &amp;&amp; modprobe ip_vs &quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h1 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h1><h2 id="下载和分发-docker-二进制文件"><a href="#下载和分发-docker-二进制文件" class="headerlink" title="下载和分发 docker 二进制文件"></a>下载和分发 docker 二进制文件</h2><p>到 <a href="https://download.docker.com/linux/static/stable/x86_64/" target="_blank" rel="noopener">docker 下载页面</a> 下载最新发布包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-18.09.6.tgz</span><br><span class="line">tar -xvf docker-18.09.6.tgz</span><br></pre></td></tr></table></figure><p>分发二进制文件到所有 worker 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp docker/*  root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-systemd-unit-文件"><a href="#创建和分发-systemd-unit-文件" class="headerlink" title="创建和分发 systemd unit 文件"></a>创建和分发 systemd unit 文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; docker.service &lt;&lt;&quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=http://docs.docker.io</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=##DOCKER_DIR##</span><br><span class="line">Environment=&quot;PATH=/opt/k8s/bin:/bin:/sbin:/usr/bin:/usr/sbin&quot;</span><br><span class="line">EnvironmentFile=-/run/flannel/docker</span><br><span class="line">ExecStart=/opt/k8s/bin/dockerd $DOCKER_NETWORK_OPTIONS</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发 systemd unit 文件到所有 worker 机器:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">sed -i -e &quot;s|##DOCKER_DIR##|$&#123;DOCKER_DIR&#125;|&quot; docker.service</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp docker.service root@$&#123;node_ip&#125;:/etc/systemd/system/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="配置和分发-docker-配置文件"><a href="#配置和分发-docker-配置文件" class="headerlink" title="配置和分发 docker 配置文件"></a>配置和分发 docker 配置文件</h2><p>使用国内的仓库镜像服务器以加快 pull image 的速度，同时增加下载的并发数 (需要重启 dockerd 生效)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; docker-daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hub-mirror.c.163.com&quot;],</span><br><span class="line">    &quot;insecure-registries&quot;: [&quot;docker02:35000&quot;],</span><br><span class="line">    &quot;max-concurrent-downloads&quot;: 20,</span><br><span class="line">    &quot;live-restore&quot;: true,</span><br><span class="line">    &quot;max-concurrent-uploads&quot;: 10,</span><br><span class="line">    &quot;debug&quot;: true,</span><br><span class="line">    &quot;data-root&quot;: &quot;$&#123;DOCKER_DIR&#125;/data&quot;,</span><br><span class="line">    &quot;exec-root&quot;: &quot;$&#123;DOCKER_DIR&#125;/exec&quot;,</span><br><span class="line">    &quot;log-opts&quot;: &#123;</span><br><span class="line">      &quot;max-size&quot;: &quot;100m&quot;,</span><br><span class="line">      &quot;max-file&quot;: &quot;5&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发 docker 配置文件到所有 worker 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p  /etc/docker/ $&#123;DOCKER_DIR&#125;/&#123;data,exec&#125;&quot;</span><br><span class="line">    scp docker-daemon.json root@$&#123;node_ip&#125;:/etc/docker/daemon.json</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="启动-docker-服务"><a href="#启动-docker-服务" class="headerlink" title="启动 docker 服务"></a>启动 docker 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable docker &amp;&amp; systemctl restart docker&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="检查服务运行状态"><a href="#检查服务运行状态" class="headerlink" title="检查服务运行状态"></a>检查服务运行状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status docker|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code></p><h1 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h1><h2 id="创建-kubelet-bootstrap-kubeconfig-文件"><a href="#创建-kubelet-bootstrap-kubeconfig-文件" class="headerlink" title="创建 kubelet bootstrap kubeconfig 文件"></a>创建 kubelet bootstrap kubeconfig 文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_name in $&#123;NODE_NAMES[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;</span><br><span class="line"></span><br><span class="line">    # 创建 token</span><br><span class="line">    export BOOTSTRAP_TOKEN=$(kubeadm token create \</span><br><span class="line">      --description kubelet-bootstrap-token \</span><br><span class="line">      --groups system:bootstrappers:$&#123;node_name&#125; \</span><br><span class="line">      --kubeconfig ~/.kube/config)</span><br><span class="line"></span><br><span class="line">    # 设置集群参数</span><br><span class="line">    kubectl config set-cluster kubernetes \</span><br><span class="line">      --certificate-authority=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">      --embed-certs=true \</span><br><span class="line">      --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig</span><br><span class="line"></span><br><span class="line">    # 设置客户端认证参数</span><br><span class="line">    kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">      --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig</span><br><span class="line"></span><br><span class="line">    # 设置上下文参数</span><br><span class="line">    kubectl config set-context default \</span><br><span class="line">      --cluster=kubernetes \</span><br><span class="line">      --user=kubelet-bootstrap \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig</span><br><span class="line"></span><br><span class="line">    # 设置默认上下文</span><br><span class="line">    kubectl config use-context default --kubeconfig=kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>向 kubeconfig 写入的是 token，bootstrap 结束后 kube-controller-manager 为 kubelet 创建 client 和 server 证书；</li></ul><p>查看 kubeadm 为各节点创建的 token： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubeadm token list --kubeconfig ~/.kube/config</span><br><span class="line">TOKEN                     TTL         EXPIRES                     USAGES                   DESCRIPTION               EXTRA GROUPS</span><br><span class="line">kp5seh.klhbcowm40rkaoh1   &lt;invalid&gt;   2019-06-05T15:24:51+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:node1</span><br><span class="line">u2zt2n.3tqw704a4ndqdj1k   &lt;invalid&gt;   2019-06-05T15:24:51+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:node2</span><br><span class="line">[root@node1 ~]#</span><br></pre></td></tr></table></figure><h2 id="分发-bootstrap-kubeconfig-文件到所有-worker-节点"><a href="#分发-bootstrap-kubeconfig-文件到所有-worker-节点" class="headerlink" title="分发 bootstrap kubeconfig 文件到所有 worker 节点"></a>分发 bootstrap kubeconfig 文件到所有 worker 节点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_name in $&#123;NODE_NAMES[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;</span><br><span class="line">    scp kubelet-bootstrap-$&#123;node_name&#125;.kubeconfig root@$&#123;node_name&#125;:/etc/kubernetes/kubelet-bootstrap.kubeconfig</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kubelet-参数配置文件"><a href="#创建和分发-kubelet-参数配置文件" class="headerlink" title="创建和分发 kubelet 参数配置文件"></a>创建和分发 kubelet 参数配置文件</h2><p>创建 kubelet 参数配置文件模板（可配置项参考<a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/config/types.go" target="_blank" rel="noopener">代码中注释</a> ）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kubelet-config.yaml.template &lt;&lt;EOF</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">address: &quot;##NODE_IP##&quot;</span><br><span class="line">staticPodPath: &quot;&quot;</span><br><span class="line">syncFrequency: 1m</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">staticPodURL: &quot;&quot;</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 0</span><br><span class="line">rotateCertificates: true</span><br><span class="line">serverTLSBootstrap: true</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: &quot;/etc/kubernetes/cert/ca.pem&quot;</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">registryPullQPS: 0</span><br><span class="line">registryBurst: 20</span><br><span class="line">eventRecordQPS: 0</span><br><span class="line">eventBurst: 20</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enableContentionProfiling: true</span><br><span class="line">healthzPort: 10248</span><br><span class="line">healthzBindAddress: &quot;##NODE_IP##&quot;</span><br><span class="line">clusterDomain: &quot;$&#123;CLUSTER_DNS_DOMAIN&#125;&quot;</span><br><span class="line">clusterDNS:</span><br><span class="line">  - &quot;$&#123;CLUSTER_DNS_SVC_IP&#125;&quot;</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">nodeStatusReportFrequency: 1m</span><br><span class="line">imageMinimumGCAge: 2m</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">volumeStatsAggPeriod: 1m</span><br><span class="line">kubeletCgroups: &quot;&quot;</span><br><span class="line">systemCgroups: &quot;&quot;</span><br><span class="line">cgroupRoot: &quot;&quot;</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">runtimeRequestTimeout: 10m</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">maxPods: 220</span><br><span class="line">podCIDR: &quot;$&#123;CLUSTER_CIDR&#125;&quot;</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">kubeAPIQPS: 1000</span><br><span class="line">kubeAPIBurst: 2000</span><br><span class="line">serializeImagePulls: false</span><br><span class="line">evictionHard:</span><br><span class="line">  memory.available:  &quot;100Mi&quot;</span><br><span class="line">nodefs.available:  &quot;10%&quot;</span><br><span class="line">nodefs.inodesFree: &quot;5%&quot;</span><br><span class="line">imagefs.available: &quot;15%&quot;</span><br><span class="line">evictionSoft: &#123;&#125;</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">failSwapOn: true</span><br><span class="line">containerLogMaxSize: 20Mi</span><br><span class="line">containerLogMaxFiles: 10</span><br><span class="line">systemReserved: &#123;&#125;</span><br><span class="line">kubeReserved: &#123;&#125;</span><br><span class="line">systemReservedCgroup: &quot;&quot;</span><br><span class="line">kubeReservedCgroup: &quot;&quot;</span><br><span class="line">enforceNodeAllocatable: [&quot;pods&quot;]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>address：kubelet 安全端口（https，10250）监听的地址，不能为 127.0.0.1，否则 kube-apiserver、heapster 等不能调用 kubelet 的 API；</li><li>readOnlyPort=0：关闭只读端口(默认 10255)，等效为未指定；</li><li>authentication.anonymous.enabled：设置为 false，不允许匿名访问 10250 端口；</li><li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTP 证书认证；</li><li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li><li>对于未通过 x509 证书和 webhook 认证的请求(kube-apiserver 或其他客户端)，将被拒绝，提示 Unauthorized；</li><li>authroization.mode=Webhook：kubelet 使用 SubjectAccessReview API 查询 kube-apiserver 某 user、group 是否具有操作资源的权限(RBAC)；</li><li>featureGates.RotateKubeletClientCertificate、featureGates.RotateKubeletServerCertificate：自动 rotate 证书，证书的有效期取决于 kube-controller-manager 的 –experimental-cluster-signing-duration 参数；</li><li>需要 root 账户运行；</li></ul><p>为各节点创建和分发 kubelet 配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do </span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    sed -e &quot;s/##NODE_IP##/$&#123;node_ip&#125;/&quot; kubelet-config.yaml.template &gt; kubelet-config-$&#123;node_ip&#125;.yaml.template</span><br><span class="line">    scp kubelet-config-$&#123;node_ip&#125;.yaml.template root@$&#123;node_ip&#125;:/etc/kubernetes/kubelet-config.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kubelet-systemd-unit-文件"><a href="#创建和分发-kubelet-systemd-unit-文件" class="headerlink" title="创建和分发 kubelet systemd unit 文件"></a>创建和分发 kubelet systemd unit 文件</h2><p>创建 kubelet systemd unit 文件模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kubelet.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kubelet</span><br><span class="line">ExecStart=/opt/k8s/bin/kubelet \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --bootstrap-kubeconfig=/etc/kubernetes/kubelet-bootstrap.kubeconfig \\</span><br><span class="line">  --cert-dir=/etc/kubernetes/cert \\</span><br><span class="line">  --cni-conf-dir=/etc/cni/net.d \\</span><br><span class="line">  --container-runtime=docker \\</span><br><span class="line">  --container-runtime-endpoint=unix:///var/run/dockershim.sock \\</span><br><span class="line">  --root-dir=$&#123;K8S_DIR&#125;/kubelet \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><br><span class="line">  --config=/etc/kubernetes/kubelet-config.yaml \\</span><br><span class="line">  --hostname-override=##NODE_NAME## \\</span><br><span class="line">  --pod-infra-container-image=registry.cn-beijing.aliyuncs.com/k8s_images/pause-amd64:3.1 \\</span><br><span class="line">  --image-pull-progress-deadline=15m \\</span><br><span class="line">  --volume-plugin-dir=$&#123;K8S_DIR&#125;/kubelet/kubelet-plugins/volume/exec/ \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">StartLimitInterval=0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>如果设置了 <code>--hostname-override</code> 选项，则 <code>kube-proxy</code> 也需要设置该选项，否则会出现找不到 Node 的情况；</li><li><code>--bootstrap-kubeconfig</code>：指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求；</li><li>K8S approve kubelet 的 csr 请求后，在 <code>--cert-dir</code> 目录创建证书和私钥文件，然后写入 <code>--kubeconfig</code> 文件；</li><li><code>--pod-infra-container-image</code> 不使用 redhat 的 <code>pod-infrastructure:latest</code> 镜像，它不能回收容器的僵尸；</li></ul><p>为各节点创建和分发 kubelet systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_name in $&#123;NODE_NAMES[@]&#125;</span><br><span class="line">  do </span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;node_name&#125;/&quot; kubelet.service.template &gt; kubelet-$&#123;node_name&#125;.service</span><br><span class="line">    scp kubelet-$&#123;node_name&#125;.service root@$&#123;node_name&#125;:/etc/systemd/system/kubelet.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="Bootstrap-Token-Auth-和授予权限"><a href="#Bootstrap-Token-Auth-和授予权限" class="headerlink" title="Bootstrap Token Auth 和授予权限"></a>Bootstrap Token Auth 和授予权限</h2><p>kubelet 启动时查找 <code>--kubeletconfig</code> 参数对应的文件是否存在，如果不存在则使用 <code>--bootstrap-kubeconfig</code> 指定的 kubeconfig 文件向 kube-apiserver 发送证书签名请求 (CSR)。</p><p>kube-apiserver 收到 CSR 请求后，对其中的 Token 进行认证，认证通过后将请求的 user 设置为 <code>system:bootstrap:&lt;Token ID&gt;</code>，group 设置为 <code>system:bootstrappers</code>，这一过程称为 Bootstrap Token Auth。</p><p>如果说kubelet启动失败的话：</p><p>创建一个 clusterrolebinding，将 group system:bootstrappers 和 clusterrole system:node-bootstrapper 绑定：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers</span><br></pre></td></tr></table></figure><h2 id="启动-kubelet-服务"><a href="#启动-kubelet-服务" class="headerlink" title="启动 kubelet 服务"></a>启动 kubelet 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;/kubelet/kubelet-plugins/volume/exec/&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/swapoff -a&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kubelet &amp;&amp; systemctl restart kubelet&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>kubelet 启动后使用 –bootstrap-kubeconfig 向 kube-apiserver 发送 CSR 请求，当这个 CSR 被 approve 后，kube-controller-manager 为 kubelet 创建 TLS 客户端证书、私钥和 –kubeletconfig 文件。</p><p>注意：kube-controller-manager 需要配置 <code>--cluster-signing-cert-file</code> 和 <code>--cluster-signing-key-file</code>参数，才会为 TLS Bootstrap 创建证书和私钥。</p><h2 id="自动-approve-CSR-请求"><a href="#自动-approve-CSR-请求" class="headerlink" title="自动 approve CSR 请求"></a>自动 approve CSR 请求</h2><p>创建三个 ClusterRoleBinding，分别用于自动 approve client、renew client、renew server 证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; csr-crb.yaml &lt;&lt;EOF</span><br><span class="line"> # Approve all CSRs for the group &quot;system:bootstrappers&quot;</span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: auto-approve-csrs-for-group</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:bootstrappers</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line"> # To let a node of the group &quot;system:nodes&quot; renew its own credentials</span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: node-client-cert-renewal</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:nodes</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line"># A ClusterRole which instructs the CSR approver to approve a node requesting a</span><br><span class="line"># serving cert matching its client cert.</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: approve-node-server-renewal-csr</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;certificates.k8s.io&quot;]</span><br><span class="line">  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]</span><br><span class="line">  verbs: [&quot;create&quot;]</span><br><span class="line">---</span><br><span class="line"> # To let a node of the group &quot;system:nodes&quot; renew its own server credentials</span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: node-server-cert-renewal</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:nodes</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: approve-node-server-renewal-csr</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f csr-crb.yaml</span><br></pre></td></tr></table></figure><ul><li>auto-approve-csrs-for-group：自动 approve node 的第一次 CSR； 注意第一次 CSR 时，请求的 Group 为 system:bootstrappers；</li><li>node-client-cert-renewal：自动 approve node 后续过期的 client 证书，自动生成的证书 Group 为 system:nodes;</li><li>node-server-cert-renewal：自动 approve node 后续过期的 server 证书，自动生成的证书 Group 为 system:nodes;</li></ul><h2 id="手动-approve-server-cert-csr"><a href="#手动-approve-server-cert-csr" class="headerlink" title="手动 approve server cert csr"></a>手动 approve server cert csr</h2><p>基于<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#kubelet-configuration" target="_blank" rel="noopener">安全性考虑</a>，CSR approving controllers 不会自动 approve kubelet server 证书签名请求，需要手动 approve：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get csr</span><br><span class="line">NAME        AGE     REQUESTOR                    CONDITION</span><br><span class="line">csr-5f4vh   9m25s   system:bootstrap:82jfrm      Approved,Issued</span><br><span class="line">csr-5r7j7   6m11s   system:node:zhangjun-k8s03   Pending</span><br><span class="line">csr-5rw7s   9m23s   system:bootstrap:b1f7np      Approved,Issued</span><br><span class="line">csr-9snww   8m3s    system:bootstrap:82jfrm      Approved,Issued</span><br><span class="line">csr-c7z56   6m12s   system:node:zhangjun-k8s02   Pending</span><br><span class="line">csr-j55lh   6m12s   system:node:zhangjun-k8s01   Pending</span><br><span class="line">csr-m29fm   9m25s   system:bootstrap:3gzd53      Approved,Issued</span><br><span class="line">csr-rc8w7   8m3s    system:bootstrap:3gzd53      Approved,Issued</span><br><span class="line">csr-vd52r   8m2s    system:bootstrap:b1f7np      Approved,Issued</span><br><span class="line"></span><br><span class="line">$ kubectl certificate approve csr-5r7j7</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-5r7j7 approved</span><br><span class="line"></span><br><span class="line">$ kubectl certificate approve csr-c7z56</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-c7z56 approved</span><br><span class="line"></span><br><span class="line">$ kubectl certificate approve csr-j55lh</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-j55lh approved</span><br></pre></td></tr></table></figure><h2 id="kubelet-提供的-API-接口"><a href="#kubelet-提供的-API-接口" class="headerlink" title="kubelet 提供的 API 接口"></a>kubelet 提供的 API 接口</h2><ul><li>10248: healthz http 服务；</li><li>10250: https 服务，访问该端口时需要认证和授权（即使访问 /healthz 也需要）；</li><li>未开启只读端口 10255；</li><li>从 K8S v1.10 开始，去除了 <code>--cadvisor-port</code> 参数（默认 4194 端口），不支持访问 cAdvisor UI &amp; API。</li></ul><p>例如执行 <code>kubectl exec -it nginx-ds-5rmws -- sh</code> 命令时，kube-apiserver 会向 kubelet 发送如下请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /exec/default/nginx-ds-5rmws/my-nginx?command=sh&amp;input=1&amp;output=1&amp;tty=1</span><br></pre></td></tr></table></figure><p>kubelet 接收 10250 端口的 https 请求，可以访问如下资源：</p><ul><li>/pods、/runningpods</li><li>/metrics、/metrics/cadvisor、/metrics/probes</li><li>/spec</li><li>/stats、/stats/container</li><li>/logs</li><li>/run/、/exec/, /attach/, /portForward/, /containerLogs/</li></ul><p>详情参考：<a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/server/server.go#L434:3" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/server/server.go#L434:3</a></p><p>由于关闭了匿名认证，同时开启了 webhook 授权，所有访问 10250 端口 https API 的请求都需要被认证和授权。</p><p>预定义的 ClusterRole system:kubelet-api-admin 授予访问 kubelet 所有 API 的权限(kube-apiserver 使用的 kubernetes 证书 User 授予了该权限)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe clusterrole system:kubelet-api-admin</span><br><span class="line">Name:         system:kubelet-api-admin</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate=true</span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources      Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------      -----------------  --------------  -----</span><br><span class="line">  nodes          []                 []              [get list watch proxy]</span><br><span class="line">  nodes/log      []                 []              [*]</span><br><span class="line">  nodes/metrics  []                 []              [*]</span><br><span class="line">  nodes/proxy    []                 []              [*]</span><br><span class="line">  nodes/spec     []                 []              [*]</span><br><span class="line">  nodes/stats    []                 []              [*]</span><br></pre></td></tr></table></figure><h2 id="kubelet-api-认证和授权"><a href="#kubelet-api-认证和授权" class="headerlink" title="kubelet api 认证和授权"></a>kubelet api 认证和授权</h2><p>kubelet 配置了如下认证参数：</p><ul><li>authentication.anonymous.enabled：设置为 false，不允许匿名访问 10250 端口；</li><li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTPs 证书认证；</li><li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li></ul><p>同时配置了如下授权参数：</p><ul><li>authroization.mode=Webhook：开启 RBAC 授权；</li></ul><p>kubelet 收到请求后，使用 clientCAFile 对证书签名进行认证，或者查询 bearer token 是否有效。如果两者都没通过，则拒绝请求，提示 Unauthorized：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ curl -s --cacert /etc/kubernetes/cert/ca.pem https://192.168.6.101:10250/metrics</span><br><span class="line">Unauthorized</span><br><span class="line"></span><br><span class="line">$ curl -s --cacert /etc/kubernetes/cert/ca.pem -H &quot;Authorization: Bearer 123456&quot; https://192.168.6.101:10250/metrics</span><br><span class="line">Unauthorized</span><br></pre></td></tr></table></figure><p>通过认证后，kubelet 使用 SubjectAccessReview API 向 kube-apiserver 发送请求，查询证书或 token 对应的 user、group 是否有操作资源的权限(RBAC)；</p><h3 id="证书认证和授权"><a href="#证书认证和授权" class="headerlink" title="证书认证和授权"></a>证书认证和授权</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ # 权限不足的证书；</span><br><span class="line">$ curl -s --cacert /etc/kubernetes/cert/ca.pem --cert /etc/kubernetes/cert/kube-controller-manager.pem --key /etc/kubernetes/cert/kube-controller-manager-key.pem https://192.168.6.101:10250/metrics</span><br><span class="line">Forbidden (user=system:kube-controller-manager, verb=get, resource=nodes, subresource=metrics)</span><br><span class="line"></span><br><span class="line">$ # 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；</span><br><span class="line">$ curl -s --cacert /etc/kubernetes/cert/ca.pem --cert /opt/k8s/work/admin.pem --key /opt/k8s/work/admin-key.pem https://172.27.137.240:10250/metrics|head</span><br><span class="line"># HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend.</span><br><span class="line"># TYPE apiserver_audit_event_total counter</span><br><span class="line">apiserver_audit_event_total 0</span><br><span class="line"># HELP apiserver_audit_requests_rejected_total Counter of apiserver requests rejected due to an error in audit logging backend.</span><br><span class="line"># TYPE apiserver_audit_requests_rejected_total counter</span><br><span class="line">apiserver_audit_requests_rejected_total 0</span><br><span class="line"># HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.</span><br><span class="line"># TYPE apiserver_client_certificate_expiration_seconds histogram</span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;0&quot;&#125; 0</span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;1800&quot;&#125; 0</span><br></pre></td></tr></table></figure><ul><li><code>--cacert</code>、<code>--cert</code>、<code>--key</code> 的参数值必须是文件路径，如上面的 <code>./admin.pem</code> 不能省略 <code>./</code>，否则返回 <code>401 Unauthorized</code>；</li></ul><h3 id="bear-token-认证和授权"><a href="#bear-token-认证和授权" class="headerlink" title="bear token 认证和授权"></a>bear token 认证和授权</h3><p>创建一个 ServiceAccount，将它和 ClusterRole system:kubelet-api-admin 绑定，从而具有调用 kubelet API 的权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl create sa kubelet-api-test</span><br><span class="line">kubectl create clusterrolebinding kubelet-api-test --clusterrole=system:kubelet-api-admin --serviceaccount=default:kubelet-api-test</span><br><span class="line">SECRET=$(kubectl get secrets | grep kubelet-api-test | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">TOKEN=$(kubectl describe secret $&#123;SECRET&#125; | grep -E &apos;^token&apos; | awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">echo $&#123;TOKEN&#125;</span><br><span class="line">$ curl -s --cacert /etc/kubernetes/cert/ca.pem -H &quot;Authorization: Bearer $&#123;TOKEN&#125;&quot; https://172.27.137.240:10250/metrics|head</span><br><span class="line"># HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend.</span><br><span class="line"># TYPE apiserver_audit_event_total counter</span><br><span class="line">apiserver_audit_event_total 0</span><br><span class="line"># HELP apiserver_audit_requests_rejected_total Counter of apiserver requests rejected due to an error in audit logging backend.</span><br><span class="line"># TYPE apiserver_audit_requests_rejected_total counter</span><br><span class="line">apiserver_audit_requests_rejected_total 0</span><br><span class="line"># HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.</span><br><span class="line"># TYPE apiserver_client_certificate_expiration_seconds histogram</span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;0&quot;&#125; 0</span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=&quot;1800&quot;&#125; 0</span><br></pre></td></tr></table></figure><h1 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h1><h2 id="创建-kube-proxy-证书"><a href="#创建-kube-proxy-证书" class="headerlink" title="创建 kube-proxy 证书"></a>创建 kube-proxy 证书</h2><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>CN：指定该证书的 User 为 <code>system:kube-proxy</code>；</li><li>预定义的 RoleBinding <code>system:node-proxier</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限；</li><li>该证书只会被 kube-proxy 当做 client 证书使用，所以 hosts 字段为空；</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line">ls kube-proxy*</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kubeconfig-文件"><a href="#创建和分发-kubeconfig-文件" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/k8s/work/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate=kube-proxy.pem \</span><br><span class="line">  --client-key=kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><ul><li><code>--embed-certs=true</code>：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl-proxy.kubeconfig 文件中(不加时，写入的是证书文件路径)；</li></ul><p>分发 kubeconfig 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_name in $&#123;NODE_NAMES[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;</span><br><span class="line">    scp kube-proxy.kubeconfig root@$&#123;node_name&#125;:/etc/kubernetes/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-kube-proxy-配置文件"><a href="#创建-kube-proxy-配置文件" class="headerlink" title="创建 kube-proxy 配置文件"></a>创建 kube-proxy 配置文件</h2><p>从 v1.10 开始，kube-proxy <strong>部分参数</strong>可以配置文件中配置。可以使用 <code>--write-config-to</code> 选项生成该配置文件，或者参考 <a href="https://github.com/kubernetes/kubernetes/blob/release-1.14/pkg/proxy/apis/config/types.go" target="_blank" rel="noopener">源代码的注释</a>。</p><p>创建 kube-proxy config 文件模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-proxy-config.yaml.template &lt;&lt;EOF</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">clientConnection:</span><br><span class="line">  burst: 200</span><br><span class="line">  kubeconfig: &quot;/etc/kubernetes/kube-proxy.kubeconfig&quot;</span><br><span class="line">  qps: 100</span><br><span class="line">bindAddress: ##NODE_IP##</span><br><span class="line">healthzBindAddress: ##NODE_IP##:10256</span><br><span class="line">metricsBindAddress: ##NODE_IP##:10249</span><br><span class="line">enableProfiling: true</span><br><span class="line">clusterCIDR: $&#123;CLUSTER_CIDR&#125;</span><br><span class="line">hostnameOverride: ##NODE_NAME##</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">kubeProxyIPTablesConfiguration:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">kubeProxyIPVSConfiguration:</span><br><span class="line">  scheduler: rr</span><br><span class="line">  excludeCIDRs: []</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>bindAddress</code>: 监听地址；</li><li><code>clientConnection.kubeconfig</code>: 连接 apiserver 的 kubeconfig 文件；</li><li><code>clusterCIDR</code>: kube-proxy 根据 <code>--cluster-cidr</code> 判断集群内部和外部流量，指定 <code>--cluster-cidr</code> 或 <code>--masquerade-all</code> 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT；</li><li><code>hostnameOverride</code>: 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 ipvs 规则；</li><li><code>mode</code>: 使用 ipvs 模式；</li></ul><p>为各节点创建和分发 kube-proxy 配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 3; i++ ))</span><br><span class="line">  do </span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;NODE_NAMES[i]&#125;&quot;</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-proxy-config.yaml.template &gt; kube-proxy-config-$&#123;NODE_NAMES[i]&#125;.yaml.template</span><br><span class="line">    scp kube-proxy-config-$&#123;NODE_NAMES[i]&#125;.yaml.template root@$&#123;NODE_NAMES[i]&#125;:/etc/kubernetes/kube-proxy-config.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kube-proxy-systemd-unit-文件"><a href="#创建和分发-kube-proxy-systemd-unit-文件" class="headerlink" title="创建和分发 kube-proxy systemd unit 文件"></a>创建和分发 kube-proxy systemd unit 文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kube-proxy.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-proxy</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-proxy \\</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy-config.yaml \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发 kube-proxy systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_name in $&#123;NODE_NAMES[@]&#125;</span><br><span class="line">  do </span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_name&#125;&quot;</span><br><span class="line">    scp kube-proxy.service root@$&#123;node_name&#125;:/etc/systemd/system/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="启动-kube-proxy-服务"><a href="#启动-kube-proxy-服务" class="headerlink" title="启动 kube-proxy 服务"></a>启动 kube-proxy 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;/kube-proxy&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;modprobe ip_vs_rr&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-proxy &amp;&amp; systemctl restart kube-proxy&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>启动服务前必须先创建工作目录；</li></ul><h2 id="检查启动结果"><a href="#检查启动结果" class="headerlink" title="检查启动结果"></a>检查启动结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-proxy|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code></p><h2 id="查看-ipvs-路由规则"><a href="#查看-ipvs-路由规则" class="headerlink" title="查看 ipvs 路由规则"></a>查看 ipvs 路由规则</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;/usr/sbin/ipvsadm -ln&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;安装依赖包&quot;&gt;&lt;a href=&quot;#安装依赖包&quot; class=&quot;headerlink&quot; title=&quot;安装依赖包&quot;&gt;&lt;/a&gt;安装依赖包&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-controller、schedule</title>
    <link href="https://shenshengkun.github.io/posts/544ccaa2.html"/>
    <id>https://shenshengkun.github.io/posts/544ccaa2.html</id>
    <published>2019-06-05T07:16:01.000Z</published>
    <updated>2019-06-05T08:52:13.176Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kube-controller-manager-集群"><a href="#kube-controller-manager-集群" class="headerlink" title="kube-controller-manager 集群"></a>kube-controller-manager 集群</h1><h2 id="创建-kube-controller-manager-证书和私钥"><a href="#创建-kube-controller-manager-证书和私钥" class="headerlink" title="创建 kube-controller-manager 证书和私钥"></a>创建 kube-controller-manager 证书和私钥</h2><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-controller-manager-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.6.101&quot;,</span><br><span class="line">      &quot;192.168.6.102&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>hosts 列表包含<strong>所有</strong> kube-controller-manager 节点 IP；</li><li>CN 和 O 均为 <code>system:kube-controller-manager</code>，kubernetes 内置的 ClusterRoleBindings <code>system:kube-controller-manager</code> 赋予 kube-controller-manager 工作所需的权限。</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure><p>将生成的证书和私钥分发到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-controller-manager*.pem root@$&#123;node_ip&#125;:/etc/kubernetes/cert/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kubeconfig-文件"><a href="#创建和分发-kubeconfig-文件" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h2><p>kube-controller-manager 使用 kubeconfig 文件访问 apiserver，该文件提供了 apiserver 地址、嵌入的 CA 证书和 kube-controller-manager 证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/k8s/work/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">  --client-certificate=kube-controller-manager.pem \</span><br><span class="line">  --client-key=kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-controller-manager \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig</span><br></pre></td></tr></table></figure><p>分发 kubeconfig 到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-controller-manager.kubeconfig root@$&#123;node_ip&#125;:/etc/kubernetes/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-kube-controller-manager-systemd-unit-模板文件"><a href="#创建-kube-controller-manager-systemd-unit-模板文件" class="headerlink" title="创建 kube-controller-manager systemd unit 模板文件"></a>创建 kube-controller-manager systemd unit 模板文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kube-controller-manager.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-controller-manager</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-controller-manager \\</span><br><span class="line">  --profiling \\</span><br><span class="line">  --cluster-name=kubernetes \\</span><br><span class="line">  --controllers=*,bootstrapsigner,tokencleaner \\</span><br><span class="line">  --kube-api-qps=1000 \\</span><br><span class="line">  --kube-api-burst=2000 \\</span><br><span class="line">  --leader-elect \\</span><br><span class="line">  --use-service-account-credentials\\</span><br><span class="line">  --concurrent-service-syncs=2 \\</span><br><span class="line">  --bind-address=##NODE_IP## \\</span><br><span class="line">  --secure-port=10252 \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/cert/kube-controller-manager.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/cert/kube-controller-manager-key.pem \\</span><br><span class="line">  --port=0 \\</span><br><span class="line">  --authentication-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-allowed-names=&quot;&quot; \\</span><br><span class="line">  --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix=&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers=X-Remote-User \\</span><br><span class="line">  --authorization-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --cluster-signing-cert-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --cluster-signing-key-file=/etc/kubernetes/cert/ca-key.pem \\</span><br><span class="line">  --experimental-cluster-signing-duration=8760h \\</span><br><span class="line">  --horizontal-pod-autoscaler-sync-period=10s \\</span><br><span class="line">  --concurrent-deployment-syncs=10 \\</span><br><span class="line">  --concurrent-gc-syncs=30 \\</span><br><span class="line">  --node-cidr-mask-size=24 \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --pod-eviction-timeout=6m \\</span><br><span class="line">  --terminated-pod-gc-threshold=10000 \\</span><br><span class="line">  --root-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --service-account-private-key-file=/etc/kubernetes/cert/ca-key.pem \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>--port=0</code>：关闭监听非安全端口（http），同时 <code>--address</code> 参数无效，<code>--bind-address</code> 参数有效；</li><li><code>--secure-port=10252</code>、<code>--bind-address=0.0.0.0</code>: 在所有网络接口监听 10252 端口的 https /metrics 请求；</li><li><code>--kubeconfig</code>：指定 kubeconfig 文件路径，kube-controller-manager 使用它连接和验证 kube-apiserver；</li><li><code>--authentication-kubeconfig</code> 和 <code>--authorization-kubeconfig</code>：kube-controller-manager 使用它连接 apiserver，对 client 的请求进行认证和授权。<code>kube-controller-manager</code> 不再使用 <code>--tls-ca-file</code>对请求 https metrics 的 Client 证书进行校验。如果没有配置这两个 kubeconfig 参数，则 client 连接 kube-controller-manager https 端口的请求会被拒绝(提示权限不足)。</li><li><code>--cluster-signing-*-file</code>：签名 TLS Bootstrap 创建的证书；</li><li><code>--experimental-cluster-signing-duration</code>：指定 TLS Bootstrap 证书的有效期；</li><li><code>--root-ca-file</code>：放置到容器 ServiceAccount 中的 CA 证书，用来对 kube-apiserver 的证书进行校验；</li><li><code>--service-account-private-key-file</code>：签名 ServiceAccount 中 Token 的私钥文件，必须和 kube-apiserver 的 <code>--service-account-key-file</code> 指定的公钥文件配对使用；</li><li><code>--service-cluster-ip-range</code> ：指定 Service Cluster IP 网段，必须和 kube-apiserver 中的同名参数一致；</li><li><code>--leader-elect=true</code>：集群运行模式，启用选举功能；被选为 leader 的节点负责处理工作，其它节点为阻塞状态；</li><li><code>--controllers=*,bootstrapsigner,tokencleaner</code>：启用的控制器列表，tokencleaner 用于自动清理过期的 Bootstrap token；</li><li><code>--horizontal-pod-autoscaler-*</code>：custom metrics 相关参数，支持 autoscaling/v2alpha1；</li><li><code>--tls-cert-file</code>、<code>--tls-private-key-file</code>：使用 https 输出 metrics 时使用的 Server 证书和秘钥；</li><li><code>--use-service-account-credentials=true</code>: kube-controller-manager 中各 controller 使用 serviceaccount 访问 kube-apiserver；</li></ul><h2 id="创建和分发-kube-controller-mananger-systemd-unit-文件"><a href="#创建和分发-kube-controller-mananger-systemd-unit-文件" class="headerlink" title="创建和分发 kube-controller-mananger systemd unit 文件"></a>创建和分发 kube-controller-mananger systemd unit 文件</h2><p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 2; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-controller-manager.service.template &gt; kube-controller-manager-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line">ls kube-controller-manager*.service</span><br></pre></td></tr></table></figure><ul><li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP；</li></ul><p>分发到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-controller-manager-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:/etc/systemd/system/kube-controller-manager.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>文件重命名为 kube-controller-manager.service;</li></ul><h2 id="启动-kube-controller-manager-服务"><a href="#启动-kube-controller-manager-服务" class="headerlink" title="启动 kube-controller-manager 服务"></a>启动 kube-controller-manager 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;/kube-controller-manager&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-controller-manager &amp;&amp; systemctl restart kube-controller-manager&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>启动服务前必须先创建工作目录；</li></ul><h2 id="检查服务运行状态"><a href="#检查服务运行状态" class="headerlink" title="检查服务运行状态"></a>检查服务运行状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-controller-manager|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code>，否则查看日志，确认原因：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -u kube-controller-manager</span><br></pre></td></tr></table></figure><h2 id="查看当前的-leader"><a href="#查看当前的-leader" class="headerlink" title="查看当前的 leader"></a>查看当前的 leader</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl get endpoints kube-controller-manager --namespace=kube-system  -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    control-plane.alpha.kubernetes.io/leader: &apos;&#123;&quot;holderIdentity&quot;:&quot;node1_3e3a8815-8698-11e9-87d5-005056b16e40&quot;,&quot;leaseDurationSeconds&quot;:15,&quot;acquireTime&quot;:&quot;2019-06-04T07:14:15Z&quot;,&quot;renewTime&quot;:&quot;2019-06-05T07:22:40Z&quot;,&quot;leaderTransitions&quot;:2&#125;&apos;</span><br><span class="line">  creationTimestamp: &quot;2019-06-04T07:00:39Z&quot;</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  resourceVersion: &quot;124731&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager</span><br><span class="line">  uid: 75e30eec-8696-11e9-b371-005056b1d2de</span><br></pre></td></tr></table></figure><h1 id="kube-scheduler-集群"><a href="#kube-scheduler-集群" class="headerlink" title="kube-scheduler 集群"></a>kube-scheduler 集群</h1><h2 id="创建-kube-scheduler-证书和私钥"><a href="#创建-kube-scheduler-证书和私钥" class="headerlink" title="创建 kube-scheduler 证书和私钥"></a>创建 kube-scheduler 证书和私钥</h2><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.6.101&quot;,</span><br><span class="line">      &quot;192.168.6.102&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>hosts 列表包含<strong>所有</strong> kube-scheduler 节点 IP；</li><li>CN 和 O 均为 <code>system:kube-scheduler</code>，kubernetes 内置的 ClusterRoleBindings <code>system:kube-scheduler</code> 将赋予 kube-scheduler 工作所需的权限；</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br><span class="line">ls kube-scheduler*pem</span><br></pre></td></tr></table></figure><p>将生成的证书和私钥分发到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler*.pem root@$&#123;node_ip&#125;:/etc/kubernetes/cert/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建和分发-kubeconfig-文件-1"><a href="#创建和分发-kubeconfig-文件-1" class="headerlink" title="创建和分发 kubeconfig 文件"></a>创建和分发 kubeconfig 文件</h2><p>kube-scheduler 使用 kubeconfig 文件访问 apiserver，该文件提供了 apiserver 地址、嵌入的 CA 证书和 kube-scheduler 证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/k8s/work/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">  --client-certificate=kube-scheduler.pem \</span><br><span class="line">  --client-key=kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-scheduler \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig</span><br></pre></td></tr></table></figure><p>分发 kubeconfig 到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler.kubeconfig root@$&#123;node_ip&#125;:/etc/kubernetes/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-kube-scheduler-配置文件"><a href="#创建-kube-scheduler-配置文件" class="headerlink" title="创建 kube-scheduler 配置文件"></a>创建 kube-scheduler 配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt;kube-scheduler.yaml.template &lt;&lt;EOF</span><br><span class="line">apiVersion: kubescheduler.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeSchedulerConfiguration</span><br><span class="line">bindTimeoutSeconds: 600</span><br><span class="line">clientConnection:</span><br><span class="line">  burst: 200</span><br><span class="line">  kubeconfig: &quot;/etc/kubernetes/kube-scheduler.kubeconfig&quot;</span><br><span class="line">  qps: 100</span><br><span class="line">enableContentionProfiling: false</span><br><span class="line">enableProfiling: true</span><br><span class="line">hardPodAffinitySymmetricWeight: 1</span><br><span class="line">healthzBindAddress: ##NODE_IP##:10251</span><br><span class="line">leaderElection:</span><br><span class="line">  leaderElect: true</span><br><span class="line">metricsBindAddress: ##NODE_IP##:10251</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>--kubeconfig</code>：指定 kubeconfig 文件路径，kube-scheduler 使用它连接和验证 kube-apiserver；</li><li><code>--leader-elect=true</code>：集群运行模式，启用选举功能；被选为 leader 的节点负责处理工作，其它节点为阻塞状态；</li></ul><p>替换模板文件中的变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-scheduler.yaml.template &gt; kube-scheduler-$&#123;NODE_IPS[i]&#125;.yaml</span><br><span class="line">  done</span><br><span class="line">ls kube-scheduler*.yaml</span><br></pre></td></tr></table></figure><ul><li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP；</li></ul><p>分发 kube-scheduler 配置文件到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler-$&#123;node_ip&#125;.yaml root@$&#123;node_ip&#125;:/etc/kubernetes/kube-scheduler.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>重命名为 kube-scheduler.yaml;</li></ul><h2 id="创建-kube-scheduler-systemd-unit-模板文件"><a href="#创建-kube-scheduler-systemd-unit-模板文件" class="headerlink" title="创建 kube-scheduler systemd unit 模板文件"></a>创建 kube-scheduler systemd unit 模板文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-scheduler.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-scheduler</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-scheduler \\</span><br><span class="line">  --config=/etc/kubernetes/kube-scheduler.yaml \\</span><br><span class="line">  --bind-address=##NODE_IP## \\</span><br><span class="line">  --secure-port=10259 \\</span><br><span class="line">  --port=0 \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/cert/kube-scheduler.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/cert/kube-scheduler-key.pem \\</span><br><span class="line">  --authentication-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-allowed-names=&quot;&quot; \\</span><br><span class="line">  --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix=&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers=X-Remote-User \\</span><br><span class="line">  --authorization-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">StartLimitInterval=0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="为各节点创建和分发-kube-scheduler-systemd-unit-文件"><a href="#为各节点创建和分发-kube-scheduler-systemd-unit-文件" class="headerlink" title="为各节点创建和分发 kube-scheduler systemd unit 文件"></a>为各节点创建和分发 kube-scheduler systemd unit 文件</h2><p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 2; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-scheduler.service.template &gt; kube-scheduler-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line">ls kube-scheduler*.service</span><br></pre></td></tr></table></figure><p>分发 systemd unit 文件到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:/etc/systemd/system/kube-scheduler.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>重命名为 kube-scheduler.service；</li></ul><h2 id="启动-kube-scheduler-服务"><a href="#启动-kube-scheduler-服务" class="headerlink" title="启动 kube-scheduler 服务"></a>启动 kube-scheduler 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;/kube-scheduler&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-scheduler &amp;&amp; systemctl restart kube-scheduler&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>启动服务前必须先创建工作目录；</li></ul><h2 id="检查服务运行状态-1"><a href="#检查服务运行状态-1" class="headerlink" title="检查服务运行状态"></a>检查服务运行状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-scheduler|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code></p><h2 id="查看当前的-leader-1"><a href="#查看当前的-leader-1" class="headerlink" title="查看当前的 leader"></a>查看当前的 leader</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl get endpoints kube-scheduler --namespace=kube-system  -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    control-plane.alpha.kubernetes.io/leader: &apos;&#123;&quot;holderIdentity&quot;:&quot;node1_b23eda23-8698-11e9-b281-005056b16e40&quot;,&quot;leaseDurationSeconds&quot;:15,&quot;acquireTime&quot;:&quot;2019-06-04T07:17:00Z&quot;,&quot;renewTime&quot;:&quot;2019-06-05T07:31:12Z&quot;,&quot;leaderTransitions&quot;:1&#125;&apos;</span><br><span class="line">  creationTimestamp: &quot;2019-06-04T07:07:02Z&quot;</span><br><span class="line">  name: kube-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  resourceVersion: &quot;125460&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler</span><br><span class="line">  uid: 5a3888a1-8697-11e9-b371-005056b1d2de</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;kube-controller-manager-集群&quot;&gt;&lt;a href=&quot;#kube-controller-manager-集群&quot; class=&quot;headerlink&quot; title=&quot;kube-controller-manager 集群&quot;&gt;&lt;/a&gt;kube-con
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-apiserver集群</title>
    <link href="https://shenshengkun.github.io/posts/863q77b5.html"/>
    <id>https://shenshengkun.github.io/posts/863q77b5.html</id>
    <published>2019-06-05T06:54:01.000Z</published>
    <updated>2019-06-05T08:52:01.693Z</updated>
    
    <content type="html"><![CDATA[<h1 id="nginx代理"><a href="#nginx代理" class="headerlink" title="nginx代理"></a>nginx代理</h1><h2 id="基于-nginx-代理的-kube-apiserver-高可用方案"><a href="#基于-nginx-代理的-kube-apiserver-高可用方案" class="headerlink" title="基于 nginx 代理的 kube-apiserver 高可用方案"></a>基于 nginx 代理的 kube-apiserver 高可用方案</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 控制节点的 kube-controller-manager、kube-scheduler 是多实例部署，所以只要有一个实例正常，就可以保证高可用；</span><br><span class="line">- 集群内的 Pod 使用 K8S 服务域名 kubernetes 访问 kube-apiserver， kube-dns 会自动解析出多个 kube-apiserver 节点的 IP，所以也是高可用的；</span><br><span class="line">- 在每个节点起一个 nginx 进程，后端对接多个 apiserver 实例，nginx 对它们做健康检查和负载均衡；</span><br><span class="line">- kubelet、kube-proxy、controller-manager、scheduler 通过本地的 nginx（监听 127.0.0.1）访问 kube-apiserver，从而实现 kube-apiserver 的高可用；</span><br></pre></td></tr></table></figure><h2 id="下载和编译-nginx"><a href="#下载和编译-nginx" class="headerlink" title="下载和编译 nginx"></a>下载和编译 nginx</h2><p>下载源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">wget http://nginx.org/download/nginx-1.15.3.tar.gz</span><br><span class="line">tar -xzvf nginx-1.15.3.tar.gz</span><br></pre></td></tr></table></figure><p>配置编译参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work/nginx-1.15.3</span><br><span class="line">mkdir nginx-prefix</span><br><span class="line">./configure --with-stream --without-http --prefix=$(pwd)/nginx-prefix --without-http_uwsgi_module --without-http_scgi_module --without-http_fastcgi_module</span><br></pre></td></tr></table></figure><ul><li><code>--with-stream</code>：开启 4 层透明转发(TCP Proxy)功能；</li><li><code>--without-xxx</code>：关闭所有其他功能，这样生成的动态链接二进制程序依赖最小；</li></ul><p>编译和安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work/nginx-1.15.3</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h2 id="安装和部署-nginx"><a href="#安装和部署-nginx" class="headerlink" title="安装和部署 nginx"></a>安装和部署 nginx</h2><p>创建目录结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    mkdir -p /opt/k8s/kube-nginx/&#123;conf,logs,sbin&#125;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>拷贝二进制程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp /opt/k8s/work/nginx-1.15.3/nginx-prefix/sbin/nginx  root@$&#123;node_ip&#125;:/opt/k8s/kube-nginx/sbin/kube-nginx</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod a+x /opt/k8s/kube-nginx/sbin/*&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /opt/k8s/kube-nginx/&#123;conf,logs,sbin&#125;&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>重命名二进制文件为 kube-nginx；</li></ul><p>配置 nginx，开启 4 层透明转发功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-nginx.conf &lt;&lt;EOF</span><br><span class="line">worker_processes 1;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">    upstream backend &#123;</span><br><span class="line">        hash $remote_addr consistent;</span><br><span class="line">        server 192.168.6.101:6443        max_fails=3 fail_timeout=30s;</span><br><span class="line">        server 192.168.6.102:6443        max_fails=3 fail_timeout=30s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 127.0.0.1:8443;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">        proxy_pass backend;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-nginx.conf  root@$&#123;node_ip&#125;:/opt/k8s/kube-nginx/conf/kube-nginx.conf</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="配置-systemd-unit-文件，启动服务"><a href="#配置-systemd-unit-文件，启动服务" class="headerlink" title="配置 systemd unit 文件，启动服务"></a>配置 systemd unit 文件，启动服务</h2><p>配置 kube-nginx systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; kube-nginx.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=kube-apiserver nginx proxy</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStartPre=/opt/k8s/kube-nginx/sbin/kube-nginx -c /opt/k8s/kube-nginx/conf/kube-nginx.conf -p /opt/k8s/kube-nginx -t</span><br><span class="line">ExecStart=/opt/k8s/kube-nginx/sbin/kube-nginx -c /opt/k8s/kube-nginx/conf/kube-nginx.conf -p /opt/k8s/kube-nginx</span><br><span class="line">ExecReload=/opt/k8s/kube-nginx/sbin/kube-nginx -c /opt/k8s/kube-nginx/conf/kube-nginx.conf -p /opt/k8s/kube-nginx -s reload</span><br><span class="line">PrivateTmp=true</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-nginx.service  root@$&#123;node_ip&#125;:/etc/systemd/system/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>启动 kube-nginx 服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-nginx &amp;&amp; systemctl restart kube-nginx&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h1 id="apiserver集群"><a href="#apiserver集群" class="headerlink" title="apiserver集群"></a>apiserver集群</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="下载最新版本二进制文件"><a href="#下载最新版本二进制文件" class="headerlink" title="下载最新版本二进制文件"></a>下载最新版本二进制文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">wget https://dl.k8s.io/v1.14.2/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">cd kubernetes</span><br><span class="line">tar -xzvf  kubernetes-src.tar.gz</span><br></pre></td></tr></table></figure><p>将二进制文件拷贝到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kubernetes/server/bin/&#123;apiextensions-apiserver,cloud-controller-manager,kube-apiserver,kube-controller-manager,kube-proxy,kube-scheduler,kubeadm,kubectl,kubelet,mounter&#125; root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-kubernetes-证书和私钥"><a href="#创建-kubernetes-证书和私钥" class="headerlink" title="创建 kubernetes 证书和私钥"></a>创建 kubernetes 证书和私钥</h2><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kubernetes-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.6.101&quot;,</span><br><span class="line">    &quot;192.168.6.102&quot;,</span><br><span class="line">    &quot;$&#123;CLUSTER_KUBERNETES_SVC_IP&#125;&quot;,</span><br><span class="line">    &quot;kubernetes&quot;,</span><br><span class="line">    &quot;kubernetes.default&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster.local.&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>hosts 字段指定授权使用该证书的 <strong>IP 和域名列表</strong>，这里列出了 master 节点 IP、kubernetes 服务的 IP 和域名；</li><li>kubernetes 服务 IP 是 apiserver 自动创建的，一般是 <code>--service-cluster-ip-range</code> 参数指定的网段的<strong>第一个IP</strong>，后续可以通过下面命令获取：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl get svc kubernetes</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.254.0.1   &lt;none&gt;        443/TCP   24h</span><br></pre></td></tr></table></figure><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes</span><br><span class="line">ls kubernetes*pem</span><br></pre></td></tr></table></figure><p>将生成的证书和私钥文件拷贝到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/kubernetes/cert&quot;</span><br><span class="line">    scp kubernetes*.pem root@$&#123;node_ip&#125;:/etc/kubernetes/cert/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建加密配置文件"><a href="#创建加密配置文件" class="headerlink" title="创建加密配置文件"></a>创建加密配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; encryption-config.yaml &lt;&lt;EOF</span><br><span class="line">kind: EncryptionConfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">resources:</span><br><span class="line">  - resources:</span><br><span class="line">      - secrets</span><br><span class="line">    providers:</span><br><span class="line">      - aescbc:</span><br><span class="line">          keys:</span><br><span class="line">            - name: key1</span><br><span class="line">              secret: $&#123;ENCRYPTION_KEY&#125;</span><br><span class="line">      - identity: &#123;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>将加密配置文件拷贝到 master 节点的 <code>/etc/kubernetes</code> 目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp encryption-config.yaml root@$&#123;node_ip&#125;:/etc/kubernetes/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建审计策略文件"><a href="#创建审计策略文件" class="headerlink" title="创建审计策略文件"></a>创建审计策略文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; audit-policy.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: audit.k8s.io/v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line">  # The following requests were manually identified as high-volume and low-risk, so drop them.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - endpoints</span><br><span class="line">          - services</span><br><span class="line">          - services/status</span><br><span class="line">    users:</span><br><span class="line">      - &apos;system:kube-proxy&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes</span><br><span class="line">          - nodes/status</span><br><span class="line">    userGroups:</span><br><span class="line">      - &apos;system:nodes&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    namespaces:</span><br><span class="line">      - kube-system</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - endpoints</span><br><span class="line">    users:</span><br><span class="line">      - &apos;system:kube-controller-manager&apos;</span><br><span class="line">      - &apos;system:kube-scheduler&apos;</span><br><span class="line">      - &apos;system:serviceaccount:kube-system:endpoint-controller&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - namespaces</span><br><span class="line">          - namespaces/status</span><br><span class="line">          - namespaces/finalize</span><br><span class="line">    users:</span><br><span class="line">      - &apos;system:apiserver&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line"></span><br><span class="line">  # Don&apos;t log HPA fetching metrics.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">    users:</span><br><span class="line">      - &apos;system:kube-controller-manager&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line"></span><br><span class="line">  # Don&apos;t log these read-only URLs.</span><br><span class="line">  - level: None</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">      - &apos;/healthz*&apos;</span><br><span class="line">      - /version</span><br><span class="line">      - &apos;/swagger*&apos;</span><br><span class="line"></span><br><span class="line">  # Don&apos;t log events requests.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - events</span><br><span class="line"></span><br><span class="line">  # node and pod status calls from nodes are high-volume and can be large, don&apos;t log responses for expected updates from nodes</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes/status</span><br><span class="line">          - pods/status</span><br><span class="line">    users:</span><br><span class="line">      - kubelet</span><br><span class="line">      - &apos;system:node-problem-detector&apos;</span><br><span class="line">      - &apos;system:serviceaccount:kube-system:node-problem-detector&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">      - patch</span><br><span class="line"></span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes/status</span><br><span class="line">          - pods/status</span><br><span class="line">    userGroups:</span><br><span class="line">      - &apos;system:nodes&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">      - patch</span><br><span class="line"></span><br><span class="line">  # deletecollection calls can be large, don&apos;t log responses for expected namespace deletions</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    users:</span><br><span class="line">      - &apos;system:serviceaccount:kube-system:namespace-controller&apos;</span><br><span class="line">    verbs:</span><br><span class="line">      - deletecollection</span><br><span class="line"></span><br><span class="line">  # Secrets, ConfigMaps, and TokenReviews can contain sensitive &amp; binary data,</span><br><span class="line">  # so only log at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - secrets</span><br><span class="line">          - configmaps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">        resources:</span><br><span class="line">          - tokenreviews</span><br><span class="line">  # Get repsonses can be large; skip them.</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">      - group: admissionregistration.k8s.io</span><br><span class="line">      - group: apiextensions.k8s.io</span><br><span class="line">      - group: apiregistration.k8s.io</span><br><span class="line">      - group: apps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">      - group: authorization.k8s.io</span><br><span class="line">      - group: autoscaling</span><br><span class="line">      - group: batch</span><br><span class="line">      - group: certificates.k8s.io</span><br><span class="line">      - group: extensions</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">      - group: networking.k8s.io</span><br><span class="line">      - group: policy</span><br><span class="line">      - group: rbac.authorization.k8s.io</span><br><span class="line">      - group: scheduling.k8s.io</span><br><span class="line">      - group: settings.k8s.io</span><br><span class="line">      - group: storage.k8s.io</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">  # Default level for known APIs</span><br><span class="line">  - level: RequestResponse</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">      - group: admissionregistration.k8s.io</span><br><span class="line">      - group: apiextensions.k8s.io</span><br><span class="line">      - group: apiregistration.k8s.io</span><br><span class="line">      - group: apps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">      - group: authorization.k8s.io</span><br><span class="line">      - group: autoscaling</span><br><span class="line">      - group: batch</span><br><span class="line">      - group: certificates.k8s.io</span><br><span class="line">      - group: extensions</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">      - group: networking.k8s.io</span><br><span class="line">      - group: policy</span><br><span class="line">      - group: rbac.authorization.k8s.io</span><br><span class="line">      - group: scheduling.k8s.io</span><br><span class="line">      - group: settings.k8s.io</span><br><span class="line">      - group: storage.k8s.io</span><br><span class="line"></span><br><span class="line">  # Default level for all other requests.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>分发审计策略文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp audit-policy.yaml root@$&#123;node_ip&#125;:/etc/kubernetes/audit-policy.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建后续访问-metrics-server-使用的证书"><a href="#创建后续访问-metrics-server-使用的证书" class="headerlink" title="创建后续访问 metrics-server 使用的证书"></a>创建后续访问 metrics-server 使用的证书</h2><p>创建证书签名请求:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; proxy-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;aggregator&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>CN 名称为 aggregator，需要与 metrics-server 的 <code>--requestheader-allowed-names</code> 参数配置一致，否则访问会被 metrics-server 拒绝；</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/cert/ca-key.pem  \</span><br><span class="line">  -config=/etc/kubernetes/cert/ca-config.json  \</span><br><span class="line">  -profile=kubernetes proxy-client-csr.json | cfssljson -bare proxy-client</span><br><span class="line">ls proxy-client*.pem</span><br></pre></td></tr></table></figure><p>将生成的证书和私钥文件拷贝到所有 master 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp proxy-client*.pem root@$&#123;node_ip&#125;:/etc/kubernetes/cert/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-kube-apiserver-systemd-unit-模板文件"><a href="#创建-kube-apiserver-systemd-unit-模板文件" class="headerlink" title="创建 kube-apiserver systemd unit 模板文件"></a>创建 kube-apiserver systemd unit 模板文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kube-apiserver.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-apiserver</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-apiserver \\</span><br><span class="line">  --advertise-address=##NODE_IP## \\</span><br><span class="line">  --default-not-ready-toleration-seconds=360 \\</span><br><span class="line">  --default-unreachable-toleration-seconds=360 \\</span><br><span class="line">  --feature-gates=DynamicAuditing=true \\</span><br><span class="line">  --max-mutating-requests-inflight=2000 \\</span><br><span class="line">  --max-requests-inflight=4000 \\</span><br><span class="line">  --default-watch-cache-size=200 \\</span><br><span class="line">  --delete-collection-workers=2 \\</span><br><span class="line">  --encryption-provider-config=/etc/kubernetes/encryption-config.yaml \\</span><br><span class="line">  --etcd-cafile=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --etcd-certfile=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --etcd-keyfile=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --etcd-servers=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  --bind-address=##NODE_IP## \\</span><br><span class="line">  --secure-port=6443 \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --insecure-port=0 \\</span><br><span class="line">  --audit-dynamic-configuration \\</span><br><span class="line">  --audit-log-maxage=15 \\</span><br><span class="line">  --audit-log-maxbackup=3 \\</span><br><span class="line">  --audit-log-maxsize=100 \\</span><br><span class="line">  --audit-log-mode=batch \\</span><br><span class="line">  --audit-log-truncate-enabled \\</span><br><span class="line">  --audit-log-batch-buffer-size=20000 \\</span><br><span class="line">  --audit-log-batch-max-size=2 \\</span><br><span class="line">  --audit-log-path=$&#123;K8S_DIR&#125;/kube-apiserver/audit.log \\</span><br><span class="line">  --audit-policy-file=/etc/kubernetes/audit-policy.yaml \\</span><br><span class="line">  --profiling \\</span><br><span class="line">  --anonymous-auth=false \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --enable-bootstrap-token-auth \\</span><br><span class="line">  --requestheader-allowed-names=&quot;&quot; \\</span><br><span class="line">  --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix=&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers=X-Remote-User \\</span><br><span class="line">  --service-account-key-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --authorization-mode=Node,RBAC \\</span><br><span class="line">  --runtime-config=api/all=true \\</span><br><span class="line">  --enable-admission-plugins=NodeRestriction \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --apiserver-count=3 \\</span><br><span class="line">  --event-ttl=168h \\</span><br><span class="line">  --kubelet-certificate-authority=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --kubelet-client-certificate=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --kubelet-client-key=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --kubelet-https=true \\</span><br><span class="line">  --kubelet-timeout=10s \\</span><br><span class="line">  --proxy-client-cert-file=/etc/kubernetes/cert/proxy-client.pem \\</span><br><span class="line">  --proxy-client-key-file=/etc/kubernetes/cert/proxy-client-key.pem \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --service-node-port-range=$&#123;NODE_PORT_RANGE&#125; \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>--advertise-address</code>：apiserver 对外通告的 IP（kubernetes 服务后端节点 IP）；</li><li><code>--default-*-toleration-seconds</code>：设置节点异常相关的阈值；</li><li><code>--max-*-requests-inflight</code>：请求相关的最大阈值；</li><li><code>--etcd-*</code>：访问 etcd 的证书和 etcd 服务器地址；</li><li><code>--experimental-encryption-provider-config</code>：指定用于加密 etcd 中 secret 的配置；</li><li><code>--bind-address</code>： https 监听的 IP，不能为 <code>127.0.0.1</code>，否则外界不能访问它的安全端口 6443；</li><li><code>--secret-port</code>：https 监听端口；</li><li><code>--insecure-port=0</code>：关闭监听 http 非安全端口(8080)；</li><li><code>--tls-*-file</code>：指定 apiserver 使用的证书、私钥和 CA 文件；</li><li><code>--audit-*</code>：配置审计策略和审计日志文件相关的参数；</li><li><code>--client-ca-file</code>：验证 client (kue-controller-manager、kube-scheduler、kubelet、kube-proxy 等)请求所带的证书；</li><li><code>--enable-bootstrap-token-auth</code>：启用 kubelet bootstrap 的 token 认证；</li><li><code>--requestheader-*</code>：kube-apiserver 的 aggregator layer 相关的配置参数，proxy-client &amp; HPA 需要使用；</li><li><code>--requestheader-client-ca-file</code>：用于签名 <code>--proxy-client-cert-file</code> 和 <code>--proxy-client-key-file</code> 指定的证书；在启用了 metric aggregator 时使用；</li><li>如果 <code>--requestheader-allowed-names</code> 不为空，则<code>--proxy-client-cert-file</code> 证书的 CN 必须位于 allowed-names 中，默认为 aggregator;</li><li><code>--service-account-key-file</code>：签名 ServiceAccount Token 的公钥文件，kube-controller-manager 的 <code>--service-account-private-key-file</code> 指定私钥文件，两者配对使用；</li><li><code>--runtime-config=api/all=true</code>： 启用所有版本的 APIs，如 autoscaling/v2alpha1；</li><li><code>--authorization-mode=Node,RBAC</code>、<code>--anonymous-auth=false</code>： 开启 Node 和 RBAC 授权模式，拒绝未授权的请求；</li><li><code>--enable-admission-plugins</code>：启用一些默认关闭的 plugins；</li><li><code>--allow-privileged</code>：运行执行 privileged 权限的容器；</li><li><code>--apiserver-count=3</code>：指定 apiserver 实例的数量；</li><li><code>--event-ttl</code>：指定 events 的保存时间；</li><li><code>--kubelet-*</code>：如果指定，则使用 https 访问 kubelet APIs；需要为证书对应的用户(上面 kubernetes*.pem 证书的用户为 kubernetes) 用户定义 RBAC 规则，否则访问 kubelet API 时提示未授权；</li><li><code>--proxy-client-*</code>：apiserver 访问 metrics-server 使用的证书；</li><li><code>--service-cluster-ip-range</code>： 指定 Service Cluster IP 地址段；</li><li><code>--service-node-port-range</code>： 指定 NodePort 的端口范围；</li></ul><p>如果 kube-apiserver 机器<strong>没有</strong>运行 kube-proxy，则还需要添加 <code>--enable-aggregator-routing=true</code> 参数；</p><p>关于 <code>--requestheader-XXX</code> 相关参数，参考：</p><ul><li><a href="https://github.com/kubernetes-incubator/apiserver-builder/blob/master/docs/concepts/auth.md" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/apiserver-builder/blob/master/docs/concepts/auth.md</a></li><li><a href="https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/" target="_blank" rel="noopener">https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/</a></li></ul><p>注意：requestheader-client-ca-file 指定的 CA 证书，必须具有 client auth and server auth；</p><h2 id="为各节点创建和分发-kube-apiserver-systemd-unit-文件"><a href="#为各节点创建和分发-kube-apiserver-systemd-unit-文件" class="headerlink" title="为各节点创建和分发 kube-apiserver systemd unit 文件"></a>为各节点创建和分发 kube-apiserver systemd unit 文件</h2><p>替换模板文件中的变量，为各节点生成 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 2; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; kube-apiserver.service.template &gt; kube-apiserver-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line">ls kube-apiserver*.service</span><br></pre></td></tr></table></figure><ul><li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP；</li></ul><p>分发生成的 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-apiserver-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:/etc/systemd/system/kube-apiserver.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>文件重命名为 kube-apiserver.service;</li></ul><h2 id="启动-kube-apiserver-服务"><a href="#启动-kube-apiserver-服务" class="headerlink" title="启动 kube-apiserver 服务"></a>启动 kube-apiserver 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;/kube-apiserver&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-apiserver &amp;&amp; systemctl restart kube-apiserver&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>启动服务前必须先创建工作目录；</li></ul><h2 id="检查-kube-apiserver-运行状态"><a href="#检查-kube-apiserver-运行状态" class="headerlink" title="检查 kube-apiserver 运行状态"></a>检查 kube-apiserver 运行状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-apiserver |grep &apos;Active:&apos;&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code></p><h2 id="打印-kube-apiserver-写入-etcd-的数据"><a href="#打印-kube-apiserver-写入-etcd-的数据" class="headerlink" title="打印 kube-apiserver 写入 etcd 的数据"></a>打印 kube-apiserver 写入 etcd 的数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">ETCDCTL_API=3 etcdctl \</span><br><span class="line">    --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">    --cacert=/opt/k8s/work/ca.pem \</span><br><span class="line">    --cert=/opt/k8s/work/etcd.pem \</span><br><span class="line">    --key=/opt/k8s/work/etcd-key.pem \</span><br><span class="line">    get /registry/ --prefix --keys-only</span><br></pre></td></tr></table></figure><h2 id="授予-kube-apiserver-访问-kubelet-API-的权限"><a href="#授予-kube-apiserver-访问-kubelet-API-的权限" class="headerlink" title="授予 kube-apiserver 访问 kubelet API 的权限"></a>授予 kube-apiserver 访问 kubelet API 的权限</h2><p>在执行 kubectl exec、run、logs 等命令时，apiserver 会将请求转发到 kubelet 的 https 端口。这里定义 RBAC 规则，授权 apiserver 使用的证书（kubernetes.pem）用户名（CN：kuberntes）访问 kubelet API 的权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;nginx代理&quot;&gt;&lt;a href=&quot;#nginx代理&quot; class=&quot;headerlink&quot; title=&quot;nginx代理&quot;&gt;&lt;/a&gt;nginx代理&lt;/h1&gt;&lt;h2 id=&quot;基于-nginx-代理的-kube-apiserver-高可用方案&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-flannel网络、kubectl工具</title>
    <link href="https://shenshengkun.github.io/posts/66ae7fg23.html"/>
    <id>https://shenshengkun.github.io/posts/66ae7fg23.html</id>
    <published>2019-06-05T06:30:01.000Z</published>
    <updated>2019-06-05T08:51:51.368Z</updated>
    
    <content type="html"><![CDATA[<h1 id="flannel网络"><a href="#flannel网络" class="headerlink" title="flannel网络"></a>flannel网络</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。 </p><h3 id="flannel在k8s工作"><a href="#flannel在k8s工作" class="headerlink" title="flannel在k8s工作"></a>flannel在k8s工作</h3><p>kubernetes 要求集群内各节点(包括 master 节点)能通过 Pod 网段互联互通。flannel 使用 vxlan 技术为各节点创建一个可以互通的 Pod 网络，使用的端口为 UDP 8472（<strong>需要开放该端口</strong>，如公有云 AWS 等）。</p><p>flanneld 第一次启动时，从 etcd 获取配置的 Pod 网段信息，为本节点分配一个未使用的地址段，然后创建 <code>flannedl.1</code> 网络接口（也可能是其它名称，如 flannel1 等）。</p><p>flannel 将分配给自己的 Pod 网段信息写入 <code>/run/flannel/docker</code> 文件，docker 后续使用这个文件中的环境变量设置 <code>docker0</code> 网桥，从而从这个地址段为本节点的所有 Pod 容器分配 IP。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="下载和分发-flanneld-二进制文件"><a href="#下载和分发-flanneld-二进制文件" class="headerlink" title="下载和分发 flanneld 二进制文件"></a>下载和分发 flanneld 二进制文件</h3><p>从 flannel 的 <a href="https://github.com/coreos/flannel/releases" target="_blank" rel="noopener">release 页面</a> 下载最新版本的安装包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">mkdir flannel</span><br><span class="line">wget https://github.com/coreos/flannel/releases/download/v0.11.0/flannel-v0.11.0-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf flannel-v0.11.0-linux-amd64.tar.gz -C flannel</span><br></pre></td></tr></table></figure><p>分发二进制文件到集群所有节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp flannel/&#123;flanneld,mk-docker-opts.sh&#125; root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h3 id="创建-flannel-证书和私钥"><a href="#创建-flannel-证书和私钥" class="headerlink" title="创建 flannel 证书和私钥"></a>创建 flannel 证书和私钥</h3><p>flanneld 从 etcd 集群存取网段分配信息，而 etcd 集群启用了双向 x509 证书认证，所以需要为 flanneld 生成证书和私钥。</p><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; flanneld-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;flanneld&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空；</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes flanneld-csr.json | cfssljson -bare flanneld</span><br><span class="line">ls flanneld*pem</span><br></pre></td></tr></table></figure><p>将生成的证书和私钥分发到<strong>所有节点</strong>（master 和 worker）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/flanneld/cert&quot;</span><br><span class="line">    scp flanneld*.pem root@$&#123;node_ip&#125;:/etc/flanneld/cert</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h3 id="在etcd-写入集群-Pod-网段信息"><a href="#在etcd-写入集群-Pod-网段信息" class="headerlink" title="在etcd 写入集群 Pod 网段信息"></a>在etcd 写入集群 Pod 网段信息</h3><p>注意：本步骤<strong>只需执行一次</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/opt/k8s/work/ca.pem \</span><br><span class="line">  --cert-file=/opt/k8s/work/flanneld.pem \</span><br><span class="line">  --key-file=/opt/k8s/work/flanneld-key.pem \</span><br><span class="line">  mk $&#123;FLANNEL_ETCD_PREFIX&#125;/config &apos;&#123;&quot;Network&quot;:&quot;&apos;$&#123;CLUSTER_CIDR&#125;&apos;&quot;, &quot;SubnetLen&quot;: 21, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure><ul><li>flanneld <strong>当前版本 (v0.11.0) 不支持 etcd v3</strong>，故使用 etcd v2 API 写入配置 key 和网段数据；</li><li>写入的 Pod 网段 <code>${CLUSTER_CIDR}</code> 地址段（如 /16）必须小于 <code>SubnetLen</code>，必须与 <code>kube-controller-manager</code> 的 <code>--cluster-cidr</code> 参数值一致；</li></ul><h3 id="创建-flanneld-的-systemd"><a href="#创建-flanneld-的-systemd" class="headerlink" title="创建 flanneld 的 systemd"></a>创建 flanneld 的 systemd</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; flanneld.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Flanneld overlay address etcd agent</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=etcd.service</span><br><span class="line">Before=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/opt/k8s/bin/flanneld \\</span><br><span class="line">  -etcd-cafile=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  -etcd-certfile=/etc/flanneld/cert/flanneld.pem \\</span><br><span class="line">  -etcd-keyfile=/etc/flanneld/cert/flanneld-key.pem \\</span><br><span class="line">  -etcd-endpoints=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  -etcd-prefix=$&#123;FLANNEL_ETCD_PREFIX&#125; \\</span><br><span class="line">  -iface=$&#123;IFACE&#125; \\</span><br><span class="line">  -ip-masq</span><br><span class="line">ExecStartPost=/opt/k8s/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">StartLimitInterval=0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">RequiredBy=docker.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>mk-docker-opts.sh</code> 脚本将分配给 flanneld 的 Pod 子网段信息写入 <code>/run/flannel/docker</code> 文件，后续 docker 启动时使用这个文件中的环境变量配置 docker0 网桥；</li><li>flanneld 使用系统缺省路由所在的接口与其它节点通信，对于有多个网络接口（如内网和公网）的节点，可以用 <code>-iface</code> 参数指定通信接口;</li><li>flanneld 运行时需要 root 权限；</li><li><code>-ip-masq</code>: flanneld 为访问 Pod 网络外的流量设置 SNAT 规则，同时将传递给 Docker 的变量 <code>--ip-masq</code>（<code>/run/flannel/docker</code> 文件中）设置为 false，这样 Docker 将不再创建 SNAT 规则； Docker 的 <code>--ip-masq</code> 为 true 时，创建的 SNAT 规则比较“暴力”：将所有本节点 Pod 发起的、访问非 docker0 接口的请求做 SNAT，这样访问其他节点 Pod 的请求来源 IP 会被设置为 flannel.1 接口的 IP，导致目的 Pod 看不到真实的来源 Pod IP。 flanneld 创建的 SNAT 规则比较温和，只对访问非 Pod 网段的请求做 SNAT。</li></ul><h3 id="分发-flanneld-systemd-unit"><a href="#分发-flanneld-systemd-unit" class="headerlink" title="分发 flanneld systemd unit"></a>分发 flanneld systemd unit</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp flanneld.service root@$&#123;node_ip&#125;:/etc/systemd/system/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h3 id="启动-flanneld-服务"><a href="#启动-flanneld-服务" class="headerlink" title="启动 flanneld 服务"></a>启动 flanneld 服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable flanneld &amp;&amp; systemctl restart flanneld&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h3 id="检查启动结果"><a href="#检查启动结果" class="headerlink" title="检查启动结果"></a>检查启动结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status flanneld|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code></p><h3 id="检查分配给各-flanneld-的-Pod-网段信息"><a href="#检查分配给各-flanneld-的-Pod-网段信息" class="headerlink" title="检查分配给各 flanneld 的 Pod 网段信息"></a>检查分配给各 flanneld 的 Pod 网段信息</h3><p>查看集群 Pod 网段(/16)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/cert/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/cert/flanneld-key.pem \</span><br><span class="line">  get $&#123;FLANNEL_ETCD_PREFIX&#125;/config</span><br></pre></td></tr></table></figure><p>输出：</p><p><code>{&quot;Network&quot;:&quot;172.30.0.0/16&quot;, &quot;SubnetLen&quot;: 21, &quot;Backend&quot;: {&quot;Type&quot;: &quot;vxlan&quot;}}</code></p><p>查看已分配的 Pod 子网段列表(/24):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/cert/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/cert/flanneld-key.pem \</span><br><span class="line">  ls $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets</span><br></pre></td></tr></table></figure><p>输出（结果视部署情况而定）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# etcdctl \</span><br><span class="line">&gt;   --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">&gt;   --ca-file=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">&gt;   --cert-file=/etc/flanneld/cert/flanneld.pem \</span><br><span class="line">&gt;   --key-file=/etc/flanneld/cert/flanneld-key.pem \</span><br><span class="line">&gt;   ls $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets</span><br><span class="line">/kubernetes/network/subnets/172.30.168.0-21</span><br><span class="line">/kubernetes/network/subnets/172.30.48.0-21</span><br></pre></td></tr></table></figure><p>查看某一 Pod 网段对应的节点 IP 和 flannel 接口地址:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/cert/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/cert/flanneld-key.pem \</span><br><span class="line">  get $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets/172.30.168.0-21</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# etcdctl \</span><br><span class="line">&gt;   --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">&gt;   --ca-file=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">&gt;   --cert-file=/etc/flanneld/cert/flanneld.pem \</span><br><span class="line">&gt;   --key-file=/etc/flanneld/cert/flanneld-key.pem \</span><br><span class="line">&gt;   get $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets/172.30.168.0-21</span><br><span class="line">&#123;&quot;PublicIP&quot;:&quot;192.168.6.101&quot;,&quot;BackendType&quot;:&quot;vxlan&quot;,&quot;BackendData&quot;:&#123;&quot;VtepMAC&quot;:&quot;62:58:f9:a2:16:73&quot;&#125;&#125;</span><br><span class="line">[root@node1 ~]#</span><br></pre></td></tr></table></figure><h3 id="验证各节点能通过-Pod-网段互通"><a href="#验证各节点能通过-Pod-网段互通" class="headerlink" title="验证各节点能通过 Pod 网段互通"></a>验证各节点能通过 Pod 网段互通</h3><p>在<strong>各节点上部署</strong> flannel 后，检查是否创建了 flannel 接口(名称可能为 flannel0、flannel.0、flannel.1 等)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh $&#123;node_ip&#125; &quot;/usr/sbin/ip addr show flannel.1|grep -w inet&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">&gt;   do</span><br><span class="line">&gt;     echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">&gt;     ssh $&#123;node_ip&#125; &quot;/usr/sbin/ip addr show flannel.1|grep -w inet&quot;</span><br><span class="line">&gt;   done</span><br><span class="line">&gt;&gt;&gt; 192.168.6.101</span><br><span class="line">    inet 172.30.168.0/32 scope global flannel.1</span><br><span class="line">&gt;&gt;&gt; 192.168.6.102</span><br><span class="line">    inet 172.30.48.0/32 scope global flannel.1</span><br></pre></td></tr></table></figure><p>在各节点上 ping 所有 flannel 接口 IP，确保能通 </p><h1 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h1><h2 id="下载和分发-kubectl-二进制文件"><a href="#下载和分发-kubectl-二进制文件" class="headerlink" title="下载和分发 kubectl 二进制文件"></a>下载和分发 kubectl 二进制文件</h2><p>下载和解压：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">wget https://dl.k8s.io/v1.14.2/kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf kubernetes-client-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>分发到所有使用 kubectl 的节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kubernetes/client/bin/kubectl root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="创建-admin-证书和私钥"><a href="#创建-admin-证书和私钥" class="headerlink" title="创建 admin 证书和私钥"></a>创建 admin 证书和私钥</h2><p>kubectl 与 apiserver https 安全端口通信，apiserver 对提供的证书进行认证和授权。</p><p>kubectl 作为集群的管理工具，需要被授予最高权限，这里创建具有<strong>最高权限</strong>的 admin 证书。</p><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>O 为 <code>system:masters</code>，kube-apiserver 收到该证书后将请求的 Group 设置为 system:masters；</li><li>预定义的 ClusterRoleBinding <code>cluster-admin</code> 将 Group <code>system:masters</code> 与 Role <code>cluster-admin</code> 绑定，该 Role 授予<strong>所有 API</strong>的权限；</li><li>该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空；</li></ul><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">  -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">  -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">  -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br></pre></td></tr></table></figure><h2 id="创建-kubeconfig-文件"><a href="#创建-kubeconfig-文件" class="headerlink" title="创建 kubeconfig 文件"></a>创建 kubeconfig 文件</h2><p>kubeconfig 为 kubectl 的配置文件，包含访问 apiserver 的所有信息，如 apiserver 地址、CA 证书和自身使用的证书；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line"></span><br><span class="line"># 设置集群参数</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/k8s/work/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置客户端认证参数</span><br><span class="line">kubectl config set-credentials admin \</span><br><span class="line">  --client-certificate=/opt/k8s/work/admin.pem \</span><br><span class="line">  --client-key=/opt/k8s/work/admin-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置上下文参数</span><br><span class="line">kubectl config set-context kubernetes \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=admin \</span><br><span class="line">  --kubeconfig=kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置默认上下文</span><br><span class="line">kubectl config use-context kubernetes --kubeconfig=kubectl.kubeconfig</span><br></pre></td></tr></table></figure><ul><li><code>--certificate-authority</code>：验证 kube-apiserver 证书的根证书；</li><li><code>--client-certificate</code>、<code>--client-key</code>：刚生成的 <code>admin</code> 证书和私钥，连接 kube-apiserver 时使用；</li><li><code>--embed-certs=true</code>：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl.kubeconfig 文件中(不加时，写入的是证书文件路径，后续拷贝 kubeconfig 到其它机器时，还需要单独拷贝证书文件，不方便。)；</li></ul><h2 id="分发-kubeconfig-文件"><a href="#分发-kubeconfig-文件" class="headerlink" title="分发 kubeconfig 文件"></a>分发 kubeconfig 文件</h2><p>分发到所有使用 <code>kubectl</code> 命令的节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p ~/.kube&quot;</span><br><span class="line">    scp kubectl.kubeconfig root@$&#123;node_ip&#125;:~/.kube/config</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><ul><li>保存的文件名为 <code>~/.kube/config</code>；</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;flannel网络&quot;&gt;&lt;a href=&quot;#flannel网络&quot; class=&quot;headerlink&quot; title=&quot;flannel网络&quot;&gt;&lt;/a&gt;flannel网络&lt;/h1&gt;&lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-etcd集群</title>
    <link href="https://shenshengkun.github.io/posts/7dqa4nb2.html"/>
    <id>https://shenshengkun.github.io/posts/7dqa4nb2.html</id>
    <published>2019-06-04T08:30:01.000Z</published>
    <updated>2019-06-05T08:51:39.964Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>ETCD 是一个高可用的分布式键值数据库，可用于服务发现。ETCD 采用 raft 一致性算法，基于 Go 语言实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">特点</span><br><span class="line"></span><br><span class="line">简单：安装配置使用简单，提供 HTTP API </span><br><span class="line"></span><br><span class="line">安全：支持 SSL 证书 </span><br><span class="line"></span><br><span class="line">可靠：采用 raft 算法，实现分布式系统数据的可用性和一致性</span><br></pre></td></tr></table></figure><p>kubernetes 使用 etcd 存储所有运行数据 </p><h1 id="下载和分发-etcd-二进制文件"><a href="#下载和分发-etcd-二进制文件" class="headerlink" title="下载和分发 etcd 二进制文件"></a>下载和分发 etcd 二进制文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">wget https://github.com/coreos/etcd/releases/download/v3.3.13/etcd-v3.3.13-linux-amd64.tar.gz</span><br><span class="line">tar -xvf etcd-v3.3.13-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>分发二进制文件到集群所有节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp etcd-v3.3.13-linux-amd64/etcd* root@$&#123;node_ip&#125;:/opt/k8s/bin</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h1 id="创建-etcd-证书和私钥"><a href="#创建-etcd-证书和私钥" class="headerlink" title="创建 etcd 证书和私钥"></a>创建 etcd 证书和私钥</h1><p>创建证书签名请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; etcd-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.6.101&quot;,</span><br><span class="line">    &quot;192.168.6.102&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>生成证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -ca=/opt/k8s/work/ca.pem \</span><br><span class="line">    -ca-key=/opt/k8s/work/ca-key.pem \</span><br><span class="line">    -config=/opt/k8s/work/ca-config.json \</span><br><span class="line">    -profile=kubernetes etcd-csr.json | cfssljson -bare etcd</span><br><span class="line">ls etcd*pem</span><br></pre></td></tr></table></figure><p>分发生成的证书和私钥到各 etcd 节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/etcd/cert&quot;</span><br><span class="line">    scp etcd*.pem root@$&#123;node_ip&#125;:/etc/etcd/cert/</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h1 id="创建-etcd-的-systemd"><a href="#创建-etcd-的-systemd" class="headerlink" title="创建 etcd 的 systemd"></a>创建 etcd 的 systemd</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; etcd.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Documentation=https://github.com/coreos</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=$&#123;ETCD_DATA_DIR&#125;</span><br><span class="line">ExecStart=/opt/k8s/bin/etcd \\</span><br><span class="line">  --data-dir=$&#123;ETCD_DATA_DIR&#125; \\</span><br><span class="line">  --wal-dir=$&#123;ETCD_WAL_DIR&#125; \\</span><br><span class="line">  --name=##NODE_NAME## \\</span><br><span class="line">  --cert-file=/etc/etcd/cert/etcd.pem \\</span><br><span class="line">  --key-file=/etc/etcd/cert/etcd-key.pem \\</span><br><span class="line">  --trusted-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --peer-cert-file=/etc/etcd/cert/etcd.pem \\</span><br><span class="line">  --peer-key-file=/etc/etcd/cert/etcd-key.pem \\</span><br><span class="line">  --peer-trusted-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --peer-client-cert-auth \\</span><br><span class="line">  --client-cert-auth \\</span><br><span class="line">  --listen-peer-urls=https://##NODE_IP##:2380 \\</span><br><span class="line">  --initial-advertise-peer-urls=https://##NODE_IP##:2380 \\</span><br><span class="line">  --listen-client-urls=https://##NODE_IP##:2379,http://127.0.0.1:2379 \\</span><br><span class="line">  --advertise-client-urls=https://##NODE_IP##:2379 \\</span><br><span class="line">  --initial-cluster-token=etcd-cluster-0 \\</span><br><span class="line">  --initial-cluster=$&#123;ETCD_NODES&#125; \\</span><br><span class="line">  --initial-cluster-state=new \\</span><br><span class="line">  --auto-compaction-mode=periodic \\</span><br><span class="line">  --auto-compaction-retention=1 \\</span><br><span class="line">  --max-request-bytes=33554432 \\</span><br><span class="line">  --quota-backend-bytes=6442450944 \\</span><br><span class="line">  --heartbeat-interval=250 \\</span><br><span class="line">  --election-timeout=2000</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>WorkingDirectory</code>、<code>--data-dir</code>：指定工作目录和数据目录为 <code>${ETCD_DATA_DIR}</code>，需在启动服务前创建这个目录；</li><li><code>--wal-dir</code>：指定 wal 目录，为了提高性能，一般使用 SSD 或者和 <code>--data-dir</code> 不同的磁盘；</li><li><code>--name</code>：指定节点名称，当 <code>--initial-cluster-state</code> 值为 <code>new</code> 时，<code>--name</code> 的参数值必须位于 <code>--initial-cluster</code> 列表中；</li><li><code>--cert-file</code>、<code>--key-file</code>：etcd server 与 client 通信时使用的证书和私钥；</li><li><code>--trusted-ca-file</code>：签名 client 证书的 CA 证书，用于验证 client 证书；</li><li><code>--peer-cert-file</code>、<code>--peer-key-file</code>：etcd 与 peer 通信使用的证书和私钥；</li><li><code>--peer-trusted-ca-file</code>：签名 peer 证书的 CA 证书，用于验证 peer 证书；</li></ul><p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for (( i=0; i &lt; 2; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s/##NODE_NAME##/$&#123;NODE_NAMES[i]&#125;/&quot; -e &quot;s/##NODE_IP##/$&#123;NODE_IPS[i]&#125;/&quot; etcd.service.template &gt; etcd-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line">ls *.service</span><br></pre></td></tr></table></figure><p>分发生成的 systemd unit 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp etcd-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:/etc/systemd/system/etcd.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h1 id="启动-etcd-服务"><a href="#启动-etcd-服务" class="headerlink" title="启动 etcd 服务"></a>启动 etcd 服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;ETCD_DATA_DIR&#125; $&#123;ETCD_WAL_DIR&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable etcd &amp;&amp; systemctl restart etcd &quot; &amp;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="检查结果"><a href="#检查结果" class="headerlink" title="检查结果"></a>检查结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status etcd|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><p>确保状态为 <code>active (running)</code>，否则查看日志，确认原因：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -u etcd</span><br></pre></td></tr></table></figure><h2 id="验证服务状态"><a href="#验证服务状态" class="headerlink" title="验证服务状态"></a>验证服务状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ETCDCTL_API=3 /opt/k8s/bin/etcdctl \</span><br><span class="line">    --endpoints=https://$&#123;node_ip&#125;:2379 \</span><br><span class="line">    --cacert=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">    --cert=/etc/etcd/cert/etcd.pem \</span><br><span class="line">    --key=/etc/etcd/cert/etcd-key.pem endpoint health</span><br><span class="line">  done</span><br></pre></td></tr></table></figure><h2 id="结果显示"><a href="#结果显示" class="headerlink" title="结果显示"></a>结果显示</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">&gt;   do</span><br><span class="line">&gt;     echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">&gt;     ETCDCTL_API=3 /opt/k8s/bin/etcdctl \</span><br><span class="line">&gt;     --endpoints=https://$&#123;node_ip&#125;:2379 \</span><br><span class="line">&gt;     --cacert=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">&gt;     --cert=/etc/etcd/cert/etcd.pem \</span><br><span class="line">&gt;     --key=/etc/etcd/cert/etcd-key.pem endpoint health</span><br><span class="line">&gt;   done</span><br><span class="line">&gt;&gt;&gt; 192.168.6.101</span><br><span class="line">https://192.168.6.101:2379 is healthy: successfully committed proposal: took = 2.45561ms</span><br><span class="line">&gt;&gt;&gt; 192.168.6.102</span><br><span class="line">https://192.168.6.102:2379 is healthy: successfully committed proposal: took = 3.898134ms</span><br></pre></td></tr></table></figure><h2 id="查看当前的-leader"><a href="#查看当前的-leader" class="headerlink" title="查看当前的 leader"></a>查看当前的 leader</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">ETCDCTL_API=3 /opt/k8s/bin/etcdctl \</span><br><span class="line">  -w table --cacert=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">  --cert=/etc/etcd/cert/etcd.pem \</span><br><span class="line">  --key=/etc/etcd/cert/etcd-key.pem \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; endpoint status</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# ETCDCTL_API=3 /opt/k8s/bin/etcdctl \</span><br><span class="line">&gt;   -w table --cacert=/etc/kubernetes/cert/ca.pem \</span><br><span class="line">&gt;   --cert=/etc/etcd/cert/etcd.pem \</span><br><span class="line">&gt;   --key=/etc/etcd/cert/etcd-key.pem \</span><br><span class="line">&gt;   --endpoints=$&#123;ETCD_ENDPOINTS&#125; endpoint status</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">| https://192.168.6.101:2379 | 77fff77a6e7d24c5 |  3.3.13 |  864 kB |      true |         8 |      41721 |</span><br><span class="line">| https://192.168.6.102:2379 |  e82e7402173c61e |  3.3.13 |  872 kB |     false |         8 |      41721 |</span><br><span class="line">+----------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br></pre></td></tr></table></figure><p>可以看到6.101为leader</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;ETCD 是一个高可用的分布式键值数据库，可用于服务发现。ETCD 采用 raft 一致性算法，基于 Go 语言实现。&lt;/p&gt;
&lt;figur
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-cfssl证书</title>
    <link href="https://shenshengkun.github.io/posts/8d664qf5.html"/>
    <id>https://shenshengkun.github.io/posts/8d664qf5.html</id>
    <published>2019-06-04T08:10:01.000Z</published>
    <updated>2019-06-05T08:51:30.034Z</updated>
    
    <content type="html"><![CDATA[<h1 id="k8s证书的三种方式"><a href="#k8s证书的三种方式" class="headerlink" title="k8s证书的三种方式"></a>k8s证书的三种方式</h1><ul><li>cfssl</li><li>easyrsa</li><li>openssl</li></ul><p>本文使用cfssl签发证书</p><h1 id="安装-cfssl-工具集"><a href="#安装-cfssl-工具集" class="headerlink" title="安装 cfssl 工具集"></a>安装 cfssl 工具集</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/k8s/cert &amp;&amp; cd /opt/k8s</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 /opt/k8s/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">mv cfssljson_linux-amd64 /opt/k8s/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl-certinfo_linux-amd64 /opt/k8s/bin/cfssl-certinfo</span><br><span class="line"></span><br><span class="line">chmod +x /opt/k8s/bin/*</span><br><span class="line">export PATH=/opt/k8s/bin:$PATH</span><br></pre></td></tr></table></figure><h1 id="创建根证书-CA"><a href="#创建根证书-CA" class="headerlink" title="创建根证书 (CA)"></a>创建根证书 (CA)</h1><p>CA 证书是集群所有节点共享的，<strong>只需要创建一个 CA 证书</strong>，后续创建的所有证书都由它签名。 </p><h2 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h2><p>CA 配置文件用于配置根证书的使用场景 (profile) 和具体参数 (usage，过期时间、服务端认证、客户端认证、加密等)，后续在签名其它证书时需要指定特定场景。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><code>signing</code>：表示该证书可用于签名其它证书，生成的 <code>ca.pem</code> 证书中 <code>CA=TRUE</code>；</li><li><code>server auth</code>：表示 client 可以用该该证书对 server 提供的证书进行验证；</li><li><code>client auth</code>：表示 server 可以用该该证书对 client 提供的证书进行验证；</li></ul><h2 id="创建证书签名请求文件"><a href="#创建证书签名请求文件" class="headerlink" title="创建证书签名请求文件"></a>创建证书签名请求文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="生成-CA-证书和私钥"><a href="#生成-CA-证书和私钥" class="headerlink" title="生成 CA 证书和私钥"></a>生成 CA 证书和私钥</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br></pre></td></tr></table></figure><h1 id="分发证书文件"><a href="#分发证书文件" class="headerlink" title="分发证书文件"></a>分发证书文件</h1><p>将生成的 CA 证书、秘钥文件、配置文件拷贝到<strong>所有节点</strong>的 <code>/etc/kubernetes/cert</code> 目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p /etc/kubernetes/cert&quot;</span><br><span class="line">    scp ca*.pem ca-config.json root@$&#123;node_ip&#125;:/etc/kubernetes/cert</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;k8s证书的三种方式&quot;&gt;&lt;a href=&quot;#k8s证书的三种方式&quot; class=&quot;headerlink&quot; title=&quot;k8s证书的三种方式&quot;&gt;&lt;/a&gt;k8s证书的三种方式&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;cfssl&lt;/li&gt;
&lt;li&gt;easyrsa&lt;/li&gt;
&lt;li&gt;
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s1.14集群部署-系统初始化</title>
    <link href="https://shenshengkun.github.io/posts/9c775ab5.html"/>
    <id>https://shenshengkun.github.io/posts/9c775ab5.html</id>
    <published>2019-06-04T08:01:01.000Z</published>
    <updated>2019-06-05T08:51:18.826Z</updated>
    
    <content type="html"><![CDATA[<h1 id="K8s环境准备"><a href="#K8s环境准备" class="headerlink" title="K8s环境准备"></a>K8s环境准备</h1><h2 id="本次安装版本"><a href="#本次安装版本" class="headerlink" title="本次安装版本"></a>本次安装版本</h2><ul><li>Kubernetes 1.14.2</li><li>Docker 18.09.6-ce</li><li>Etcd 3.3.13</li><li>Flanneld 0.11.0</li></ul><h2 id="机器"><a href="#机器" class="headerlink" title="机器"></a>机器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.6.101 node1</span><br><span class="line"></span><br><span class="line">192.168.6.102 node2</span><br></pre></td></tr></table></figure><p>其中node1，node2做master集群，也都是node节点</p><h2 id="主机名"><a href="#主机名" class="headerlink" title="主机名"></a>主机名</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname node1</span><br><span class="line">hostnamectl set-hostname node2</span><br><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">192.168.6.101 node1</span><br><span class="line">192.168.6.102 node2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="免秘钥"><a href="#免秘钥" class="headerlink" title="免秘钥"></a>免秘钥</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：在node1上操作即可</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id root@node1</span><br><span class="line">ssh-copy-id root@node2</span><br></pre></td></tr></table></figure><h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><p>以下操作均在所有机器操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget unzip net-tools</span><br></pre></td></tr></table></figure><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure><h2 id="关闭-swap-分区"><a href="#关闭-swap-分区" class="headerlink" title="关闭 swap 分区"></a>关闭 swap 分区</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">sed -i &apos;/ swap / s/^\(.*\)$/#\1/g&apos; /etc/fstab</span><br></pre></td></tr></table></figure><h2 id="关闭-SELinux"><a href="#关闭-SELinux" class="headerlink" title="关闭 SELinux"></a>关闭 SELinux</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &apos;s/^SELINUX=.*/SELINUX=disabled/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure><h2 id="加载内核并优化"><a href="#加载内核并优化" class="headerlink" title="加载内核并优化"></a>加载内核并优化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">modprobe ip_vs_rr</span><br><span class="line">modprobe br_netfilter</span><br><span class="line">cat &gt; kubernetes.conf &lt;&lt;EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.ipv4.tcp_tw_recycle=0</span><br><span class="line">vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它</span><br><span class="line">vm.overcommit_memory=1 # 不检查物理内存是否够用</span><br><span class="line">vm.panic_on_oom=0 # 开启 OOM</span><br><span class="line">fs.inotify.max_user_instances=8192</span><br><span class="line">fs.inotify.max_user_watches=1048576</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line">EOF</span><br><span class="line">cp kubernetes.conf  /etc/sysctl.d/kubernetes.conf</span><br><span class="line">sysctl -p /etc/sysctl.d/kubernetes.conf</span><br></pre></td></tr></table></figure><h2 id="ntp"><a href="#ntp" class="headerlink" title="ntp"></a>ntp</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure><h2 id="创建相关目录"><a href="#创建相关目录" class="headerlink" title="创建相关目录"></a>创建相关目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p  /opt/k8s/&#123;bin,work&#125; /etc/&#123;kubernetes,etcd&#125;/cert</span><br></pre></td></tr></table></figure><h1 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h1><p>CentOS 7.x 系统自带的 3.10.x 内核存在一些 Bugs，导致运行的 Docker、Kubernetes 不稳定，例如：</p><ol><li>高版本的 docker(1.13 以后) 启用了 3.10 kernel 实验支持的 kernel memory account 功能(无法关闭)，当节点压力大如频繁启动和停止容器时会导致 cgroup memory leak；</li><li>网络设备引用计数泄漏，会导致类似于报错：”kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1”;</li></ol><p>解决方案如下：</p><ol><li>升级内核到 4.4.X 以上；</li><li>或者，手动编译内核，disable CONFIG_MEMCG_KMEM 特性；</li><li>或者，安装修复了该问题的 Docker 18.09.1 及以上的版本。但由于 kubelet 也会设置 kmem（它 vendor 了 runc），所以需要重新编译 kubelet 并指定 GOFLAGS=”-tags=nokmem”；</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone --branch v1.14.1 --single-branch --depth 1 https://github.com/kubernetes/kubernetes</span><br><span class="line">cd kubernetes</span><br><span class="line">KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&quot;-tags=nokmem&quot;</span><br></pre></td></tr></table></figure><p>这里采用升级内核的解决办法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line"># 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再安装一次！</span><br><span class="line">yum --enablerepo=elrepo-kernel install -y kernel-lt</span><br><span class="line"># 设置开机从新内核启动</span><br><span class="line">grub2-set-default 0</span><br></pre></td></tr></table></figure><p>安装内核源文件（可选，在升级完内核并重启机器后执行）:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># yum erase kernel-headers</span><br><span class="line">yum --enablerepo=elrepo-kernel install kernel-lt-devel-$(uname -r) kernel-lt-headers-$(uname -r)</span><br></pre></td></tr></table></figure><h1 id="设置配置参数脚本"><a href="#设置配置参数脚本" class="headerlink" title="设置配置参数脚本"></a>设置配置参数脚本</h1><h2 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cat environment.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#!/usr/bin/bash</span><br><span class="line"></span><br><span class="line"># 生成 EncryptionConfig 所需的加密 key</span><br><span class="line">export ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)</span><br><span class="line"></span><br><span class="line"># 集群各机器 IP 数组</span><br><span class="line">export NODE_IPS=(192.168.6.101 192.168.6.102)</span><br><span class="line"></span><br><span class="line"># 集群各 IP 对应的主机名数组</span><br><span class="line">export NODE_NAMES=(node1 node2)</span><br><span class="line"></span><br><span class="line"># etcd 集群服务地址列表</span><br><span class="line">export ETCD_ENDPOINTS=&quot;https://192.168.6.101:2379,https://192.168.6.102:2379&quot;</span><br><span class="line"></span><br><span class="line"># etcd 集群间通信的 IP 和端口</span><br><span class="line">export ETCD_NODES=&quot;node1=https://192.168.6.101:2380,node2=https://192.168.6.102:2380&quot;</span><br><span class="line"></span><br><span class="line"># kube-apiserver 的反向代理(kube-nginx)地址端口</span><br><span class="line">export KUBE_APISERVER=&quot;https://127.0.0.1:8443&quot;</span><br><span class="line"></span><br><span class="line"># 节点间互联网络接口名称</span><br><span class="line">export IFACE=&quot;ens160&quot;</span><br><span class="line"></span><br><span class="line"># etcd 数据目录</span><br><span class="line">export ETCD_DATA_DIR=&quot;/data/k8s/etcd/data&quot;</span><br><span class="line"></span><br><span class="line"># etcd WAL 目录，建议是 SSD 磁盘分区，或者和 ETCD_DATA_DIR 不同的磁盘分区</span><br><span class="line">export ETCD_WAL_DIR=&quot;/data/k8s/etcd/wal&quot;</span><br><span class="line"></span><br><span class="line"># k8s 各组件数据目录</span><br><span class="line">export K8S_DIR=&quot;/data/k8s/k8s&quot;</span><br><span class="line"></span><br><span class="line"># docker 数据目录</span><br><span class="line">export DOCKER_DIR=&quot;/data/k8s/docker&quot;</span><br><span class="line"></span><br><span class="line">## 以下参数一般不需要修改</span><br><span class="line"></span><br><span class="line"># TLS Bootstrapping 使用的 Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x | tr -d &apos; &apos; 生成</span><br><span class="line">BOOTSTRAP_TOKEN=&quot;4d8a35f48da304e4433ba0bda5b8ffd1&quot;</span><br><span class="line"></span><br><span class="line"># 最好使用 当前未用的网段 来定义服务网段和 Pod 网段</span><br><span class="line"></span><br><span class="line"># 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 保证)</span><br><span class="line">SERVICE_CIDR=&quot;10.254.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"># Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)</span><br><span class="line">CLUSTER_CIDR=&quot;172.30.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"># 服务端口范围 (NodePort Range)</span><br><span class="line">export NODE_PORT_RANGE=&quot;30000-32767&quot;</span><br><span class="line"></span><br><span class="line"># flanneld 网络配置前缀</span><br><span class="line">export FLANNEL_ETCD_PREFIX=&quot;/kubernetes/network&quot;</span><br><span class="line"></span><br><span class="line"># kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)</span><br><span class="line">export CLUSTER_KUBERNETES_SVC_IP=&quot;10.254.0.1&quot;</span><br><span class="line"></span><br><span class="line"># 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)</span><br><span class="line">export CLUSTER_DNS_SVC_IP=&quot;10.254.0.2&quot;</span><br><span class="line"></span><br><span class="line"># 集群 DNS 域名（末尾不带点号）</span><br><span class="line">export CLUSTER_DNS_DOMAIN=&quot;cluster.local&quot;</span><br><span class="line"></span><br><span class="line"># 将二进制目录 /opt/k8s/bin 加到 PATH 中</span><br><span class="line">export PATH=/opt/k8s/bin:$PATH</span><br></pre></td></tr></table></figure><h2 id="分发到所有节点"><a href="#分发到所有节点" class="headerlink" title="分发到所有节点"></a>分发到所有节点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp environment.sh root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;K8s环境准备&quot;&gt;&lt;a href=&quot;#K8s环境准备&quot; class=&quot;headerlink&quot; title=&quot;K8s环境准备&quot;&gt;&lt;/a&gt;K8s环境准备&lt;/h1&gt;&lt;h2 id=&quot;本次安装版本&quot;&gt;&lt;a href=&quot;#本次安装版本&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>tomcat报SEVERE Error listenerStart</title>
    <link href="https://shenshengkun.github.io/posts/1b8b1cc1.html"/>
    <id>https://shenshengkun.github.io/posts/1b8b1cc1.html</id>
    <published>2019-05-28T09:49:10.000Z</published>
    <updated>2019-05-30T02:29:19.208Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>启动tomcat时报错，错误信息如下： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">org.apache.catalina.core.StandardContext startInternal</span><br><span class="line">SEVERE: Error listenerStart</span><br><span class="line">org.apache.catalina.core.StandardContext startInternal</span><br><span class="line">SEVERE: Context [/projectname] startup failed due to previous errors</span><br></pre></td></tr></table></figure><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>在<code>WEB-INF/classes</code>目录下新建一个文件叫<code>logging.properties</code>，内容如下 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">handlers = org.apache.juli.FileHandler, java.util.logging.ConsoleHandler  </span><br><span class="line">org.apache.juli.FileHandler.level = FINE  </span><br><span class="line">org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs  </span><br><span class="line">org.apache.juli.FileHandler.prefix = error-debug.   </span><br><span class="line">java.util.logging.ConsoleHandler.level = FINE  </span><br><span class="line">java.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter</span><br></pre></td></tr></table></figure><p>之后，重启tomcat查看日志，就可以看到是由于数据库连接或者jdk版本不兼容等原因导致的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;p&gt;启动tomcat时报错，错误信息如下： &lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
      <category term="中间件" scheme="https://shenshengkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s强制删除</title>
    <link href="https://shenshengkun.github.io/posts/267edcc5.html"/>
    <id>https://shenshengkun.github.io/posts/267edcc5.html</id>
    <published>2019-05-27T09:43:01.000Z</published>
    <updated>2019-05-30T02:29:19.201Z</updated>
    
    <content type="html"><![CDATA[<h1 id="可使用kubectl中的强制删除命令"><a href="#可使用kubectl中的强制删除命令" class="headerlink" title="可使用kubectl中的强制删除命令"></a>可使用kubectl中的强制删除命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 删除POD</span><br><span class="line">kubectl delete pod PODNAME --force --grace-period=0</span><br><span class="line"></span><br><span class="line"># 删除NAMESPACE</span><br><span class="line">kubectl delete namespace NAMESPACENAME --force --grace-period=0</span><br></pre></td></tr></table></figure><p>有时候这种方法也删除不掉，可能是之前删除顺序有问题，没有删干净pod，就删除命名空间，导致删除不掉</p><h1 id="直接从ETCD中删除源数据"><a href="#直接从ETCD中删除源数据" class="headerlink" title="直接从ETCD中删除源数据"></a>直接从ETCD中删除源数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 删除default namespace下的pod名为pod-to-be-deleted-0</span><br><span class="line">ETCDCTL_API=3 etcdctl del /registry/pods/default/pod-to-be-deleted-0</span><br><span class="line"></span><br><span class="line"># 删除需要删除的NAMESPACE</span><br><span class="line">etcdctl del /registry/namespaces/NAMESPACENAME</span><br></pre></td></tr></table></figure><h2 id="添加别名"><a href="#添加别名" class="headerlink" title="添加别名"></a>添加别名</h2><p>上面直接etcd删除，是证书直接能找到时候，如果证书配置方式不一样，就需要手动配一下！</p><p>配置别名etcdctl3，添加证书等参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">alias etcdctl3=&apos;docker run --rm -it \</span><br><span class="line">--net host -e ETCDCTL_API=3 \</span><br><span class="line">-v /etc/kubernetes:/etc/kubernetes k8s.gcr.io/etcd:3.3.10 etcdctl \</span><br><span class="line">--cert /etc/kubernetes/pki/etcd/peer.crt \</span><br><span class="line">--key /etc/kubernetes/pki/etcd/peer.key \</span><br><span class="line">--cacert /etc/kubernetes/pki/etcd/ca.crt \</span><br><span class="line">--endpoints https://192.168.3.101:2379,https://192.168.3.102:2379,https://192.168.3.103:2379&apos;</span><br></pre></td></tr></table></figure><p>查询都有哪些daemonsets</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tcdctl3 get /registry/daemonsets/ --prefix --keys-only</span><br><span class="line">/registry/daemonsets/default/testpod</span><br><span class="line">/registry/daemonsets/kube-system/calico-node</span><br><span class="line">/registry/daemonsets/kube-system/kube-proxy</span><br></pre></td></tr></table></figure><p>与kubectl查看的结果一致</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get daemonsets --all-namespaces </span><br><span class="line">NAMESPACE     NAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                 AGE</span><br><span class="line">default       testpod       3         3         3       3            3           &lt;none&gt;                        91m</span><br><span class="line">kube-system   calico-node   3         3         3       3            3           beta.kubernetes.io/os=linux   116m</span><br><span class="line">kube-system   kube-proxy    3         3         3       3            3           &lt;none&gt;                        122m</span><br></pre></td></tr></table></figure><p>在etcd中查询default namespace中的pod</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">etcdctl3 get /registry/pods/default --prefix --keys-only </span><br><span class="line">/registry/pods/default/testpod-5wtb7</span><br><span class="line">/registry/pods/default/testpod-646d8</span><br><span class="line">/registry/pods/default/testpod-t7ps7</span><br></pre></td></tr></table></figure><p>kubectl命令看到结果与etcd中一致</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -l app=fortest</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">testpod-5wtb7   1/1     Running   0          93m</span><br><span class="line">testpod-646d8   1/1     Running   0          93m</span><br><span class="line">testpod-t7ps7   1/1     Running   0          93m</span><br></pre></td></tr></table></figure><p>在etcd中删除pod testpod-t7ps7</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etcdctl3 del /registry/pods/default/testpod-t7ps7    </span><br><span class="line">1</span><br></pre></td></tr></table></figure><p>再次查看pod，发现testpod-t7ps7已经没有了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">testpod-5wtb7   1/1     Running   0          96m</span><br><span class="line">testpod-646d8   1/1     Running   0          96m</span><br><span class="line">testpod-qczvt   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;可使用kubectl中的强制删除命令&quot;&gt;&lt;a href=&quot;#可使用kubectl中的强制删除命令&quot; class=&quot;headerlink&quot; title=&quot;可使用kubectl中的强制删除命令&quot;&gt;&lt;/a&gt;可使用kubectl中的强制删除命令&lt;/h1&gt;&lt;figure c
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>fabric问题汇总</title>
    <link href="https://shenshengkun.github.io/posts/9c5623c7.html"/>
    <id>https://shenshengkun.github.io/posts/9c5623c7.html</id>
    <published>2019-05-22T05:04:10.000Z</published>
    <updated>2019-05-30T02:29:19.211Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><h2 id="fabric测试项目安装问题"><a href="#fabric测试项目安装问题" class="headerlink" title="fabric测试项目安装问题"></a>fabric测试项目安装问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install probuf的时候报的错</span><br><span class="line">fabric依赖的sdk需要依赖c++的编译库，windows也许windows-tools，linux也需要支持的gc++,gc</span><br></pre></td></tr></table></figure><h2 id="fabric-ca-server-存储私钥么"><a href="#fabric-ca-server-存储私钥么" class="headerlink" title="fabric-ca-server 存储私钥么"></a>fabric-ca-server 存储私钥么</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">从mysql中不存储私钥</span><br></pre></td></tr></table></figure><h2 id="启动order遇到问题"><a href="#启动order遇到问题" class="headerlink" title="启动order遇到问题"></a>启动order遇到问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize local MSP: the supplied identity is not valid: x509: certificate signed by unknown authority</span><br><span class="line"></span><br><span class="line">原因：实体的证书不是组织的证书签发的</span><br></pre></td></tr></table></figure><h2 id="docker-compose创建报错"><a href="#docker-compose创建报错" class="headerlink" title="docker-compose创建报错"></a>docker-compose创建报错</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[blocksProvider] DeliverBlocks -&gt; ERRO 039 [vaccinechannel] Got error &amp;&#123;FORBIDDEN&#125;</span><br><span class="line"></span><br><span class="line">解决办法： 需要在组织的msp中增加config.yaml</span><br></pre></td></tr></table></figure><h1 id="应用过程中问题"><a href="#应用过程中问题" class="headerlink" title="应用过程中问题"></a>应用过程中问题</h1><h2 id="Peer或者Orderer不通"><a href="#Peer或者Orderer不通" class="headerlink" title="Peer或者Orderer不通"></a>Peer或者Orderer不通</h2><p>当不通的时候，先确认域名对应的IP是否正确，然后用telnet检查服务端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping peer0.org1.example.com</span><br><span class="line">telnet peer0.org1.example.com 7051</span><br></pre></td></tr></table></figure><p>如果不通，检查一下/etc/hosts中是否设置了域名和IP的对应关系是否正确。</p><p>如果还是不通，看一下系统有没有防火墙，7051端口有没有被防火墙禁止。</p><h2 id="目标Peer上的Docker没有启动，导致合约实例化失败"><a href="#目标Peer上的Docker没有启动，导致合约实例化失败" class="headerlink" title="目标Peer上的Docker没有启动，导致合约实例化失败"></a>目标Peer上的Docker没有启动，导致合约实例化失败</h2><p>实例化合约时出错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./peer.sh chaincode instantiate -o orderer.example.com:7050 --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n demo -v 0.0.1 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;]&#125;&apos; -P &quot;OR(&apos;Org1MSP.member&apos;,&apos;Org2MSP.member&apos;)&quot;</span><br></pre></td></tr></table></figure><p>错误如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Error endorsing chaincode: rpc error: code = Unknown desc = error starting container: Post http://unix.sock/containers/create?name=dev-peer1.org1.example.com-demo-0.0.1: dial unix /var/run/docker.sock: connect: no such file or directory</span><br></pre></td></tr></table></figure><p>这是目标peer上的docker没有启动造成的。</p><h2 id="genesisblock中admin证书错误导致orderer-panic-x509-ECDSA-verification-failure"><a href="#genesisblock中admin证书错误导致orderer-panic-x509-ECDSA-verification-failure" class="headerlink" title="genesisblock中admin证书错误导致orderer panic: x509: ECDSA verification failure"></a>genesisblock中admin证书错误导致orderer panic: x509: ECDSA verification failure</h2><p>orderer在启动的时候报错，直接panic：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-----END CERTIFICATE-----</span><br><span class="line">2018-06-22 14:27:30.462 UTC [orderer/commmon/multichannel] newLedgerResources -&gt; CRIT 04d Error creating channelconfig bundle: initializing channelconfig failed: could not create channel Consortiums sub-group config: setting up the MSP manager failed: the supplied identity is not valid: x509: certificate signed by unknown authority (possibly because of &quot;x509: ECDSA verification failure&quot; while trying to verify candidate authority certificate &quot;ca.org1.example.com&quot;)</span><br><span class="line">panic: Error creating channelconfig bundle: initializing channelconfig failed: could not create channel Consortiums sub-group config: setting up the MSP manager failed: the supplied identity is not valid: x509: certificate signed by unknown authority (possibly because of &quot;x509: ECDSA verification failure&quot; while trying to verify candidate authority certificate &quot;ca.org1.example.com&quot;)</span><br><span class="line"></span><br><span class="line">goroutine 1 [running]:</span><br><span class="line">github.com/hyperledger/fabric/vendor/github.com/op/go-logging.(*Logger).Panicf(0xc4201ee120, 0x108668e, 0x27, 0xc42026af50, 0x1, 0x1)</span><br><span class="line">/w/workspace/fabric-binaries-x86_64/gopath/src/github.com/hyperledger/fabric/vendor/github.com/op/go-logging/logger.go:194 +0x134</span><br><span class="line">github.com/hyperledger/fabric/orderer/common/multichannel.(*Registrar).newLedgerResources(0xc42010a380, 0xc420138840, 0xc420138840)</span><br><span class="line">/w/workspace/fabric-binaries-x86_64/gopath/src/github.com/hyperledger/fabric/orderer/common/multichannel/registrar.go:253 +0x391</span><br></pre></td></tr></table></figure><p>怀疑是创世块的原因，用下面的命令将创始块解开：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./genesisblock</span><br></pre></td></tr></table></figure><p>发现比较奇怪的地方，Org1的Admin证书有两个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;groups&quot;: &#123;</span><br><span class="line">  &quot;Org1MSP&quot;: &#123;</span><br><span class="line">  &quot;mod_policy&quot;: &quot;Admins&quot;,</span><br><span class="line">  ...</span><br><span class="line">  &quot;mod_policy&quot;: &quot;Admins&quot;,</span><br><span class="line">  &quot;value&quot;: &#123;</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">  &quot;admins&quot;: [</span><br><span class="line">  &quot;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNHVENDQWIrZ0F3SUJBZ0lRVXRxQWxlZENzWkErWStWdlZMUTZQakFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTVM1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NUzVsZUdGdGNHeGxMbU52YlRBZUZ3MHhPREEyTWpFd05qVTNNekJhRncweU9EQTJNVGd3TmpVM016QmEKTUZzeEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVI4d0hRWURWUVFEREJaQlpHMXBia0J2Y21jeExtVjRZVzF3YkdVdVkyOXRNRmt3CkV3WUhLb1pJemowQ0FRWUlLb1pJemowREFRY0RRZ0FFRVp3cUhTVmxxRGNKNC9aVSt0YnB5RVBSTkl5ellMdTMKRGlRVUZOMklBZm5vVGhjTjRmY3Y4c2dsdXUxcnpJYUVHSFRFLzd0TC9EdEg2U3Fjd2tOQkthTk5NRXN3RGdZRApWUjBQQVFIL0JBUURBZ2VBTUF3R0ExVWRFd0VCL3dRQ01BQXdLd1lEVlIwakJDUXdJb0FnbkpjYVVLVFlseVJxCjcyckk4QXNINHNVZHB0ZytWY3IvbHkxZlp3QndrOEF3Q2dZSUtvWkl6ajBFQXdJRFNBQXdSUUloQUsvRXh6NlYKRVYwUFl4M1BQbitPMysvODQrdXFEVkZ2Q1ZRUEVNcU1yV3dkQWlBNVVqTDcyb2drTHB3UUtGZ1ptdTJqRmtPWApSVnhpY0htLzZCR3htelFRc1E9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==&quot;,</span><br><span class="line">  &quot;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNGVENDQWJ5Z0F3SUJBZ0lRU3E0VzJ1SEVqbHdXZHdGY21WNUlpekFLQmdncWhrak9QUVFEQWpCek1Rc3cKQ1FZRFZRUUdFd0pWVXpFVE1CRUdBMVVFQ0JNS1EyRnNhV1p2Y201cFlURVdNQlFHQTFVRUJ4TU5VMkZ1SUVaeQpZVzVqYVhOamJ6RVpNQmNHQTFVRUNoTVFiM0puTVM1bGVHRnRjR3hsTG1OdmJURWNNQm9HQTFVRUF4TVRZMkV1CmIzSm5NUzVsZUdGdGNHeGxMbU52YlRBZUZ3MHhPREEyTWpFd056VXdNVEZhRncweU9EQTJNVGd3TnpVd01URmEKTUZneEN6QUpCZ05WQkFZVEFsVlRNUk13RVFZRFZRUUlFd3BEWVd4cFptOXlibWxoTVJZd0ZBWURWUVFIRXcxVApZVzRnUm5KaGJtTnBjMk52TVJ3d0dnWURWUVFERXhOallTNXZjbWN4TG1WNFlXMXdiR1V1WTI5dE1Ga3dFd1lICktvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUVxNHl6K0tqSTR2ZmtObzQ0bWp0Q25HQ2cwLzA3L2Y5VW1sZlEKMlpSZWtHN2lyVm1QY0N6YnRVVEcvTFJjbndVemgyaFMvZkg5cGxvZEM4a1pwSlpXQzZOTk1Fc3dEZ1lEVlIwUApBUUgvQkFRREFnZUFNQXdHQTFVZEV3RUIvd1FDTUFBd0t3WURWUjBqQkNRd0lvQWdPc1NNQ2VqcnBOMnBhNEZSCnBOMVE2eXJkVHJleXNGY0Q1Ym9TcVNzSnFLNHdDZ1lJS29aSXpqMEVBd0lEUndBd1JBSWdCQWo1Q3l2cEFhU0kKaTh4anpVVHZxbUt5dmxSOFFPeExBUTAvVi9jRGpTNENJRVg3V1lnZzYwTFUwTy9LNEpmVVpiQmoyNHRBbTkxcgpkQmczN21IZHZVcSsKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=&quot;</span><br><span class="line">  ],</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>将上面的两大行字符串分别用base64解码得到证书，然后用openssl命令查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;LS0tLS1CRUdJTiBDRVJUSU....tLS0tCg==&quot; |base64 -D &gt;a.cert</span><br><span class="line">openssl x509 -in a.cert -text</span><br></pre></td></tr></table></figure><p>第一个证书正确：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"> Subject: C=US, ST=California, L=San Francisco, CN=Admin@org1.example.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>查看第二行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;LS0tLS1CRUdJTi....tLS0tLQo=&quot; |base64 -D &gt;b.cert</span><br><span class="line">openssl x509 -in b.cert -text</span><br></pre></td></tr></table></figure><p>发现第二个证书是CA证书，不是用户证书！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Subject: C=US, ST=California, L=San Francisco, CN=ca.org1.example.com</span><br></pre></td></tr></table></figure><p>检查生成genesisblock时使用的configtx.yaml文件，发现configtx.yaml中配置的msp目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSPDir: ./certs/peerOrganizations/org1.example.com/msp</span><br></pre></td></tr></table></figure><p>msp的admincerts子目录中，多出了一个ca证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls ./certs/peerOrganizations/org1.example.com/msp/admincerts/</span><br><span class="line">Admin@org1.example.com-cert.pem ca.org1.example.com-cert.pem</span><br></pre></td></tr></table></figure><p>把多出的ca证书删除。</p><h2 id="残留数据导致orderer启动失败"><a href="#残留数据导致orderer启动失败" class="headerlink" title="残留数据导致orderer启动失败"></a>残留数据导致orderer启动失败</h2><p>启动orderer的时候报错，orderer直接panic：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2018-06-21 11:01:47.892 CST [orderer/commmon/multichannel] newLedgerResources -&gt; CRIT 052 Error creating channelconfig bundle: initializing channelconfig failed: could not create channel Orderer sub-group config: setting up the MSP manager failed: the supplied identity is not valid: x509: certificate signed by unknown authority (possibly because of &quot;x509: ECDSA verification failure&quot; while trying to verify candidate authority certificate &quot;ca.example.com&quot;)</span><br><span class="line">panic: Error creating channelconfig bundle: initializing channelconfig failed: could not create channel Orderer sub-group config: setting up the MSP manager failed: the supplied identity is not valid: x509: certificate signed by unknown authority (possibly because of &quot;x509: ECDSA verification failure&quot; while trying to verify candidate authority certificate &quot;ca.example.com&quot;)</span><br></pre></td></tr></table></figure><p>排查发现，部署orderer的机器上以前部署过orderer，并且orderer.yaml中配置的数据路径<code>/opt/app/fabric/orderer/data</code>中残留了以前的数据。</p><p>将/opt/app/fabric/orderer/data中的文件都删除后，问题解决。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;安装部署&quot;&gt;&lt;a href=&quot;#安装部署&quot; class=&quot;headerlink&quot; title=&quot;安装部署&quot;&gt;&lt;/a&gt;安装部署&lt;/h1&gt;&lt;h2 id=&quot;fabric测试项目安装问题&quot;&gt;&lt;a href=&quot;#fabric测试项目安装问题&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="区块链" scheme="https://shenshengkun.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
  </entry>
  
  <entry>
    <title>Prometheus添加验证登录</title>
    <link href="https://shenshengkun.github.io/posts/239bdf86.html"/>
    <id>https://shenshengkun.github.io/posts/239bdf86.html</id>
    <published>2019-05-22T01:38:01.000Z</published>
    <updated>2019-05-30T02:29:19.206Z</updated>
    
    <content type="html"><![CDATA[<h1 id="prometheus添加nginx验证"><a href="#prometheus添加nginx验证" class="headerlink" title="prometheus添加nginx验证"></a>prometheus添加nginx验证</h1><p>Prometheus默认开箱即食，并没有设置认证方式，如果你使用Grafana那就另当别论。</p><p>如果你想直接访问Prometheus并且需要设置个认证，那么通过Nginx反向代理是一个不错的选择。</p><p>本文通过Nginx反向代理增加401认证方式来实现。</p><h2 id="安装apache-htpasswd工具"><a href="#安装apache-htpasswd工具" class="headerlink" title="安装apache-htpasswd工具"></a>安装apache-htpasswd工具</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install httpd-tools</span><br></pre></td></tr></table></figure><h2 id="加密认证密码"><a href="#加密认证密码" class="headerlink" title="加密认证密码"></a>加密认证密码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -cs /usr/local/nginx/conf/401htpasswd sy</span><br></pre></td></tr></table></figure><h2 id="设置Nginx反向代理及401认证"><a href="#设置Nginx反向代理及401认证" class="headerlink" title="设置Nginx反向代理及401认证"></a>设置Nginx反向代理及401认证</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/nginx/conf/vhost</span><br><span class="line">vi demo.conf</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name 192.168.10.177;</span><br><span class="line"> </span><br><span class="line">    location / &#123;</span><br><span class="line">        auth_basic &quot;Prometheus&quot;;</span><br><span class="line">        auth_basic_user_file /usr/local/nginx/conf/401htpasswd;</span><br><span class="line">        proxy_pass http://localhost:9090/;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动nginx；访问192.168.10.177</p><p>正常输入密码后，会看到Prometheus页面，如果提示403则表示账号密码不正确，或者路径配错。 </p><h1 id="加密node-exporter"><a href="#加密node-exporter" class="headerlink" title="加密node_exporter"></a>加密node_exporter</h1><p>node_exporter是Prometheus的一个扩展程序，也是通过go语言编写，同样是开箱即食，主要用来采集服务器上的数据（CPU、内存等等）。 所以为了安全考虑，也需要加密一下。</p><h2 id="Nginx配置如下"><a href="#Nginx配置如下" class="headerlink" title="Nginx配置如下"></a>Nginx配置如下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 19100;</span><br><span class="line">    server_name 你的远程主机IP;</span><br><span class="line"> </span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://localhost:9100/;</span><br><span class="line">        auth_basic &quot;Prometheus&quot;;</span><br><span class="line">        auth_basic_user_file /usr/local/nginx/conf/401htpasswd;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="prometheus配置"><a href="#prometheus配置" class="headerlink" title="prometheus配置"></a>prometheus配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在Prometheus配置文件下面添加以下内容，username是远程服务器认证账号，password为加密密码，此处IP为远程服务器的IP地址，不需要加http。</span><br><span class="line"></span><br><span class="line">- job_name: server</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&apos;IP:19100&apos;]</span><br><span class="line">        labels:</span><br><span class="line">          instance: name</span><br><span class="line">    basic_auth:</span><br><span class="line">      username: sy</span><br><span class="line">      password: 123456</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;prometheus添加nginx验证&quot;&gt;&lt;a href=&quot;#prometheus添加nginx验证&quot; class=&quot;headerlink&quot; title=&quot;prometheus添加nginx验证&quot;&gt;&lt;/a&gt;prometheus添加nginx验证&lt;/h1&gt;&lt;p&gt;Pr
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
  <entry>
    <title>nginx基础整理</title>
    <link href="https://shenshengkun.github.io/posts/8d1c645b.html"/>
    <id>https://shenshengkun.github.io/posts/8d1c645b.html</id>
    <published>2019-05-15T07:40:10.000Z</published>
    <updated>2019-05-30T02:29:19.234Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><blockquote><p>prce(重定向支持)和openssl(https支持，如果不需要https可以不安装。)</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y pcre-devel </span><br><span class="line">yum -y install gcc make gcc-c++ wget</span><br><span class="line">yum -y install openssl openssl-devel</span><br></pre></td></tr></table></figure><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">nginx的所有版本在这里</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#创建存放源码包的目录</span><br><span class="line">[root@nginx ~]# mkdir tools</span><br><span class="line">[root@nginx ~]# cd tools/</span><br><span class="line"> #下载Nginx源码包</span><br><span class="line">[root@nginx tools]# wget http://nginx.org/download/nginx-1.14.2.tar.gz</span><br><span class="line">[root@nginx tools]# ls</span><br><span class="line">nginx-1.14.2.tar.gz</span><br><span class="line"> #解压Nginx源码包</span><br><span class="line">[root@nginx tools]# tar -xf nginx-1.14.2.tar.gz</span><br></pre></td></tr></table></figure><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><p>然后进入目录编译安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> #创建安装的目录</span><br><span class="line">[root@nginx nginx-1.14.2]# mkdir -p /application/nginx</span><br><span class="line">[root@nginx nginx-1.14.2]# ./configure --prefix=/application/nginx</span><br></pre></td></tr></table></figure><p>如果没有error信息，就可以执行下边的安装了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h2 id="nginx测试"><a href="#nginx测试" class="headerlink" title="nginx测试"></a>nginx测试</h2><p>运行下面命令会出现两个结果，一般情况nginx会安装在<code>/usr/local/nginx</code>目录中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/nginx/sbin/</span><br><span class="line">./nginx -t</span><br><span class="line"></span><br><span class="line"># nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok</span><br><span class="line"># nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful</span><br></pre></td></tr></table></figure><h2 id="设置全局nginx命令"><a href="#设置全局nginx命令" class="headerlink" title="设置全局nginx命令"></a>设置全局nginx命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br></pre></td></tr></table></figure><p>将下面内容添加到 <code>~/.bash_profile</code> 文件中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PATH=$PATH:$HOME/bin:/usr/local/nginx/sbin/</span><br><span class="line">export PATH</span><br></pre></td></tr></table></figure><p>运行命令 <strong>source ~/.bash_profile</strong> 让配置立即生效。你就可以全局运行 <code>nginx</code> 命令了。</p><h2 id="开机自启动"><a href="#开机自启动" class="headerlink" title="开机自启动"></a>开机自启动</h2><p><strong>开机自启动方法一：</strong></p><p>编辑 <strong>vi /lib/systemd/system/nginx.service</strong> 文件，没有创建一个 <strong>touch nginx.service</strong> 然后将如下内容根据具体情况进行修改后，添加到nginx.service文件中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=nginx</span><br><span class="line">After=network.target remote-fs.target nss-lookup.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line"></span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=/var/run/nginx.pid</span><br><span class="line">ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf</span><br><span class="line">ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">ExecStop=/bin/kill -s QUIT $MAINPID</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><ul><li><code>[Unit]</code>:服务的说明</li><li><code>Description</code>:描述服务</li><li><code>After</code>:描述服务类别</li><li><code>[Service]</code>服务运行参数的设置</li><li><code>Type=forking</code>是后台运行的形式</li><li><code>ExecStart</code>为服务的具体运行命令</li><li><code>ExecReload</code>为重启命令</li><li><code>ExecStop</code>为停止命令</li><li><code>PrivateTmp=True</code>表示给服务分配独立的临时空间</li></ul><p>注意：<code>[Service]</code>的启动、重启、停止命令全部要求使用绝对路径。</p><p><code>[Install]</code>运行级别下服务安装的相关设置，可设置为多用户，即系统运行级别为<code>3</code>。</p><p>保存退出。</p><p>设置开机启动，使配置生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 启动nginx服务</span><br><span class="line">systemctl start nginx.service</span><br><span class="line"># 停止开机自启动</span><br><span class="line">systemctl disable nginx.service</span><br><span class="line"># 查看服务当前状态</span><br><span class="line">systemctl status nginx.service</span><br><span class="line"># 查看所有已启动的服务</span><br><span class="line">systemctl list-units --type=service</span><br><span class="line"># 重新启动服务</span><br><span class="line">systemctl restart nginx.service</span><br><span class="line"># 设置开机自启动</span><br><span class="line">systemctl enable nginx.service</span><br><span class="line"># 输出下面内容表示成功了</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/nginx.service to /usr/lib/systemd/system/nginx.service.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">systemctl is-enabled servicename.service # 查询服务是否开机启动</span><br><span class="line">systemctl enable *.service # 开机运行服务</span><br><span class="line">systemctl disable *.service # 取消开机运行</span><br><span class="line">systemctl start *.service # 启动服务</span><br><span class="line">systemctl stop *.service # 停止服务</span><br><span class="line">systemctl restart *.service # 重启服务</span><br><span class="line">systemctl reload *.service # 重新加载服务配置文件</span><br><span class="line">systemctl status *.service # 查询服务运行状态</span><br><span class="line">systemctl --failed # 显示启动失败的服务</span><br></pre></td></tr></table></figure><p>注：*代表某个服务的名字，如http的服务名为httpd</p><p><strong>开机自启动方法二：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/rc.local</span><br><span class="line"></span><br><span class="line"># 在 rc.local 文件中，添加下面这条命令</span><br><span class="line">/usr/local/nginx/sbin/nginx start</span><br></pre></td></tr></table></figure><p>如果开机后发现自启动脚本没有执行，你要去确认一下rc.local这个文件的访问权限是否是可执行的，因为rc.local默认是不可执行的。修改rc.local访问权限，增加可执行权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/rc.local是/etc/rc.d/rc.local的软连接，</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>–prefix=<code>&lt;path&gt;</code></td><td>Nginx安装路径。如果没有指定，默认为 /usr/local/nginx。</td></tr><tr><td>–sbin-path=<code>&lt;path&gt;</code></td><td>Nginx可执行文件安装路径。只能安装时指定，如果没有指定，默认为<code>&lt;prefix&gt;</code>/sbin/nginx。</td></tr><tr><td>–conf-path=<code>&lt;path&gt;</code></td><td>在没有给定-c选项下默认的nginx.conf的路径。如果没有指定，默认为<code>&lt;prefix&gt;</code>/conf/nginx.conf。</td></tr><tr><td>–pid-path=<code>&lt;path&gt;</code></td><td>在nginx.conf中没有指定pid指令的情况下，默认的nginx.pid的路径。如果没有指定，默认为 <code>&lt;prefix&gt;</code>/logs/nginx.pid。</td></tr><tr><td>–lock-path=<code>&lt;path&gt;</code></td><td>nginx.lock文件的路径。</td></tr><tr><td>–error-log-path=<code>&lt;path&gt;</code></td><td>在nginx.conf中没有指定error_log指令的情况下，默认的错误日志的路径。如果没有指定，默认为 <code>&lt;prefix&gt;</code>/- logs/error.log。</td></tr><tr><td>–http-log-path=<code>&lt;path&gt;</code></td><td>在nginx.conf中没有指定access_log指令的情况下，默认的访问日志的路径。如果没有指定，默认为 <code>&lt;prefix&gt;</code>/- logs/access.log。</td></tr><tr><td>–user=<code>&lt;user&gt;</code></td><td>在nginx.conf中没有指定user指令的情况下，默认的nginx使用的用户。如果没有指定，默认为 nobody。</td></tr><tr><td>–group=<code>&lt;group&gt;</code></td><td>在nginx.conf中没有指定user指令的情况下，默认的nginx使用的组。如果没有指定，默认为 nobody。</td></tr><tr><td>–builddir=DIR</td><td>指定编译的目录</td></tr><tr><td>–with-rtsig_module</td><td>启用 rtsig 模块</td></tr><tr><td>–with-select_module –without-select_module</td><td>允许或不允许开启SELECT模式，如果 configure 没有找到更合适的模式，比如：kqueue(sun os),epoll (linux kenel 2.6+), rtsig(- 实时信号)或者/dev/poll(一种类似select的模式，底层实现与SELECT基本相 同，都是采用轮训方法) SELECT模式将是默认安装模式</td></tr><tr><td>–with-poll_module –without-poll_module</td><td>Whether or not to enable the poll module. This module is enabled by, default if a more suitable method such as kqueue, epoll, rtsig or /dev/poll is not discovered by configure.</td></tr><tr><td>–with-http_ssl_module</td><td>Enable ngx_http_ssl_module. Enables SSL support and the ability to handle HTTPS requests. Requires OpenSSL. On Debian, this is libssl-dev. 开启HTTP SSL模块，使NGINX可以支持HTTPS请求。这个模块需要已经安装了OPENSSL，在DEBIAN上是libssl</td></tr><tr><td>–with-http_realip_module</td><td>启用 ngx_http_realip_module</td></tr><tr><td>–with-http_addition_module</td><td>启用 ngx_http_addition_module</td></tr><tr><td>–with-http_sub_module</td><td>启用 ngx_http_sub_module</td></tr><tr><td>–with-http_dav_module</td><td>启用 ngx_http_dav_module</td></tr><tr><td>–with-http_flv_module</td><td>启用 ngx_http_flv_module</td></tr><tr><td>–with-http_stub_status_module</td><td>启用 “server status” 页</td></tr><tr><td>–without-http_charset_module</td><td>禁用 ngx_http_charset_module</td></tr><tr><td>–without-http_gzip_module</td><td>禁用 ngx_http_gzip_module. 如果启用，需要 zlib 。</td></tr><tr><td>–without-http_ssi_module</td><td>禁用 ngx_http_ssi_module</td></tr><tr><td>–without-http_userid_module</td><td>禁用 ngx_http_userid_module</td></tr><tr><td>–without-http_access_module</td><td>禁用 ngx_http_access_module</td></tr><tr><td>–without-http_auth_basic_module</td><td>禁用 ngx_http_auth_basic_module</td></tr><tr><td>–without-http_autoindex_module</td><td>禁用 ngx_http_autoindex_module</td></tr><tr><td>–without-http_geo_module</td><td>禁用 ngx_http_geo_module</td></tr><tr><td>–without-http_map_module</td><td>禁用 ngx_http_map_module</td></tr><tr><td>–without-http_referer_module</td><td>禁用 ngx_http_referer_module</td></tr><tr><td>–without-http_rewrite_module</td><td>禁用 ngx_http_rewrite_module. 如果启用需要 PCRE 。</td></tr><tr><td>–without-http_proxy_module</td><td>禁用 ngx_http_proxy_module</td></tr><tr><td>–without-http_fastcgi_module</td><td>禁用 ngx_http_fastcgi_module</td></tr><tr><td>–without-http_memcached_module</td><td>禁用 ngx_http_memcached_module</td></tr><tr><td>–without-http_limit_zone_module</td><td>禁用 ngx_http_limit_zone_module</td></tr><tr><td>–without-http_empty_gif_module</td><td>禁用 ngx_http_empty_gif_module</td></tr><tr><td>–without-http_browser_module</td><td>禁用 ngx_http_browser_module</td></tr><tr><td>–without-http_upstream_ip_hash_module</td><td>禁用 ngx_http_upstream_ip_hash_module</td></tr><tr><td>–with-http_perl_module</td><td>启用 ngx_http_perl_module</td></tr><tr><td>–with-perl_modules_path=PATH</td><td>指定 perl 模块的路径</td></tr><tr><td>–with-perl=PATH</td><td>指定 perl 执行文件的路径</td></tr><tr><td>–http-log-path=PATH</td><td>Set path to the http access log</td></tr><tr><td>–http-client-body-temp-path=PATH</td><td>Set path to the http client request body temporary files</td></tr><tr><td>–http-proxy-temp-path=PATH</td><td>Set path to the http proxy temporary files</td></tr><tr><td>–http-fastcgi-temp-path=PATH</td><td>Set path to the http fastcgi temporary files</td></tr><tr><td>–without-http</td><td>禁用 HTTP server</td></tr><tr><td>–with-mail</td><td>启用 IMAP4/POP3/SMTP 代理模块</td></tr><tr><td>–with-mail_ssl_module</td><td>启用 ngx_mail_ssl_module</td></tr><tr><td>–with-cc=PATH</td><td>指定 C 编译器的路径</td></tr><tr><td>–with-cpp=PATH</td><td>指定 C 预处理器的路径</td></tr><tr><td>–with-cc-opt=OPTIONS</td><td>Additional parameters which will be added to the variable CFLAGS. With the use of the system library PCRE in FreeBSD, it is necessary to indicate –with-cc-opt=”-I /usr/local/include”. If we are using select() and it is necessary to increase the number of file descriptors, then this also can be assigned here: –with-cc-opt=”-D FD_SETSIZE=2048”.</td></tr><tr><td>–with-ld-opt=OPTIONS</td><td>Additional parameters passed to the linker. With the use of the system library PCRE in - FreeBSD, it is necessary to indicate –with-ld-opt=”-L /usr/local/lib”.</td></tr><tr><td>–with-cpu-opt=CPU</td><td>为特定的 CPU 编译，有效的值包括：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, amd64, sparc32, sparc64, ppc64</td></tr><tr><td>–without-pcre</td><td>禁止 PCRE 库的使用。同时也会禁止 HTTP rewrite 模块。在 “location” 配置指令中的正则表达式也需要 PCRE 。</td></tr><tr><td>–with-pcre=DIR</td><td>指定 PCRE 库的源代码的路径。</td></tr><tr><td>–with-pcre-opt=OPTIONS</td><td>Set additional options for PCRE building.</td></tr><tr><td>–with-md5=DIR</td><td>Set path to md5 library sources.</td></tr><tr><td>–with-md5-opt=OPTIONS</td><td>Set additional options for md5 building.</td></tr><tr><td>–with-md5-asm</td><td>Use md5 assembler sources.</td></tr><tr><td>–with-sha1=DIR</td><td>Set path to sha1 library sources.</td></tr><tr><td>–with-sha1-opt=OPTIONS</td><td>Set additional options for sha1 building.</td></tr><tr><td>–with-sha1-asm</td><td>Use sha1 assembler sources.</td></tr><tr><td>–with-zlib=DIR</td><td>Set path to zlib library sources.</td></tr><tr><td>–with-zlib-opt=OPTIONS</td><td>Set additional options for zlib building.</td></tr><tr><td>–with-zlib-asm=CPU</td><td>Use zlib assembler sources optimized for specified CPU, valid values are: pentium, pentiumpro</td></tr><tr><td>–with-openssl=DIR</td><td>Set path to OpenSSL library sources</td></tr><tr><td>–with-openssl-opt=OPTIONS</td><td>Set additional options for OpenSSL building</td></tr><tr><td>–with-debug</td><td>启用调试日志</td></tr><tr><td>–add-module=PATH</td><td>Add in a third-party module found in directory PATH</td></tr></tbody></table><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>在Centos 默认配置文件在 <strong>/usr/local/nginx-1.5.1/conf/nginx.conf</strong> 我们要在这里配置一些文件。nginx.conf是主配置文件，由若干个部分组成，每个大括号<code>{}</code>表示一个部分。每一行指令都由分号结束<code>;</code>，标志着一行的结束。</p><h2 id="常用正则"><a href="#常用正则" class="headerlink" title="常用正则"></a>常用正则</h2><table><thead><tr><th>正则</th><th>说明</th><th>正则</th><th>说明</th></tr></thead><tbody><tr><td><code>.</code></td><td>匹配除换行符以外的任意字符</td><td><code>$</code></td><td>匹配字符串的结束</td></tr><tr><td><code>?</code></td><td>重复0次或1次</td><td><code>{n}</code></td><td>重复n次</td></tr><tr><td><code>+</code></td><td>重复1次或更多次</td><td><code>{n,}</code></td><td>重复n次或更多次</td></tr><tr><td><code>*</code></td><td>重复0次或更多次</td><td><code>[c]</code></td><td>匹配单个字符c</td></tr><tr><td><code>\d</code></td><td>匹配数字</td><td><code>[a-z]</code></td><td>匹配a-z小写字母的任意一个</td></tr><tr><td><code>^</code></td><td>匹配字符串的开始</td><td>-</td><td>-</td></tr></tbody></table><h2 id="全局变量"><a href="#全局变量" class="headerlink" title="全局变量"></a>全局变量</h2><table><thead><tr><th>变量</th><th>说明</th><th>变量</th><th>说明</th></tr></thead><tbody><tr><td>$args</td><td>这个变量等于请求行中的参数，同$query_string</td><td>$remote_port</td><td>客户端的端口。</td></tr><tr><td>$content_length</td><td>请求头中的Content-length字段。</td><td>$remote_user</td><td>已经经过Auth Basic Module验证的用户名。</td></tr><tr><td>$content_type</td><td>请求头中的Content-Type字段。</td><td>$request_filename</td><td>当前请求的文件路径，由root或alias指令与URI请求生成。</td></tr><tr><td>$document_root</td><td>当前请求在root指令中指定的值。</td><td>$scheme</td><td>HTTP方法（如http，https）。</td></tr><tr><td>$host</td><td>请求主机头字段，否则为服务器名称。</td><td>$server_protocol</td><td>请求使用的协议，通常是HTTP/1.0或HTTP/1.1。</td></tr><tr><td>$http_user_agent</td><td>客户端agent信息</td><td>$server_addr</td><td>服务器地址，在完成一次系统调用后可以确定这个值。</td></tr><tr><td>$http_cookie</td><td>客户端cookie信息</td><td>$server_name</td><td>服务器名称。</td></tr><tr><td>$limit_rate</td><td>这个变量可以限制连接速率。</td><td>$server_port</td><td>请求到达服务器的端口号。</td></tr><tr><td>$request_method</td><td>客户端请求的动作，通常为GET或POST。</td><td>$request_uri</td><td>包含请求参数的原始URI，不包含主机名，如：/foo/bar.php?arg=baz。</td></tr><tr><td>$remote_addr</td><td>客户端的IP地址。</td><td>$uri</td><td>不带请求参数的当前URI，$uri不包含主机名，如/foo/bar.html。</td></tr><tr><td>$document_uri</td><td>与$uri相同。</td><td>-</td><td>-</td></tr></tbody></table><p>例如请求：<code>http://localhost:3000/test1/test2/test.php</code></p><p>$host：localhost<br>$server_port：3000<br>$request_uri：/test1/test2/test.php<br>$document_uri：/test1/test2/test.php<br>$document_root：/var/www/html<br>$request_filename：/var/www/html/test1/test2/test.php</p><h2 id="符号参考"><a href="#符号参考" class="headerlink" title="符号参考"></a>符号参考</h2><table><thead><tr><th>符号</th><th>说明</th><th>符号</th><th>说明</th><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>k,K</td><td>千字节</td><td>m,M</td><td>兆字节</td><td>ms</td><td>毫秒</td></tr><tr><td>s</td><td>秒</td><td>m</td><td>分钟</td><td>h</td><td>小时</td></tr><tr><td>d</td><td>日</td><td>w</td><td>周</td><td>M</td><td>一个月, 30天</td></tr></tbody></table><p>例如，”8k”，”1m” 代表字节数计量。<br>例如，”1h 30m”，”1y 6M”。代表 “1小时 30分”，”1年零6个月”。</p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>nginx 的配置系统由一个主配置文件和其他一些辅助的配置文件构成。这些配置文件均是纯文本文件，全部位于 nginx 安装目录下的 conf 目录下。</p><p>指令由 nginx 的各个模块提供，不同的模块会提供不同的指令来实现配置。 指令除了 Key-Value 的形式，还有作用域指令。</p><p>nginx.conf 中的配置信息，根据其逻辑上的意义，对它们进行了分类，也就是分成了多个作用域，或者称之为配置指令上下文。不同的作用域含有一个或者多个配置项。</p><p>下面的这些上下文指令是用的比较多：</p><table><thead><tr><th>Directive</th><th>Description</th><th>Contains Directive</th></tr></thead><tbody><tr><td>main</td><td>nginx 在运行时与具体业务功能（比如 http 服务或者 email 服务代理）无关的一些参数，比如工作进程数，运行的身份等。</td><td>user, worker_processes, error_log, events, http, mail</td></tr><tr><td>http</td><td>与提供 http 服务相关的一些配置参数。例如：是否使用 keepalive 啊，是否使用 gzip 进行压缩等。</td><td>server</td></tr><tr><td>server</td><td>http 服务上支持若干虚拟主机。每个虚拟主机一个对应的 server 配置项，配置项里面包含该虚拟主机相关的配置。在提供 mail 服务的代理时，也可以建立若干 server. 每个 server 通过监听的地址来区分。</td><td>listen, server_name, access_log, location, protocol, proxy, smtp_auth, xclient</td></tr><tr><td>location</td><td>http 服务中，某些特定的 URL 对应的一系列配置项。</td><td>index, root</td></tr><tr><td>mail</td><td>实现 email 相关的 SMTP/IMAP/POP3 代理时，共享的一些配置项（因为可能实现多个代理，工作在多个监听地址上）。</td><td>server, http, imap_capabilities</td></tr><tr><td>include</td><td>以便增强配置文件的可读性，使得部分配置文件可以重新使用。</td><td>-</td></tr><tr><td>valid_referers</td><td>用来校验Http请求头Referer是否有效。</td><td>-</td></tr><tr><td>try_files</td><td>用在server部分，不过最常见的还是用在location部分，它会按照给定的参数顺序进行尝试，第一个被匹配到的将会被使用。</td><td>-</td></tr><tr><td>if</td><td>当在location块中使用if指令，在某些情况下它并不按照预期运行，一般来说避免使用if指令。</td><td>-</td></tr></tbody></table><p>例如我们再 <strong>nginx.conf</strong> 里面引用两个配置 vhost/example.com.conf 和 vhost/gitlab.com.conf 它们都被放在一个我自己新建的目录 vhost 下面。nginx.conf 配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  1;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    #log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">    #                  &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">    #                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    #access_log  logs/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    include  vhost/example.com.conf;</span><br><span class="line">    include  vhost/gitlab.com.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单的配置: example.com.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    #侦听的80端口</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  baidu.com app.baidu.com; # 这里指定域名</span><br><span class="line">    index        index.html index.htm;    # 这里指定默认入口页面</span><br><span class="line">    root /home/www/app.baidu.com;         # 这里指定目录</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="内置预定义变量"><a href="#内置预定义变量" class="headerlink" title="内置预定义变量"></a>内置预定义变量</h2><p>Nginx提供了许多预定义的变量，也可以通过使用set来设置变量。你可以在if中使用预定义变量，也可以将它们传递给代理服务器。以下是一些常见的预定义变量，<a href="http://nginx.org/en/docs/varindex.html" target="_blank" rel="noopener">更多详见</a></p><table><thead><tr><th>变量名称</th><th>值</th></tr></thead><tbody><tr><td>$args_name</td><td>在请求中的name参数</td></tr><tr><td>$args</td><td>所有请求参数</td></tr><tr><td>$query_string</td><td>$args的别名</td></tr><tr><td>$content_length</td><td>请求头Content-Length的值</td></tr><tr><td>$content_type</td><td>请求头Content-Type的值</td></tr><tr><td>$host</td><td>如果当前有Host，则为请求头Host的值；如果没有这个头，那么该值等于匹配该请求的server_name的值</td></tr><tr><td>$remote_addr</td><td>客户端的IP地址</td></tr><tr><td>$request</td><td>完整的请求，从客户端收到，包括Http请求方法、URI、Http协议、头、请求体</td></tr><tr><td>$request_uri</td><td>完整请求的URI，从客户端来的请求，包括参数</td></tr><tr><td>$scheme</td><td>当前请求的协议</td></tr><tr><td>$uri</td><td>当前请求的标准化URI</td></tr></tbody></table><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>反向代理是一个Web服务器，它接受客户端的连接请求，然后将请求转发给上游服务器，并将从服务器得到的结果返回给连接的客户端。下面简单的反向代理的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">server &#123;  </span><br><span class="line">  listen       80;                                                        </span><br><span class="line">  server_name  localhost;                                              </span><br><span class="line">  client_max_body_size 1024M;  # 允许客户端请求的最大单文件字节数</span><br><span class="line"></span><br><span class="line">  location / &#123;</span><br><span class="line">    proxy_pass                         http://localhost:8080;</span><br><span class="line">    proxy_set_header Host              $host:$server_port;</span><br><span class="line">    proxy_set_header X-Forwarded-For   $remote_addr; # HTTP的请求端真实的IP</span><br><span class="line">    proxy_set_header X-Forwarded-Proto $scheme;      # 为了正确地识别实际用户发出的协议是 http 还是 https</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>复杂的配置: gitlab.com.conf。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    #侦听的80端口</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  git.example.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass   http://localhost:3000;</span><br><span class="line">        #以下是一些反向代理的配置可删除</span><br><span class="line">        proxy_redirect             off;</span><br><span class="line">        #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br><span class="line">        proxy_set_header           Host $host;</span><br><span class="line">        client_max_body_size       10m; #允许客户端请求的最大单文件字节数</span><br><span class="line">        client_body_buffer_size    128k; #缓冲区代理缓冲用户端请求的最大字节数</span><br><span class="line">        proxy_connect_timeout      300; #nginx跟后端服务器连接超时时间(代理连接超时)</span><br><span class="line">        proxy_send_timeout         300; #后端服务器数据回传时间(代理发送超时)</span><br><span class="line">        proxy_read_timeout         300; #连接成功后，后端服务器响应时间(代理接收超时)</span><br><span class="line">        proxy_buffer_size          4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br><span class="line">        proxy_buffers              4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置</span><br><span class="line">        proxy_busy_buffers_size    64k; #高负荷下缓冲大小（proxy_buffers*2）</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代理到上游服务器的配置中，最重要的是proxy_pass指令。以下是代理模块中的一些常用指令：</p><table><thead><tr><th>指令</th><th>说明</th></tr></thead><tbody><tr><td>proxy_connect_timeout</td><td>Nginx从接受请求至连接到上游服务器的最长等待时间</td></tr><tr><td>proxy_send_timeout</td><td>后端服务器数据回传时间(代理发送超时)</td></tr><tr><td>proxy_read_timeout</td><td>连接成功后，后端服务器响应时间(代理接收超时)</td></tr><tr><td>proxy_cookie_domain</td><td>替代从上游服务器来的Set-Cookie头的domain属性</td></tr><tr><td>proxy_cookie_path</td><td>替代从上游服务器来的Set-Cookie头的path属性</td></tr><tr><td>proxy_buffer_size</td><td>设置代理服务器（nginx）保存用户头信息的缓冲区大小</td></tr><tr><td>proxy_buffers</td><td>proxy_buffers缓冲区，网页平均在多少k以下</td></tr><tr><td>proxy_set_header</td><td>重写发送到上游服务器头的内容，也可以通过将某个头部的值设置为空字符串，而不发送某个头部的方法实现</td></tr><tr><td>proxy_ignore_headers</td><td>这个指令禁止处理来自代理服务器的应答。</td></tr><tr><td>proxy_intercept_errors</td><td>使nginx阻止HTTP应答代码为400或者更高的应答。</td></tr></tbody></table><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>upstream指令启用一个新的配置区段，在该区段定义一组上游服务器。这些服务器可能被设置不同的权重，也可能出于对服务器进行维护，标记为down。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">upstream gitlab &#123;</span><br><span class="line">    ip_hash;</span><br><span class="line">    # upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span><br><span class="line">    server 192.168.122.11:8081 ;</span><br><span class="line">    server 127.0.0.1:82 weight=3;</span><br><span class="line">    server 127.0.0.1:83 weight=3 down;</span><br><span class="line">    server 127.0.0.1:84 weight=3; max_fails=3  fail_timeout=20s;</span><br><span class="line">    server 127.0.0.1:85 weight=4;;</span><br><span class="line">    keepalive 32;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    #侦听的80端口</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  git.example.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass   http://gitlab;    #在这里设置一个代理，和upstream的名字一样</span><br><span class="line">        #以下是一些反向代理的配置可删除</span><br><span class="line">        proxy_redirect             off;</span><br><span class="line">        #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br><span class="line">        proxy_set_header           Host $host;</span><br><span class="line">        proxy_set_header           X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header           X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        client_max_body_size       10m;  #允许客户端请求的最大单文件字节数</span><br><span class="line">        client_body_buffer_size    128k; #缓冲区代理缓冲用户端请求的最大字节数</span><br><span class="line">        proxy_connect_timeout      300;  #nginx跟后端服务器连接超时时间(代理连接超时)</span><br><span class="line">        proxy_send_timeout         300;  #后端服务器数据回传时间(代理发送超时)</span><br><span class="line">        proxy_read_timeout         300;  #连接成功后，后端服务器响应时间(代理接收超时)</span><br><span class="line">        proxy_buffer_size          4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br><span class="line">        proxy_buffers              4 32k;# 缓冲区，网页平均在32k以下的话，这样设置</span><br><span class="line">        proxy_busy_buffers_size    64k; #高负荷下缓冲大小（proxy_buffers*2）</span><br><span class="line">        proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p><p><strong>负载均衡：</strong></p><p>upstream模块能够使用3种负载均衡算法：轮询、IP哈希、最少连接数。</p><p><strong>轮询：</strong> 默认情况下使用轮询算法，不需要配置指令来激活它，它是基于在队列中谁是下一个的原理确保访问均匀地分布到每个上游服务器；<br><strong>IP哈希：</strong> 通过ip_hash指令来激活，Nginx通过IPv4地址的前3个字节或者整个IPv6地址作为哈希键来实现，同一个IP地址总是能被映射到同一个上游服务器；<br><strong>最少连接数：</strong> 通过least_conn指令来激活，该算法通过选择一个活跃数最少的上游服务器进行连接。如果上游服务器处理能力不同，可以通过给server配置weight权重来说明，该算法将考虑到不同服务器的加权最少连接数。</p><h3 id="RR"><a href="#RR" class="headerlink" title="RR"></a>RR</h3><p><strong>简单配置</strong> ，这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的，也就是说访问不到，但是我们访问 <code>http://localhost</code> 的时候，也不会有问题，会默认跳转到<code>http://localhost:8080</code>具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">upstream test &#123;</span><br><span class="line">    server localhost:8080;</span><br><span class="line">    server localhost:8081;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       81;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">    client_max_body_size 1024M;</span><br><span class="line"> </span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://test;</span><br><span class="line">        proxy_set_header Host $host:$server_port;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>负载均衡的核心代码为</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">upstream test &#123;</span><br><span class="line">    server localhost:8080;</span><br><span class="line">    server localhost:8081;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="权重"><a href="#权重" class="headerlink" title="权重"></a>权重</h3><p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">upstream test &#123;</span><br><span class="line">    server localhost:8080 weight=9;</span><br><span class="line">    server localhost:8081 weight=1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么10次一般只会有1次会访问到8081，而有9次会访问到8080</p><h3 id="ip-hash"><a href="#ip-hash" class="headerlink" title="ip_hash"></a>ip_hash</h3><p>上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream test &#123;</span><br><span class="line">    ip_hash;</span><br><span class="line">    server localhost:8080;</span><br><span class="line">    server localhost:8081;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fair"><a href="#fair" class="headerlink" title="fair"></a>fair</h3><p>这是个第三方模块，按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream backend &#123;</span><br><span class="line">    fair;</span><br><span class="line">    server localhost:8080;</span><br><span class="line">    server localhost:8081;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="url-hash"><a href="#url-hash" class="headerlink" title="url_hash"></a>url_hash</h3><p>这是个第三方模块，按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream backend &#123;</span><br><span class="line">    hash $request_uri;</span><br><span class="line">    hash_method crc32;</span><br><span class="line">    server localhost:8080;</span><br><span class="line">    server localhost:8081;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式，不过fair和url_hash需要安装第三方模块才能使用</p><p><strong>server指令可选参数：</strong></p><ol><li>weight：设置一个服务器的访问权重，数值越高，收到的请求也越多；</li><li>fail_timeout：在这个指定的时间内服务器必须提供响应，如果在这个时间内没有收到响应，那么服务器将会被标记为down状态；</li><li>max_fails：设置在fail_timeout时间之内尝试对一个服务器连接的最大次数，如果超过这个次数，那么服务器将会被标记为down;</li><li>down：标记一个服务器不再接受任何请求；</li><li>backup：一旦其他服务器宕机，那么有该标记的机器将会接收请求。</li></ol><p><strong>keepalive指令：</strong></p><p>Nginx服务器将会为每一个worker进行保持同上游服务器的连接。</p><h2 id="屏蔽ip"><a href="#屏蔽ip" class="headerlink" title="屏蔽ip"></a>屏蔽ip</h2><p>在nginx的配置文件<code>nginx.conf</code>中加入如下配置，可以放到http, server, location, limit_except语句块，需要注意相对路径，本例当中<code>nginx.conf</code>，<code>blocksip.conf</code>在同一个目录中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include blockip.conf;</span><br></pre></td></tr></table></figure><p>在blockip.conf里面输入内容，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">deny 165.91.122.67;</span><br><span class="line"></span><br><span class="line">deny IP;   # 屏蔽单个ip访问</span><br><span class="line">allow IP;  # 允许单个ip访问</span><br><span class="line">deny all;  # 屏蔽所有ip访问</span><br><span class="line">allow all; # 允许所有ip访问</span><br><span class="line">deny 123.0.0.0/8   # 屏蔽整个段即从123.0.0.1到123.255.255.254访问的命令</span><br><span class="line">deny 124.45.0.0/16 # 屏蔽IP段即从123.45.0.1到123.45.255.254访问的命令</span><br><span class="line">deny 123.45.6.0/24 # 屏蔽IP段即从123.45.6.1到123.45.6.254访问的命令</span><br><span class="line"></span><br><span class="line"># 如果你想实现这样的应用，除了几个IP外，其他全部拒绝</span><br><span class="line">allow 1.1.1.1; </span><br><span class="line">allow 1.1.1.2;</span><br><span class="line">deny all;</span><br></pre></td></tr></table></figure><h1 id="第三方模块安装方法"><a href="#第三方模块安装方法" class="headerlink" title="第三方模块安装方法"></a>第三方模块安装方法</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/你的安装目录  --add-module=/第三方模块目录</span><br></pre></td></tr></table></figure><h1 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h1><ul><li><code>permanent</code> 永久性重定向。请求日志中的状态码为301</li><li><code>redirect</code> 临时重定向。请求日志中的状态码为302</li></ul><h2 id="重定向整个网站"><a href="#重定向整个网站" class="headerlink" title="重定向整个网站"></a>重定向整个网站</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    server_name old-site.com</span><br><span class="line">    return 301 $scheme://new-site.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="重定向单页"><a href="#重定向单页" class="headerlink" title="重定向单页"></a>重定向单页</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    location = /oldpage.html &#123;</span><br><span class="line">        return 301 http://example.org/newpage.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="重定向整个子路径"><a href="#重定向整个子路径" class="headerlink" title="重定向整个子路径"></a>重定向整个子路径</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location /old-site &#123;</span><br><span class="line">    rewrite ^/old-site/(.*) http://example.org/new-site/$1 permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><h2 id="内容缓存"><a href="#内容缓存" class="headerlink" title="内容缓存"></a>内容缓存</h2><p>允许浏览器基本上永久地缓存静态内容。 Nginx将为您设置Expires和Cache-Control头信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /static &#123;</span><br><span class="line">    root /data;</span><br><span class="line">    expires max;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要求浏览器永远不会缓存响应（例如用于跟踪请求），请使用-1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location = /empty.gif &#123;</span><br><span class="line">    empty_gif;</span><br><span class="line">    expires -1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">gzip  on;</span><br><span class="line">gzip_buffers 16 8k;</span><br><span class="line">gzip_comp_level 6;</span><br><span class="line">gzip_http_version 1.1;</span><br><span class="line">gzip_min_length 256;</span><br><span class="line">gzip_proxied any;</span><br><span class="line">gzip_vary on;</span><br><span class="line">gzip_types</span><br><span class="line">    text/xml application/xml application/atom+xml application/rss+xml application/xhtml+xml image/svg+xml</span><br><span class="line">    text/javascript application/javascript application/x-javascript</span><br><span class="line">    text/x-json application/json application/x-web-app-manifest+json</span><br><span class="line">    text/css text/plain text/x-component</span><br><span class="line">    font/opentype application/x-font-ttf application/vnd.ms-fontobject</span><br><span class="line">    image/x-icon;</span><br><span class="line">gzip_disable  &quot;msie6&quot;;</span><br></pre></td></tr></table></figure><h2 id="打开文件缓存"><a href="#打开文件缓存" class="headerlink" title="打开文件缓存"></a>打开文件缓存</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">open_file_cache max=1000 inactive=20s;</span><br><span class="line">open_file_cache_valid 30s;</span><br><span class="line">open_file_cache_min_uses 2;</span><br><span class="line">open_file_cache_errors on;</span><br></pre></td></tr></table></figure><h2 id="SSL缓存"><a href="#SSL缓存" class="headerlink" title="SSL缓存"></a>SSL缓存</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssl_session_cache shared:SSL:10m;</span><br><span class="line">ssl_session_timeout 10m;</span><br></pre></td></tr></table></figure><h2 id="上游Keepalive"><a href="#上游Keepalive" class="headerlink" title="上游Keepalive"></a>上游Keepalive</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">upstream backend &#123;</span><br><span class="line">    server 127.0.0.1:8080;</span><br><span class="line">    keepalive 32;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    ...</span><br><span class="line">    location /api/ &#123;</span><br><span class="line">        proxy_pass http://backend;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_set_header Connection &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>使用<code>ngxtop</code>实时解析nginx访问日志，并且将处理结果输出到终端，功能类似于系统命令top。所有示例都读取nginx配置文件的访问日志位置和格式。如果要指定访问日志文件和/或日志格式，请使用-f和-a选项。</p><p>注意：在nginx配置中<code>/usr/local/nginx/conf/nginx.conf</code>日志文件必须是绝对路径。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 安装 ngxtop</span><br><span class="line">pip install ngxtop</span><br><span class="line"></span><br><span class="line"># 实时状态</span><br><span class="line">ngxtop</span><br><span class="line"># 状态为404的前10个请求的路径：</span><br><span class="line">ngxtop top request_path --filter &apos;status == 404&apos;</span><br><span class="line"></span><br><span class="line"># 发送总字节数最多的前10个请求</span><br><span class="line">ngxtop --order-by &apos;avg(bytes_sent) * count&apos;</span><br><span class="line"></span><br><span class="line"># 排名前十位的IP，例如，谁攻击你最多</span><br><span class="line">ngxtop --group-by remote_addr</span><br><span class="line"></span><br><span class="line"># 打印具有4xx或5xx状态的请求，以及status和http referer</span><br><span class="line">ngxtop -i &apos;status &gt;= 400&apos; print request status http_referer</span><br><span class="line"></span><br><span class="line"># 由200个请求路径响应发送的平均正文字节以&apos;foo&apos;开始：</span><br><span class="line">ngxtop avg bytes_sent --filter &apos;status == 200 and request_path.startswith(&quot;foo&quot;)&apos;</span><br><span class="line"></span><br><span class="line"># 使用“common”日志格式从远程机器分析apache访问日志</span><br><span class="line">ssh remote tail -f /var/log/apache2/access.log | ngxtop -f common</span><br></pre></td></tr></table></figure><h1 id="常见使用场景"><a href="#常见使用场景" class="headerlink" title="常见使用场景"></a>常见使用场景</h1><h2 id="跨域问题"><a href="#跨域问题" class="headerlink" title="跨域问题"></a>跨域问题</h2><p>在工作中，有时候会遇到一些接口不支持跨域，这时候可以简单的添加add_headers来支持cors跨域。配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name api.xxx.com;</span><br><span class="line">    </span><br><span class="line">  add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;;</span><br><span class="line">  add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos;;</span><br><span class="line">  add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET,POST,HEAD&apos;;</span><br><span class="line"></span><br><span class="line">  location / &#123;</span><br><span class="line">    proxy_pass http://127.0.0.1:3000;</span><br><span class="line">    proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    proxy_set_header Host  $http_host;    </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面更改头信息，还有一种，使用 <a href="http://nginx.org/en/docs/http/ngx_http_rewrite_module.html" target="_blank" rel="noopener">rewrite</a> 指令重定向URI来解决跨域问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">upstream test &#123;</span><br><span class="line">  server 127.0.0.1:8080;</span><br><span class="line">  server localhost:8081;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name api.xxx.com;</span><br><span class="line">  location / &#123; </span><br><span class="line">    root  html;                   #去请求../html文件夹里的文件</span><br><span class="line">    index  index.html index.htm;  #首页响应地址</span><br><span class="line">  &#125;</span><br><span class="line">  # 用于拦截请求，匹配任何以 /api/开头的地址，</span><br><span class="line">  # 匹配符合以后，停止往下搜索正则。</span><br><span class="line">  location ^~/api/&#123; </span><br><span class="line">    # 代表重写拦截进来的请求，并且只能对域名后边的除去传递的参数外的字符串起作用，</span><br><span class="line">    # 例如www.a.com/proxy/api/msg?meth=1&amp;par=2重写，只对/proxy/api/msg重写。</span><br><span class="line">    # rewrite后面的参数是一个简单的正则 ^/api/(.*)$，</span><br><span class="line">    # $1代表正则中的第一个()，$2代表第二个()的值，以此类推。</span><br><span class="line">    rewrite ^/api/(.*)$ /$1 break;</span><br><span class="line">    </span><br><span class="line">    # 把请求代理到其他主机 </span><br><span class="line">    # 其中 http://www.b.com/ 写法和 http://www.b.com写法的区别如下</span><br><span class="line">    # 如果你的请求地址是他 http://server/html/test.jsp</span><br><span class="line">    # 配置一： http://www.b.com/ 后面有“/” </span><br><span class="line">    #         将反向代理成 http://www.b.com/html/test.jsp 访问</span><br><span class="line">    # 配置一： http://www.b.com 后面没有有“/” </span><br><span class="line">    #         将反向代理成 http://www.b.com/test.jsp 访问</span><br><span class="line">    proxy_pass http://test;</span><br><span class="line"></span><br><span class="line">    # 如果 proxy_pass  URL 是 http://a.xx.com/platform/ 这种情况</span><br><span class="line">    # proxy_cookie_path应该设置成 /platform/ / (注意两个斜杠之间有空格)。</span><br><span class="line">    proxy_cookie_path /platfrom/ /;</span><br><span class="line"></span><br><span class="line">    # http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass_header</span><br><span class="line">    # 设置 Cookie 头通过</span><br><span class="line">    proxy_pass_header Set-Cookie;</span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="跳转到带www的域上面"><a href="#跳转到带www的域上面" class="headerlink" title="跳转到带www的域上面"></a>跳转到带www的域上面</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    # 配置正常的带www的域名</span><br><span class="line">    server_name www.wangchujiang.com;</span><br><span class="line">    root /home/www/wabg/download;</span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files $uri $uri/ /index.html =404;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    # 这个要放到下面，</span><br><span class="line">    # 将不带www的 wangchujiang.com 永久性重定向到  https://www.wangchujiang.com</span><br><span class="line">    server_name wangchujiang.com;</span><br><span class="line">    rewrite ^(.*) https://www.wangchujiang.com$1 permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="代理转发"><a href="#代理转发" class="headerlink" title="代理转发"></a>代理转发</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">upstream server-api&#123;</span><br><span class="line">    # api 代理服务地址</span><br><span class="line">    server 127.0.0.1:3110;    </span><br><span class="line">&#125;</span><br><span class="line">upstream server-resource&#123;</span><br><span class="line">    # 静态资源 代理服务地址</span><br><span class="line">    server 127.0.0.1:3120;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       3111;</span><br><span class="line">    server_name  localhost;      # 这里指定域名</span><br><span class="line">    root /home/www/server-statics;</span><br><span class="line">    # 匹配 api 路由的反向代理到API服务</span><br><span class="line">    location ^~/api/ &#123;</span><br><span class="line">        rewrite ^/(.*)$ /$1 break;</span><br><span class="line">        proxy_pass http://server-api;</span><br><span class="line">    &#125;</span><br><span class="line">    # 假设这里验证码也在API服务中</span><br><span class="line">    location ^~/captcha &#123;</span><br><span class="line">        rewrite ^/(.*)$ /$1 break;</span><br><span class="line">        proxy_pass http://server-api;</span><br><span class="line">    &#125;</span><br><span class="line">    # 假设你的图片资源全部在另外一个服务上面</span><br><span class="line">    location ^~/img/ &#123;</span><br><span class="line">        rewrite ^/(.*)$ /$1 break;</span><br><span class="line">        proxy_pass http://server-resource;</span><br><span class="line">    &#125;</span><br><span class="line">    # 路由在前端，后端没有真实路由，在路由不存在的 404状态的页面返回 /index.html</span><br><span class="line">    # 这个方式使用场景，你在写React或者Vue项目的时候，没有真实路由</span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files $uri $uri/ /index.html =404;</span><br><span class="line">        #                               ^ 空格很重要</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="监控状态信息"><a href="#监控状态信息" class="headerlink" title="监控状态信息"></a>监控状态信息</h2><p>通过 <code>nginx -V</code> 来查看是否有 <code>with-http_stub_status_module</code> 该模块。</p><blockquote><p><code>nginx -V</code> 这里 <code>V</code> 是大写的，如果是小写的 <code>v</code> 即 <code>nginx -v</code>，则不会出现有哪些模块，只会出现 <code>nginx</code> 的版本</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /nginx_status &#123;</span><br><span class="line">    stub_status on;</span><br><span class="line">    access_log off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过 <a href="http://127.0.0.1/nginx_status" target="_blank" rel="noopener">http://127.0.0.1/nginx_status</a> 访问出现下面结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Active connections: 3</span><br><span class="line">server accepts handled requests</span><br><span class="line"> 7 7 5 </span><br><span class="line">Reading: 0 Writing: 1 Waiting: 2</span><br></pre></td></tr></table></figure><ol><li>主动连接(第 1 行)</li></ol><p>当前与http建立的连接数，包括等待的客户端连接：3</p><ol><li>服务器接受处理的请求(第 2~3 行)</li></ol><p>接受的客户端连接总数目：7<br>处理的客户端连接总数目：7<br>客户端总的请求数目：5</p><ol><li>读取其它信(第 4 行)</li></ol><p>当前，nginx读请求连接<br>当前，nginx写响应返回给客户端<br>目前有多少空闲客户端请求连接</p><h2 id="代理转发连接替换"><a href="#代理转发连接替换" class="headerlink" title="代理转发连接替换"></a>代理转发连接替换</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location ^~/api/upload &#123;</span><br><span class="line">    rewrite ^/(.*)$ /wfs/v1/upload break;</span><br><span class="line">    proxy_pass http://wfs-api;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ssl配置"><a href="#ssl配置" class="headerlink" title="ssl配置"></a>ssl配置</h2><p>超文本传输安全协议（缩写：HTTPS，英语：Hypertext Transfer Protocol Secure）是超文本传输协议和SSL/TLS的组合，用以提供加密通讯及对网络服务器身份的鉴定。HTTPS连接经常被用于万维网上的交易支付和企业信息系统中敏感信息的传输。HTTPS不应与在RFC 2660中定义的安全超文本传输协议（S-HTTP）相混。HTTPS 目前已经是所有注重隐私和安全的网站的首选，随着技术的不断发展，HTTPS 网站已不再是大型网站的专利，所有普通的个人站长和博客均可以自己动手搭建一个安全的加密的网站。</p><p>创建SSL证书，如果你购买的证书，就可以直接下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /etc/nginx/ssl</span><br><span class="line"># 创建了有效期100年，加密强度为RSA2048的SSL密钥key和X509证书文件。</span><br><span class="line">sudo openssl req -x509 -nodes -days 36500 -newkey rsa:2048 -keyout /etc/nginx/ssl/nginx.key -out /etc/nginx/ssl/nginx.crt</span><br><span class="line"># 上面命令，会有下面需要填写内容</span><br><span class="line">Country Name (2 letter code) [AU]:US</span><br><span class="line">State or Province Name (full name) [Some-State]:New York</span><br><span class="line">Locality Name (eg, city) []:New York City</span><br><span class="line">Organization Name (eg, company) [Internet Widgits Pty Ltd]:Bouncy Castles, Inc.</span><br><span class="line">Organizational Unit Name (eg, section) []:Ministry of Water Slides</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) []:your_domain.com</span><br><span class="line">Email Address []:admin@your_domain.com</span><br></pre></td></tr></table></figure><p>创建自签证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">首先，创建证书和私钥的目录</span><br><span class="line"># mkdir -p /etc/nginx/cert</span><br><span class="line"># cd /etc/nginx/cert</span><br><span class="line">创建服务器私钥，命令会让你输入一个口令：</span><br><span class="line"># openssl genrsa -des3 -out nginx.key 2048</span><br><span class="line">创建签名请求的证书（CSR）：</span><br><span class="line"># openssl req -new -key nginx.key -out nginx.csr</span><br><span class="line">在加载SSL支持的Nginx并使用上述私钥时除去必须的口令：</span><br><span class="line"># cp nginx.key nginx.key.org</span><br><span class="line"># openssl rsa -in nginx.key.org -out nginx.key</span><br><span class="line">最后标记证书使用上述私钥和CSR：</span><br><span class="line"># openssl x509 -req -days 365 -in nginx.csr -signkey nginx.key -out nginx.crt</span><br></pre></td></tr></table></figure><p>查看目前nginx编译选项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/nginx -V</span><br></pre></td></tr></table></figure><p>输出下面内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nginx version: nginx/1.7.8</span><br><span class="line">built by gcc 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC)</span><br><span class="line">TLS SNI support enabled</span><br><span class="line">configure arguments: --prefix=/usr/local/nginx-1.7.8 --with-http_ssl_module --with-http_spdy_module --with-http_stub_status_module --with-pcre</span><br></pre></td></tr></table></figure><p>如果依赖的模块不存在，可以进入安装目录，输入下面命令重新编译安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module</span><br></pre></td></tr></table></figure><p>运行完成之后还需要<code>make</code> (不用make install)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 备份nginx的二进制文件</span><br><span class="line">cp -rf /usr/local/nginx/sbin/nginx　 /usr/local/nginx/sbin/nginx.bak</span><br><span class="line"># 覆盖nginx的二进制文件</span><br><span class="line">cp -rf objs/nginx   /usr/local/nginx/sbin/</span><br></pre></td></tr></table></figure><p>HTTPS server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       443 ssl;</span><br><span class="line">    server_name  localhost;</span><br><span class="line"></span><br><span class="line">    ssl_certificate /etc/nginx/ssl/nginx.crt;</span><br><span class="line">    ssl_certificate_key /etc/nginx/ssl/nginx.key;</span><br><span class="line">    # 禁止在header中出现服务器版本，防止黑客利用版本漏洞攻击</span><br><span class="line">    server_tokens off;</span><br><span class="line">    # 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 </span><br><span class="line">    ssl_session_cache    shared:SSL:1m; </span><br><span class="line"></span><br><span class="line">    # 客户端可以重用会话缓存中ssl参数的过期时间，内网系统默认5分钟太短了，可以设成30m即30分钟甚至4h。</span><br><span class="line">    ssl_session_timeout  5m; </span><br><span class="line"></span><br><span class="line">    # 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。</span><br><span class="line">    # 这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher &apos;RC4:HIGH:!aNULL:!MD5&apos;（后面是你所指定的套件加密算法） 来看所支持算法。</span><br><span class="line">    ssl_ciphers  HIGH:!aNULL:!MD5;</span><br><span class="line"></span><br><span class="line">    # 设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。</span><br><span class="line">    ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root   html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="强制将http重定向到https"><a href="#强制将http重定向到https" class="headerlink" title="强制将http重定向到https"></a>强制将http重定向到https</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  example.com;</span><br><span class="line">    rewrite ^ https://$http_host$request_uri? permanent;    # 强制将http重定向到https</span><br><span class="line">    # 在错误页面和“服务器”响应头字段中启用或禁用发射nginx版本。 防止黑客利用版本漏洞攻击</span><br><span class="line">    server_tokens off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="两个虚拟主机"><a href="#两个虚拟主机" class="headerlink" title="两个虚拟主机"></a>两个虚拟主机</h2><p>纯静态-html 支持</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen          80;</span><br><span class="line">        server_name     www.domain1.com;</span><br><span class="line">        access_log      logs/domain1.access.log main;</span><br><span class="line">        location / &#123;</span><br><span class="line">            index index.html;</span><br><span class="line">            root  /var/www/domain1.com/htdocs;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen          80;</span><br><span class="line">        server_name     www.domain2.com;</span><br><span class="line">        access_log      logs/domain2.access.log main;</span><br><span class="line">        location / &#123;</span><br><span class="line">            index index.html;</span><br><span class="line">            root  /var/www/domain2.com/htdocs;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="虚拟主机标准配置"><a href="#虚拟主机标准配置" class="headerlink" title="虚拟主机标准配置"></a>虚拟主机标准配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">  server &#123;</span><br><span class="line">    listen          80 default;</span><br><span class="line">    server_name     _ *;</span><br><span class="line">    access_log      logs/default.access.log main;</span><br><span class="line">    location / &#123;</span><br><span class="line">       index index.html;</span><br><span class="line">       root  /var/www/default/htdocs;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="爬虫过滤"><a href="#爬虫过滤" class="headerlink" title="爬虫过滤"></a>爬虫过滤</h2><p>根据 <code>User-Agent</code> 过滤请求，通过一个简单的正则表达式，就可以过滤不符合要求的爬虫请求(初级爬虫)。</p><blockquote><p><code>~*</code> 表示不区分大小写的正则匹配</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">    if ($http_user_agent ~* &quot;python|curl|java|wget|httpclient|okhttp&quot;) &#123;</span><br><span class="line">        return 503;</span><br><span class="line">    &#125;</span><br><span class="line">    # 正常处理</span><br><span class="line">    # ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="防盗链"><a href="#防盗链" class="headerlink" title="防盗链"></a>防盗链</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">location ~* \.(gif|jpg|png|swf|flv)$ &#123;</span><br><span class="line">   root html</span><br><span class="line">   valid_referers none blocked *.nginxcn.com;</span><br><span class="line">   if ($invalid_referer) &#123;</span><br><span class="line">     rewrite ^/ www.nginx.cn</span><br><span class="line">     #return 404;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="虚拟目录配置"><a href="#虚拟目录配置" class="headerlink" title="虚拟目录配置"></a>虚拟目录配置</h2><p>alias指定的目录是准确的，root是指定目录的上级目录，并且该上级目录要含有location指定名称的同名目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">location /img/ &#123;</span><br><span class="line">    alias /var/www/image/;</span><br><span class="line">&#125;</span><br><span class="line"># 访问/img/目录里面的文件时，ningx会自动去/var/www/image/目录找文件</span><br><span class="line">location /img/ &#123;</span><br><span class="line">    root /var/www/image;</span><br><span class="line">&#125;</span><br><span class="line"># 访问/img/目录下的文件时，nginx会去/var/www/image/img/目录下找文件。]</span><br></pre></td></tr></table></figure><h2 id="防盗图配置"><a href="#防盗图配置" class="headerlink" title="防盗图配置"></a>防盗图配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location ~ \/public\/(css|js|img)\/.*\.(js|css|gif|jpg|jpeg|png|bmp|swf) &#123;</span><br><span class="line">    valid_referers none blocked *.jslite.io;</span><br><span class="line">    if ($invalid_referer) &#123;</span><br><span class="line">        rewrite ^/  http://wangchujiang.com/piratesp.png;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="屏蔽-git等文件"><a href="#屏蔽-git等文件" class="headerlink" title="屏蔽.git等文件"></a>屏蔽.git等文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~ (.git|.gitattributes|.gitignore|.svn) &#123;</span><br><span class="line">    deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="域名路径加不加需要都能正常访问"><a href="#域名路径加不加需要都能正常访问" class="headerlink" title="域名路径加不加需要都能正常访问"></a>域名路径加不加需要都能正常访问</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http://wangchujiang.com/api/index.php?a=1&amp;name=wcj</span><br><span class="line">                                  ^ 有后缀</span><br><span class="line"></span><br><span class="line">http://wangchujiang.com/api/index?a=1&amp;name=wcj</span><br><span class="line">                                 ^ 没有后缀</span><br></pre></td></tr></table></figure><p>nginx rewrite规则如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rewrite ^/(.*)/$ /index.php?/$1 permanent;</span><br><span class="line">if (!-d $request_filename)&#123;</span><br><span class="line">        set $rule_1 1$rule_1;</span><br><span class="line">&#125;</span><br><span class="line">if (!-f $request_filename)&#123;</span><br><span class="line">        set $rule_1 2$rule_1;</span><br><span class="line">&#125;</span><br><span class="line">if ($rule_1 = &quot;21&quot;)&#123;</span><br><span class="line">        rewrite ^/ /index.php last;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="错误问题"><a href="#错误问题" class="headerlink" title="错误问题"></a>错误问题</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The plain HTTP request was sent to HTTPS port</span><br></pre></td></tr></table></figure><p>解决办法，<code>fastcgi_param HTTPS $https if_not_empty</code> 添加这条规则，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl; # 注意这条规则</span><br><span class="line">    server_name  my.domain.com;</span><br><span class="line">    </span><br><span class="line">    fastcgi_param HTTPS $https if_not_empty;</span><br><span class="line">    fastcgi_param HTTPS on;</span><br><span class="line"></span><br><span class="line">    ssl_certificate /etc/ssl/certs/your.pem;</span><br><span class="line">    ssl_certificate_key /etc/ssl/private/your.key;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        # Your config here...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;h2 id=&quot;安装依赖&quot;&gt;&lt;a href=&quot;#安装依赖&quot; class=&quot;headerlink&quot; title=&quot;安装依赖&quot;&gt;&lt;/a&gt;安装依赖&lt;/h
      
    
    </summary>
    
      <category term="中间件" scheme="https://shenshengkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>区块链浏览器部署</title>
    <link href="https://shenshengkun.github.io/posts/984b410.html"/>
    <id>https://shenshengkun.github.io/posts/984b410.html</id>
    <published>2019-05-09T08:21:10.000Z</published>
    <updated>2019-05-30T02:29:19.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hyperledger-Explorer"><a href="#Hyperledger-Explorer" class="headerlink" title="Hyperledger Explorer"></a>Hyperledger Explorer</h1><p>Hyperledger Explorer是一个简单，功能强大，易于使用，高度可维护的开源浏览器，用于查看底层区块链网络上的活动 。</p><h1 id="postgresql"><a href="#postgresql" class="headerlink" title="postgresql"></a>postgresql</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>创建用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd postgres</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">注意：更新yum源，163或者阿里的yum源都可以</span><br><span class="line"></span><br><span class="line">添加RPM</span><br><span class="line">    yum install https://download.postgresql.org/pub/repos/yum/9.5/redhat/rhel-7-x86_64/pgdg-centos95-9.5-3.noarch.rpm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">安装PostgreSQL 9.5</span><br><span class="line">    yum install postgresql95-server postgresql95-contrib</span><br><span class="line"></span><br><span class="line">初始化数据库</span><br><span class="line">    /usr/pgsql-9.5/bin/postgresql95-setup initdb</span><br><span class="line">设置开机自启动</span><br><span class="line">    systemctl enable postgresql-9.5.service</span><br><span class="line"></span><br><span class="line">启动服务</span><br><span class="line">    systemctl start postgresql-9.5.service</span><br><span class="line">查看服务运行状态</span><br><span class="line">systemctl status postgresql-9.5.service</span><br></pre></td></tr></table></figure><p>postgreSQL 安装完成后，会建立一下‘postgres’用户，用于执行PostgreSQL，数据库中也会建立一个’postgres’用户，默认密码为自动生成，需要在系统中改一下。</p><h2 id="修改用户密码"><a href="#修改用户密码" class="headerlink" title="修改用户密码"></a>修改用户密码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">su - postgres  切换用户，执行后提示符会变为 &apos;-bash-4.2$&apos;</span><br><span class="line">psql -U postgres 登录数据库，执行后提示符变为 &apos;postgres=#&apos;</span><br><span class="line">ALTER USER postgres WITH PASSWORD &apos;gooagoo&apos;  设置postgres用户密码</span><br><span class="line">\q  退出数据库</span><br></pre></td></tr></table></figure><h2 id="开启远程访问"><a href="#开启远程访问" class="headerlink" title="开启远程访问"></a>开启远程访问</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi /var/lib/pgsql/9.5/data/postgresql.conf</span><br><span class="line">修改#listen_addresses = &apos;localhost&apos;  为  listen_addresses=&apos;*&apos;</span><br><span class="line">当然，此处‘*’也可以改为任何你想开放的服务器IP</span><br></pre></td></tr></table></figure><h2 id="信任远程连接"><a href="#信任远程连接" class="headerlink" title="信任远程连接"></a>信任远程连接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /var/lib/pgsql/9.5/data/pg_hba.conf</span><br><span class="line">    修改如下内容，信任指定服务器连接</span><br><span class="line">    # IPv4 local connections:</span><br><span class="line">    host    all            all      127.0.0.1/32      trust</span><br><span class="line">    host    all            all      10.211.55.6/32（需要连接的服务器IP）  trust</span><br></pre></td></tr></table></figure><h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart postgresql-9.5.service</span><br></pre></td></tr></table></figure><h1 id="blockchain-explorer"><a href="#blockchain-explorer" class="headerlink" title="blockchain-explorer"></a>blockchain-explorer</h1><h2 id="克隆存储库"><a href="#克隆存储库" class="headerlink" title="克隆存储库"></a>克隆存储库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hyperledger/blockchain-explorer.git</span><br><span class="line">cd blockchain-explorer</span><br><span class="line"></span><br><span class="line">也可以从我的百度链接上面下载：</span><br><span class="line">链接：https://pan.baidu.com/s/1VsxMlk5qo_5hUKsJ03DTlA </span><br><span class="line">提取码：9s5f </span><br><span class="line"></span><br><span class="line">cp -apr blockchain-explorer /var/lib/pgsql/</span><br></pre></td></tr></table></figure><h2 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">su - postgres</span><br><span class="line">cd blockchain-explorer/app</span><br><span class="line"></span><br><span class="line">修改explorerconfig.json以更新postgresql属性</span><br><span class="line"></span><br><span class="line">postgreSQL主机，端口，数据库，用户名，密码详细信息。</span><br><span class="line">“postgreSQL”：&#123;</span><br><span class="line"></span><br><span class="line">  &quot;host&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">  &quot;port&quot;: &quot;5432&quot;,</span><br><span class="line">  &quot;database&quot;: &quot;fabricexplorer&quot;,</span><br><span class="line">  &quot;username&quot;: &quot;postgres&quot;,</span><br><span class="line">  &quot;passwd&quot;: &quot;gooagoo&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运行create-database脚本"><a href="#运行create-database脚本" class="headerlink" title="运行create database脚本"></a>运行create database脚本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd blockchain-explorer/app/persistence/fabric/postgreSQL/db</span><br><span class="line">./createdb.sh</span><br></pre></td></tr></table></figure><h2 id="安装node"><a href="#安装node" class="headerlink" title="安装node"></a>安装node</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tar xvf  node-v11.10.0-linux-x64.tar</span><br><span class="line">cd node-v11.10.0-linux-x64</span><br><span class="line">./configure  &amp;&amp; make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">装cnpm淘宝源</span><br><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><h2 id="npm测试"><a href="#npm测试" class="headerlink" title="npm测试"></a>npm测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cnpm install</span><br><span class="line">cd blockchain-explorer/app/test</span><br><span class="line">cnpm install</span><br><span class="line">cnpm run test</span><br><span class="line">cd client/</span><br><span class="line">cnpm install</span><br><span class="line">cnpm test -- -u --coverage</span><br><span class="line">cnpm run build</span><br><span class="line"></span><br><span class="line">由于config.json还没有写配置，所以node test会测试不成功</span><br></pre></td></tr></table></figure><h2 id="fabric的网络配置"><a href="#fabric的网络配置" class="headerlink" title="fabric的网络配置"></a>fabric的网络配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">vim blockchain-explorer/app/platform/fabric/config.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;network-configs&quot;: &#123;</span><br><span class="line">    &quot;network-1&quot;: &#123;</span><br><span class="line">      &quot;version&quot;: &quot;1.0&quot;,</span><br><span class="line">      &quot;clients&quot;: &#123;</span><br><span class="line">        &quot;client-1&quot;: &#123;</span><br><span class="line">          &quot;tlsEnable&quot;: false,</span><br><span class="line">          &quot;organization&quot;: &quot;1D8L291SQ3QRQ80AB2M1029FB60010HCMSP&quot;,</span><br><span class="line">          &quot;channel&quot;: &quot;vaccine&quot;,</span><br><span class="line">          &quot;credentialStore&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;./tmp/credentialStore_Org1/credential&quot;,</span><br><span class="line">            &quot;cryptoStore&quot;: &#123;</span><br><span class="line">              &quot;path&quot;: &quot;./tmp/credentialStore_Org1/crypto&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;channels&quot;: &#123;</span><br><span class="line">        &quot;vaccine&quot;: &#123;</span><br><span class="line">          &quot;peers&quot;: &#123;</span><br><span class="line">            &quot;peer0.syj.vaccine.com&quot;: &#123;&#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;connection&quot;: &#123;</span><br><span class="line">            &quot;timeout&quot;: &#123;</span><br><span class="line">              &quot;peer&quot;: &#123;</span><br><span class="line">                &quot;endorser&quot;: &quot;6000&quot;,</span><br><span class="line">                &quot;eventHub&quot;: &quot;6000&quot;,</span><br><span class="line">                &quot;eventReg&quot;: &quot;6000&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;organizations&quot;: &#123;</span><br><span class="line">        &quot;1D8L291SQ3QRQ80AB2M1029FB60010HCMSP&quot;: &#123;</span><br><span class="line">          &quot;mspid&quot;: &quot;1D8L291SQ3QRQ80AB2M1029FB60010HCMSP&quot;,</span><br><span class="line">          &quot;fullpath&quot;: false,</span><br><span class="line">          &quot;adminPrivateKey&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/data/fabric/fabric-ca-files/vaccine-org/syj.vaccine.com/admin/msp/keystore&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;signedCert&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/data/fabric/fabric-ca-files/vaccine-org/syj.vaccine.com/admin/msp/signcerts&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;1D9K2HVDM752IN0AB2M105R9Q5001125MSP&quot;: &#123;</span><br><span class="line">          &quot;mspid&quot;: &quot;1D9K2HVDM752IN0AB2M105R9Q5001125MSP&quot;,</span><br><span class="line">          &quot;fullpath&quot;: false,</span><br><span class="line">          &quot;adminPrivateKey&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/data/fabric/fabric-ca-files/vaccine-org/czsrmyy.czsjkzx.hbsjkzx.vaccine.com/admin/msp/keystore&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;signedCert&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/data/fabric/fabric-ca-files/vaccine-org/czsrmyy.czsjkzx.hbsjkzx.vaccine.com/admin/msp/signcerts&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;OrdererMSP&quot;: &#123;</span><br><span class="line">          &quot;mspid&quot;: &quot;OrdererMSP&quot;,</span><br><span class="line">          &quot;adminPrivateKey&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/data/fabric/fabric-ca-files/vaccine-order/vaccine.syj.vaccine.com/admin/msp/keystore&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;peers&quot;: &#123;</span><br><span class="line">        &quot;peer0.syj.vaccine.com&quot;: &#123;</span><br><span class="line">          &quot;url&quot;: &quot;grpc://peer0.syj.vaccine.com:7051&quot;,</span><br><span class="line">          &quot;eventUrl&quot;: &quot;grpc://peer0.syj.vaccine.com:7053&quot;,</span><br><span class="line">          &quot;grpcOptions&quot;: &#123;</span><br><span class="line">            &quot;ssl-target-name-override&quot;: &quot;peer0.syj.vaccine.com&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;peer0.czsrmyy.czsjkzx.hbsjkzx.vaccine.com&quot;: &#123;</span><br><span class="line">          &quot;url&quot;: &quot;grpc://peer0.czsrmyy.czsjkzx.hbsjkzx.vaccine.com:7351&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;orderers&quot;: &#123;</span><br><span class="line">        &quot;orderer1.vaccine.syj.vaccine.com&quot;: &#123;</span><br><span class="line">          &quot;url&quot;: &quot;grpc://orderer1.vaccine.syj.vaccine.com:7050&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;network-2&quot;: &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;configtxgenToolPath&quot;: &quot;/data/fabric/bin&quot;,</span><br><span class="line">  &quot;license&quot;: &quot;Apache-2.0&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成之后，在执行上面的，cnpm test</p><h2 id="汉化"><a href="#汉化" class="headerlink" title="汉化"></a>汉化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /var/lib/pgsql/blockchain-explorer/client/src</span><br><span class="line">将components替换成我百度链接的包</span><br><span class="line"></span><br><span class="line">之后还需要重新，cnpm build一下</span><br></pre></td></tr></table></figure><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">由于区块链浏览器默认需要有锚节点，才能显示所有节点，所以在部署了第一个组织之后，需要在升级下锚节点</span><br><span class="line">./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID vaccine -asOrg Org1MSP</span><br><span class="line"></span><br><span class="line">docker exec -it cli-vaccine peer channel update -o orderer1.vaccine.syj.vaccine.com:7050 -c vaccine -f ./channel-artifacts/Org1MSPanchors.tx</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd blockchain-explorer/</span><br><span class="line">./start.sh</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip:8080</span><br></pre></td></tr></table></figure><p><img src="https://shenshengkun.github.io/images/fabric_exporler.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hyperledger-Explorer&quot;&gt;&lt;a href=&quot;#Hyperledger-Explorer&quot; class=&quot;headerlink&quot; title=&quot;Hyperledger Explorer&quot;&gt;&lt;/a&gt;Hyperledger Explorer&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="区块链" scheme="https://shenshengkun.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
  </entry>
  
  <entry>
    <title>python监控es状态</title>
    <link href="https://shenshengkun.github.io/posts/71abe607.html"/>
    <id>https://shenshengkun.github.io/posts/71abe607.html</id>
    <published>2019-04-28T03:04:01.000Z</published>
    <updated>2019-05-30T02:29:19.196Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>用python写一个监控es状态的脚本</p><h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><h2 id="监控es的机器"><a href="#监控es的机器" class="headerlink" title="监控es的机器"></a>监控es的机器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">配置文件</span><br><span class="line"></span><br><span class="line">[root@Ops-script monitor_elasticsearch]# cat escluster_ip.ini</span><br><span class="line">[mail]</span><br><span class="line">name = sy@xxx.com</span><br><span class="line">[tax_es]</span><br><span class="line">cluster_ip = 192.168.50.7:9200,192.168.50.8:9200,192.168.50.9:9200</span><br><span class="line">name_pass = none,none</span><br><span class="line">[analysis_es]</span><br><span class="line">cluster_ip = 192.168.50.24:9200,192.168.50.25:9200</span><br><span class="line">name_pass = none,none</span><br></pre></td></tr></table></figure><h2 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@Ops-script monitor_elasticsearch]# cat monitor_elastic_cluster.py</span><br><span class="line"></span><br><span class="line">import urllib,socket,time,json</span><br><span class="line">import logging,requests,configparser,os</span><br><span class="line"></span><br><span class="line"># 定义日志格式读取配置文件</span><br><span class="line">cur_path = os.path.dirname(os.path.realpath(__file__))</span><br><span class="line">logging.basicConfig(format=&apos;[ %(asctime)s ] -- %(message)s&apos;,</span><br><span class="line">                    datefmt=&apos;%a, %d %b %Y %H:%M:%S&apos;,</span><br><span class="line">                    filename=cur_path+&quot;/scripts.log&quot;,</span><br><span class="line">                    level=logging.INFO)</span><br><span class="line">config_path = os.path.join(cur_path,&quot;escluster_ip.ini&quot;)</span><br><span class="line">conf = configparser.ConfigParser()</span><br><span class="line">conf.read(config_path)</span><br><span class="line">esgroup = conf.sections()</span><br><span class="line"></span><br><span class="line">def GetClusterIp():</span><br><span class="line">    # 按集群名循环检查,集群名为配置文件中的标题</span><br><span class="line">    for group in esgroup:</span><br><span class="line">        # 获取到 mail 中的邮件地址不再继续循环</span><br><span class="line">        if group == &quot;mail&quot;:</span><br><span class="line">            mailname = conf.get(group,&quot;name&quot;)</span><br><span class="line">            continue</span><br><span class="line">        # 获取到一个集群 ip 后进行 get 请求</span><br><span class="line">        iplist = conf.get(group,&quot;cluster_ip&quot;).split(&quot;,&quot;)</span><br><span class="line">        for esip in iplist:</span><br><span class="line">            url = &quot;http://%s/_cat/health&quot;%esip</span><br><span class="line">            try:</span><br><span class="line">                # 超时时间为 3 秒, request 的请求值不是200的将全部置为400</span><br><span class="line">                # 如果是请求成功,则获取 status 的状态和 status_num 的百分比</span><br><span class="line">                response = requests.get(url,timeout=3)</span><br><span class="line">                request = response.status_code</span><br><span class="line">                status = response.text.split()[3]</span><br><span class="line">                status_num = response.text.split()[-1]</span><br><span class="line">            except:</span><br><span class="line">                request = 400</span><br><span class="line">            # 请求值为 200 后,检查 status 值非 green 状态发送报警邮件,并不在继续检查本集群内的剩余节点</span><br><span class="line">            if request == 200:</span><br><span class="line">                if status != &quot;green&quot;:</span><br><span class="line">                    mailtitle = &quot;elasticsearch集群 [ %s ], ip为:%s ,查状态: %s, 状态百分比: %s&quot;%(group,esip,status,status_num)</span><br><span class="line">                    mailtxt = &quot;elasticsearch集群 [ %s ]\n\nip为: [ %s ]\n\n检查状态为: %s\n\n状态百分比: %s&quot;%(group,esip,status,status_num)</span><br><span class="line">                    command = &quot;echo -e %s%s%s | mail -s %s%s%s %s&quot;%(&apos;&quot;&apos;,mailtxt,&apos;&quot;&apos;,&apos;&quot;&apos;,mailtitle,&apos;&quot;&apos;,mailname)</span><br><span class="line">                    logging.info(mailtitle)</span><br><span class="line">                    os.system(command)</span><br><span class="line">                    break</span><br><span class="line">            # 请求值不是 200 ,报警后继续检查集群内剩余 ip</span><br><span class="line">            else:</span><br><span class="line">                mailtitle = &quot;elasticsearch集群 [ %s ], ip为:%s, 请求超时,请检查端口&quot;%(group,esip)</span><br><span class="line">                mailtxt = &quot;elasticsearch集群 [ %s ]\n\nip: [ %s ]\n\n请求超时,请检查端口&quot;%(group,esip)</span><br><span class="line">                command = &quot;echo -e %s%s%s | mail -s %s%s%s %s&quot;%(&apos;&quot;&apos;,mailtxt,&apos;&quot;&apos;,&apos;&quot;&apos;,mailtitle,&apos;&quot;&apos;,mailname)</span><br><span class="line">                logging.info(mailtitle)</span><br><span class="line">                os.system(command)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    GetClusterIp()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h1&gt;&lt;p&gt;用python写一个监控es状态的脚本&lt;/p&gt;
&lt;h1 id=&quot;实例&quot;&gt;&lt;a href=&quot;#实例&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
      <category term="python" scheme="https://shenshengkun.github.io/categories/python/"/>
    
    
  </entry>
  
  <entry>
    <title>钉钉定时发送值班人员</title>
    <link href="https://shenshengkun.github.io/posts/59cdc228.html"/>
    <id>https://shenshengkun.github.io/posts/59cdc228.html</id>
    <published>2019-04-19T06:20:50.000Z</published>
    <updated>2019-05-30T02:29:19.192Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>每天运维人员都需要去做些基础服务，就需要值班人员去轮班解决，现在需要写一个定时发送值班人员的脚本</p><h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>需要自己在钉钉群，申请个机器人，申请过程这里不赘述了，下面是脚本</p><h1 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">[root@Ops-script dingding]# mkdir /home/monitor/dingding</span><br><span class="line">[root@Ops-script dingding]# touch groupkey  helpkey</span><br><span class="line"></span><br><span class="line">[root@Ops-script dingding]# cat send_dingding.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line">groupfiles=&quot;/home/monitor/dingding/groupkey&quot;</span><br><span class="line">helpfiles=&quot;/home/monitor/dingding/helpkey&quot;</span><br><span class="line">Date=`date +%Y-%m-%d\ %H:%M:%S`</span><br><span class="line">url=&quot;https://oapi.dingtalk.com/robot/send?access_token=c2123f81820fccfadfc47bbd629d26e7613ae49f1a053edc6e81f5864c550e30&quot;</span><br><span class="line">group=(&quot;a:xx;&quot;</span><br><span class="line">       &quot;b:xx;&quot;</span><br><span class="line">       &quot;c:xx;&quot;)</span><br><span class="line">opshelp=(&quot;a:xx;&quot;</span><br><span class="line">         &quot;b:xx;&quot;</span><br><span class="line">         &quot;c:xx;&quot;)</span><br><span class="line">groupkey=`sed -n &quot;1p&quot; $groupfiles`</span><br><span class="line">helpkeys=`awk &apos;NR==1&#123;print $1&#125;&apos; $helpfiles`</span><br><span class="line">helpkey=`awk &apos;NR==1&#123;print $2&#125;&apos; $helpfiles`</span><br><span class="line"># 每日值班人</span><br><span class="line">for crew in $&#123;group[@]&#125;;do</span><br><span class="line">    if echo $crew | grep -q $groupkey ;then</span><br><span class="line">        values=`echo $crew | awk -F&apos;:&apos; &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">        onduty_mess=&quot;今日运维值班人: [ $values ]&quot;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"># 修改缓存文件内的运维值班人员 key , 使得下次人员自动更换</span><br><span class="line">if [ $groupkey == &quot;a&quot; ];then</span><br><span class="line">    echo &quot;b&quot; &gt; $groupfiles</span><br><span class="line">elif [ $groupkey == &quot;b&quot; ];then</span><br><span class="line">    echo &quot;c&quot; &gt; $groupfiles</span><br><span class="line">elif [ $groupkey == &quot;c&quot; ];then</span><br><span class="line">    echo &quot;a&quot; &gt; $groupfiles</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 修改缓存文件内的运维上线人员 key , 使得下次人员自动更换</span><br><span class="line">if [ $helpkeys == 7 ];then</span><br><span class="line">    helpsum=1</span><br><span class="line">else</span><br><span class="line">    helpsum=$(($helpkeys+1))</span><br><span class="line">fi</span><br><span class="line">if [ $helpsum == 1 ];then</span><br><span class="line">    if [ $helpkey == &quot;a&quot; ];then</span><br><span class="line">        echo &quot;$helpsum b&quot; &gt; $helpfiles</span><br><span class="line">    elif [ $helpkey == &quot;b&quot; ];then</span><br><span class="line">        echo &quot;$helpsum c&quot; &gt; $helpfiles</span><br><span class="line">    elif [ $helpkey == &quot;c&quot; ];then</span><br><span class="line">        echo &quot;$helpsum a&quot; &gt; $helpfiles</span><br><span class="line">    fi</span><br><span class="line">else</span><br><span class="line">    echo &quot;$helpsum $helpkey&quot; &gt; $helpfiles</span><br><span class="line">fi</span><br><span class="line"># 每周支持上线人</span><br><span class="line">for opsdit in $&#123;opshelp[@]&#125;;do</span><br><span class="line">    if [ $helpsum == 1 ];then</span><br><span class="line">        helpkey=`awk &apos;NR==1&#123;print $2&#125;&apos; $helpfiles`</span><br><span class="line">    fi</span><br><span class="line">    if echo $opsdit | grep -q $helpkey ;then</span><br><span class="line">        helpvalues=`echo $opsdit | awk -F&apos;:&apos; &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">        help_mess=&quot;本周版本上线运维支持: [ $helpvalues ]&quot;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">curl -XPOST -s -L -H &quot;Content-Type:application/json&quot; -H &quot;charset:utf-8&quot; $url -d &quot;</span><br><span class="line">        &#123;</span><br><span class="line">        \&quot;msgtype\&quot;: \&quot;text\&quot;, </span><br><span class="line">        \&quot;text\&quot;: &#123;</span><br><span class="line">                 \&quot;content\&quot;: \&quot;大家好~\n$onduty_mess\n$help_mess\&quot;</span><br><span class="line">                 &#125;</span><br><span class="line">    &#125;&quot;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h1&gt;&lt;p&gt;每天运维人员都需要去做些基础服务，就需要值班人员去轮班解决，现在需要写一个定时发送值班人员的脚本&lt;/p&gt;
&lt;h1 id=&quot;前提&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="linux" scheme="https://shenshengkun.github.io/categories/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>docker存储驱动</title>
    <link href="https://shenshengkun.github.io/posts/12280181.html"/>
    <id>https://shenshengkun.github.io/posts/12280181.html</id>
    <published>2019-04-18T07:48:50.000Z</published>
    <updated>2019-05-30T02:29:19.231Z</updated>
    
    <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Docker最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于AUFS未并入Linux内核，且只支持Ubuntu，考虑到兼容性问题，在Docker 0.7版本中引入了存储驱动。</p><p>目前，Docker支持的存储驱动：aufs，devicemapper，btrfs，zfs，overlay和overlay2。</p><p>就如Docker官网上说的，没有单一的驱动适合所有的应用场景，要根据不同的场景选择合适的存储驱动，才能有效的提高Docker的性能。如何选择适合的存储驱动，要先了解存储驱动原理才能更好的判断</p><h1 id="写时复制（CoW）"><a href="#写时复制（CoW）" class="headerlink" title="写时复制（CoW）"></a>写时复制（CoW）</h1><p>所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景。比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论有多少个容器共享同一个image，所做的写操作都是对从image中复制到自己的文件系统中的复本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离，相互不影响。使用CoW可以有效的提高磁盘的利用率。</p><h1 id="用时分配（allocate-on-demand）"><a href="#用时分配（allocate-on-demand）" class="headerlink" title="用时分配（allocate-on-demand）"></a>用时分配（allocate-on-demand）</h1><p>而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。</p><h1 id="AUFS"><a href="#AUFS" class="headerlink" title="AUFS"></a>AUFS</h1><p>AUFS（AnotherUnionFS）是一种Union FS，是文件级的存储驱动。AUFS能透明覆盖一或多个现有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件系统可以一层一层地叠加修改文件。无论底下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改一个文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果也保存在可写层。在Docker中，底下的只读层就是image，可写层就是Container。结构如下图所示：</p><p><img src="https://shenshengkun.github.io/images/存储驱动1.png" alt=""></p><h1 id="Overlay"><a href="#Overlay" class="headerlink" title="Overlay"></a>Overlay</h1><p>Overlay是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docker的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docker中，底下的只读层就是image，可写层就是Container。结构如下图所示：</p><p><img src="https://shenshengkun.github.io/images/存储驱动2.png" alt=""></p><h1 id="Device-mapper"><a href="#Device-mapper" class="headerlink" title="Device mapper"></a>Device mapper</h1><p>Device mapper是Linux内核2.6.9后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的AUFS和OverlayFS都是文件级存储，而Device mapper是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个叫用时分配。当要修改已有文件时，再使用CoW为容器快照分配块空间，将要修改的数据复制到在容器快照中新的块里再进行修改。Device mapper 驱动默认会创建一个100G的文件包含镜像和容器。每一个容器被限制在10G大小的卷内，可以自己配置调整。结构如下图所示：</p><p><img src="https://shenshengkun.github.io/images/存储驱动3.png" alt=""></p><h1 id="Btrfs"><a href="#Btrfs" class="headerlink" title="Btrfs"></a>Btrfs</h1><p>Btrfs被称为下一代写时复制文件系统，并入Linux内核，也是文件级级存储，但可以像Device mapper一直接操作底层设备。Btrfs把文件系统的一部分配置为一个完整的子文件系统，称之为subvolume 。那么采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc()分配内存一样。为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个chunk 。每个chunk可以使用不同的磁盘空间分配策略。比如某些chunk只存放metadata，某些chunk只存放数据。这种模型有很多优点，比如Btrfs支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用Btrfs的命令将该设备添加到文件系统中。Btrfs把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照则都是subvolume的快照。</p><p><img src="https://shenshengkun.github.io/images/存储驱动4.png" alt=""></p><p>当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫用时分配。而当要修改已有文件时，使用CoW复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再更新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。</p><h1 id="ZFS"><a href="#ZFS" class="headerlink" title="ZFS"></a>ZFS</h1><p>ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式，ZFS 完全抛弃了“卷管理”，不再创建虚拟的卷，而是把所有设备集中到一个存储池中来进行管理，用“存储池”的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的。为了管理这些物理设备，并为数据提供冗余，“卷管理”的概念提供了一个单设备的映像。而ZFS创建在虚拟的，被称为“zpools”的存储池之上。每个存储池由若干虚拟设备（virtual devices，vdevs）组成。这些虚拟设备可以是原始磁盘，也可能是一个RAID1镜像设备，或是非标准RAID等级的多磁盘组。于是zpool上的文件系统可以使用这些虚拟设备的总存储容量。</p><p><img src="https://shenshengkun.github.io/images/存储驱动5.png" alt=""></p><p>下面看一下在Docker里ZFS的使用。首先从zpool里分配一个ZFS文件系统给镜像的基础层，而其他镜像层则是这个ZFS文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的最顶层生成一个可写层。如下图所示：</p><p><img src="https://shenshengkun.github.io/images/存储驱动6.png" alt=""></p><p>当要写一个新文件时，使用按需分配，一个新的数据快从zpool里生成，新的数据写入这个块，而这个新空间存于容器（ZFS的克隆）里。<br>当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。</p><h1 id="overlay2"><a href="#overlay2" class="headerlink" title="overlay2"></a>overlay2</h1><p>OverlayFS将Linux主机上的两个单独目录分层，并将它们显示为一个目录。这些目录称为层，统一过程称为联合安装。OverlayFS指向一个upper文件系统和一个lower文件系统，分别代表Docker的镜像层和容器层。用统一视图将整合的目录公开。</p><p>该overlay2驱动程序原生支持多达128个较低的OverlayFS层。此功能为与层相关的Docker命令（如docker build和docker commit）提供了更好的性能，并且大量减少了inode的消耗。</p><h1 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h1><table><thead><tr><th>存储驱动</th><th>简介</th><th>优点</th><th>缺点</th><th>存储级别</th><th>场景</th></tr></thead><tbody><tr><td>aufs</td><td>最古老的联合文件系统，没有被内核收录，只支持ubuntu</td><td>允许容器共享可执行文件和共享内存，历史悠久，使用广泛</td><td>会导致一些严重的内核崩溃，多层，在CoW时如果文件大且在低层会慢一些</td><td>文件级存储</td><td>大并发少IO</td></tr><tr><td>devicemapper</td><td>自动创建的稀疏文件的loop挂载后，自动创建块设备</td><td>精简配置和写时复制（CoW）快照技术，只复制修改的块</td><td>不支持共享存储，多个容器读同一个文件复制多份，容器启停可能会有磁盘溢出</td><td>块级存储</td><td>IO密集场景</td></tr><tr><td>btrfs</td><td>和devicemapper一样操作底层设备</td><td>非常快，支持动态添加设备</td><td>设备之间不共享可执行内存</td><td>文件级块存储</td><td>不适合高密度容器的paas平台</td></tr><tr><td>zfs</td><td></td><td>支持多个容器共享一个缓存块，适合大内存场景</td><td>CoW使碎片化问题更严重，文件在磁盘上物理地址不连续，顺序读性能差</td><td>所有设备集中到一个共享池里面进行管理</td><td>Paas平台和高密度场景</td></tr><tr><td>overlay</td><td>联合文件系统，内核版本3.18.0开始合并到内核中，只有两层</td><td>非常快速的联合文件系统。还支持页面缓存共享，这意味着访问同一文件的多个容器可以共享单个页面缓存条目（或条目），如aufs一样高效</td><td>会导致过多的inode消耗，不管修改内容大小都会复制整个文件，修改大文件消耗时间长</td><td>文件级存储</td><td>大并发少IO</td></tr><tr><td>overlay2</td><td></td><td>内核版本4.0有附加功能，避免过多的inode消耗</td><td></td><td>文件级存储</td><td>大并发少IO</td></tr></tbody></table><h2 id="AUFS-VS-Overlay"><a href="#AUFS-VS-Overlay" class="headerlink" title="AUFS VS Overlay"></a>AUFS VS Overlay</h2><p>AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。但Overlay还太年轻，要谨慎在生产使用。而AUFS做为docker的第一个存储驱动，已经有很长的历史，比较的稳定，且在大量的生产中实践过，有较强的社区支持。目前开源的DC/OS指定使用Overlay。</p><h2 id="Overlay-VS-Device-mapper"><a href="#Overlay-VS-Device-mapper" class="headerlink" title="Overlay VS Device mapper"></a>Overlay VS Device mapper</h2><p>Overlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。</p><h2 id="Device-mapper-VS-Btrfs-Driver-VS-ZFS"><a href="#Device-mapper-VS-Btrfs-Driver-VS-ZFS" class="headerlink" title="Device mapper VS Btrfs Driver VS ZFS"></a>Device mapper VS Btrfs Driver VS ZFS</h2><p>Device mapper和Btrfs都是直接对块操作，都不支持共享存储，表示当有多个容器读同一个文件时，需要生活多个复本，所以这种存储驱动不适合在高密度容器的PaaS平台上使用。而且在很多容器启停的情况下可能会导致磁盘溢出，造成主机不能工作。Device mapper不建议在生产使用。Btrfs在docker build可以很高效。</p><p>ZFS最初是为拥有大量内存的Salaris服务器设计的，所在在使用时对内存会有影响，适合内存大的环境。ZFS的COW使碎片化问题更加严重，对于顺序写生成的大文件，如果以后随机的对其中的一部分进行了更改，那么这个文件在硬盘上的物理地址就变得不再连续，未来的顺序读会变得性能比较差。ZFS支持多个容器共享一个缓存块，适合PaaS和高密度的用户场景。</p><h1 id="IO性能对比"><a href="#IO性能对比" class="headerlink" title="IO性能对比"></a>IO性能对比</h1><ul><li>测试工具：IOzone（是一个文件系统的benchmark工具，可以测试不同的操作系统中文件系统的读写性能）</li><li>测试场景：从4K到1G文件的顺序和随机IO性能</li><li>测试方法：基于不同的存储驱动启动容器，在容器内安装IOzone，执行命令：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./iozone -a -n 4k -g 1g -i 0 -i 1 -i 2 -f /root/test.rar -Rb ./iozone.xls</span><br></pre></td></tr></table></figure><h2 id="测试项的定义和解释"><a href="#测试项的定义和解释" class="headerlink" title="测试项的定义和解释"></a>测试项的定义和解释</h2><ul><li>Write：测试向一个新文件写入的性能。</li><li>Re-write：测试向一个已存在的文件写入的性能。</li><li>Read：测试读一个已存在的文件的性能。</li><li>Re-Read：测试读一个最近读过的文件的性能。</li><li>Random Read：测试读一个文件中的随机偏移量的性能。</li><li>Random Write：测试写一个文件中的随机偏移量的性能。</li></ul><h2 id="通过以上的性能数据可以看到："><a href="#通过以上的性能数据可以看到：" class="headerlink" title="通过以上的性能数据可以看到："></a>通过以上的性能数据可以看到：</h2><p>AUFS在读的方面性能相比Overlay要差一些，但在写的方面性能比Overlay要好。<br>device mapper在512M以上文件的读写性能都非常的差，但在512M以下的文件读写性能都比较好。<br>btrfs在512M以上的文件读写性能都非常好，但在512M以下的文件读写性能相比其他的存储驱动都比较差。<br>ZFS整体的读写性能相比其他的存储驱动都要差一些。 简单的测试了一些数据，对测试出来的数据原理还需要进一步的解析。</p><h1 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h1><h2 id="devicemapper"><a href="#devicemapper" class="headerlink" title="devicemapper"></a>devicemapper</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;storage-driver&quot;: &quot;devicemapper&quot;,</span><br><span class="line">    &quot;storage-opts&quot;: [</span><br><span class="line">      &quot;dm.thinpooldev=/dev/mapper/thin-pool&quot;,</span><br><span class="line">      &quot;dm.use_deferred_deletion=true&quot;,</span><br><span class="line">      &quot;dm.use_deferred_removal=true&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="overlay2-1"><a href="#overlay2-1" class="headerlink" title="overlay2"></a>overlay2</h2><p>overlay2需要使用4.0以上版本的内核，如果使用的是RHEL或CentOS，需要3.10.0-514以上版本的内核</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看是否开启overlay</span><br><span class="line">lsmod |grep over</span><br><span class="line"></span><br><span class="line"># 开启overlay支持</span><br><span class="line">modprobe overlay</span><br></pre></td></tr></table></figure><p>配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">    &quot;storage-opts&quot;: [</span><br><span class="line">        &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">        #&quot;overlay2.size=1G&quot;, # xfs文件系统</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h1&gt;&lt;p&gt;Docker最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于AUFS
      
    
    </summary>
    
      <category term="虚拟化" scheme="https://shenshengkun.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
  </entry>
  
  <entry>
    <title>Kubernetes节点资源耗尽状态的处理</title>
    <link href="https://shenshengkun.github.io/posts/a54106c5.html"/>
    <id>https://shenshengkun.github.io/posts/a54106c5.html</id>
    <published>2019-04-18T06:20:01.000Z</published>
    <updated>2019-05-30T02:29:19.200Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现测试环境的k8s集群，总有node利用不上，pod漂移过去之后，启动不了，故仔细排查了一下缘由！</p><h1 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master35 scripts]# ./list_pod.sh | grep imis</span><br><span class="line">imis-866d46c464-nvz4b                       0/1       ContainerCreating   0          3m        &lt;none&gt;          node149</span><br><span class="line"></span><br><span class="line">发现有的pod无法启动，刚开始describe查了下原因，看到，一直在拉镜像状态中，但是3分钟了，也不至于镜像拉不下来啊！</span><br><span class="line"></span><br><span class="line">查看了下node149的状态，发现</span><br><span class="line">Warning: “EvictionThresholdMet Attempting to reclaim nodefs”</span><br><span class="line">发现大概应该是由于磁盘原因造成的，也可以看下kubelet日志，也会报这个类似的错误</span><br></pre></td></tr></table></figure><h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node149 ~]# df -h</span><br><span class="line">Filesystem                Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/cl-root        36G  30G   6G  86% /</span><br><span class="line">devtmpfs                  7.8G     0  7.8G   0% /dev</span><br><span class="line">tmpfs                     7.8G     0  7.8G   0% /dev/shm</span><br><span class="line">tmpfs                     7.8G  9.3M  7.8G   1% /run</span><br><span class="line">tmpfs                     7.8G     0  7.8G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                1014M  186M  829M  19% /boot</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">由于这是测试环境，所以docker的目录，默认在/var/lib/docker，没有单独挂载别的目录，这样的话，也没加定时任务清理磁盘，/ 磁盘就会越来越满，现在看是用了86%</span><br></pre></td></tr></table></figure><p>由于某些原因，我们的那个portal pod必须运行于该node上（通过<a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">nodeSelector</a>选定node的方式）。在无法扩充根分区size的情况下，为了临时恢复pod运行，我们只能进一步“压榨”node了。于是我们的思路是：通过调整node的eviction threshold值来让node恢复healthy。 </p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>每个node上的kubelet都负责定期采集资源占用数据，并与预设的 threshold值进行比对，如果超过 threshold值，kubelet就会尝试杀掉一些Pod以回收相关资源，对Node进行保护。kubelet关注的资源指标threshold大约有如下几种： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- memory.available</span><br><span class="line">- nodefs.available</span><br><span class="line">- nodefs.inodesFree</span><br><span class="line">- imagefs.available</span><br><span class="line">- imagefs.inodesFree</span><br></pre></td></tr></table></figure><p>每种threshold又分为eviction-soft和eviction-hard两组值。soft和hard的区别在于前者在到达threshold值时会给pod一段时间优雅退出，而后者则崇尚“暴力”，直接杀掉pod，没有任何优雅退出的机会。这里还要提一下nodefs和imagefs的区别： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nodefs: 指node自身的存储，存储daemon的运行日志等，一般指root分区/；</span><br><span class="line">imagefs: 指docker daemon用于存储image和容器可写层(writable layer)的磁盘；</span><br></pre></td></tr></table></figure><h1 id="解决步骤"><a href="#解决步骤" class="headerlink" title="解决步骤"></a>解决步骤</h1><p>我们需要为kubelet重新设定nodefs.available的threshold值。怎么做呢？</p><p><a href="https://kubernetes.io/docs/admin/kubelet/" target="_blank" rel="noopener">kubelet</a>是运行于每个kubernetes node上的daemon，它在system boot时由<a href="http://en.wikipedia.org/wiki/Systemd" target="_blank" rel="noopener">systemd</a>拉起:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@master35 ~# ps -ef|grep kubelet</span><br><span class="line">root      5718  5695  0 16:38 pts/3    00:00:00 grep --color=auto kubelet</span><br><span class="line">root     13640     1  4 10:25 ?        00:17:25 /usr/bin/kubelet --kubeconfig=/etc/kubernetes/kubelet.conf --require-kubeconfig=true --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --authorization-mode=Webhook --client-ca-file=/etc/kubernetes/pki/ca.crt --cadvisor-port=0</span><br></pre></td></tr></table></figure><p>查看一下kubelet service的状态： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master35 scripts]# systemctl status kubelet               </span><br><span class="line">● kubelet.service - kubelet: The Kubernetes Node Agent</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/kubelet.service.d</span><br><span class="line">           └─10-kubeadm.conf</span><br><span class="line">   Active: active (running) since Thu 2018-07-19 21:04:35 CST; 8 months 29 days ago</span><br><span class="line">     Docs: http://kubernetes.io/docs/</span><br><span class="line"> Main PID: 1921 (kubelet)</span><br><span class="line">    Tasks: 19</span><br><span class="line">   Memory: 54.9M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─1921 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --pod-manifest-path=...</span><br><span class="line"></span><br><span class="line">Apr 14 09:26:16 master35 kubelet[1921]: W0414 09:26:16.673359    1921 reflector.go:341] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: watch o...(56737582)</span><br><span class="line">Apr 15 06:36:48 master35 kubelet[1921]: W0415 06:36:48.938194    1921 reflector.go:341] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: watch o...(56940044)</span><br></pre></td></tr></table></figure><p>我们定义一个新的Environment var，比如就叫：KUBELET_EVICTION_POLICY_ARGS 在/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Environment=&quot;KUBELET_EVICTION_POLICY_ARGS=--eviction-hard=nodefs.available&lt;5%&quot;</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_EXTRA_ARGS $KUBELET_EVICTION_POLICY_ARGS</span><br></pre></td></tr></table></figure><p>这样控制，node的磁盘策略为&lt;5%的硬盘就可以用，不像之前默认的15%就用不了了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近发现测试环境的k8s集群，总有node利用不上，pod漂移过去之后，启动不了，故仔细排查了一下缘由！&lt;/p&gt;
&lt;h1 id=&quot;问题现象&quot;&gt;&lt;a href=&quot;#问题现象&quot; class=&quot;headerlink&quot; title=&quot;问题现象&quot;&gt;&lt;/a&gt;问题现象&lt;/h1&gt;&lt;figu
      
    
    </summary>
    
      <category term="k8s" scheme="https://shenshengkun.github.io/categories/k8s/"/>
    
    
  </entry>
  
</feed>
